[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "PHC 6701: R for Data Science // Advanced R",
    "section": "",
    "text": "Getting Started\n\nSetting up your computer:\n\nWindows: https://derailment.netlify.app/2019-11-01-configure-a-windows-pc-for-data-science/ (ignore the stuff about LaTeX)\nMac: https://derailment.netlify.app/2019-10-29-configure-a-mac-for-data-science/ (ignore the stuff about LaTeX)\n\nInstalling R/Rstudio:\n\nWindows: https://derailment.netlify.app/2019-12-10-installing-r-rstudio-on-windows/\nMac: https://derailment.netlify.app/2019-11-16-installing-r-rstudio-on-a-mac/\n\nSetting up R/RStudio: https://derailment.netlify.app/2019-12-22-configuring-rstudio/\nIf you want help, there is a great community of R programmers on Slack: https://rfordatasci.com/.\nSign up for GitHub using your student email address: https://docs.github.com/en/get-started/quickstart/creating-an-account-on-github"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "History of this material: I started writing the very first versions of these lessons back in spring of 2018 when I was a postdoc at the Sylvester Comprehensive Cancer Center. The Biostats/Bioinformatics group had weekly “research clinics” for the other postdocs and junior faculty to learn about various computational topics that could be helpful in their work. This material started off as four lessons (I can’t remember exactly what the topics were, but I think it was intro to R, ggplot, organizing work into scripts, and dplyr). The lessons were well received. That fall, I ended up teaching 9 weeks on R as part of “Survey of Statistical Computing” for the grad students in the school of medicine, and I also joined The Carpentries group at the University of Miami. After I joined Florida International University, I spent some time building out these lessons semester after semester (and with help and feedback from some awesome graduate students), and I taught this class every year. Now, I’m finally organizing and restructuring most of the lessons and scripts that I’ve worked on and taught from these past few years into a website to help my students have easy access to the material even after they finish class.\nMotivation: My experiences teaching with The Carpentries, to medical school students, and to public health students gave me a lot of one-on-one time with high-performing people who did not come from math / computer science backgrounds. I want to present the material in a logical way to people with hardly any computing background, but who still want to learn the basics for their research. As my friend Prof. Raymond Balise points out, we should assume students “can both point and click with a mouse”, and that’s about it. In that vein, if you come across parts of these lessons where I assume you know more than you do, please leave an issue ticket on the GitHub repository for this book (if you don’t know how to create a new issue, here’s a guide: https://www.techrepublic.com/article/how-to-create-github-issue/). I hope that this material is accessible to everyone."
  },
  {
    "objectID": "lessons/lesson01_greater_data_science.html",
    "href": "lessons/lesson01_greater_data_science.html",
    "title": "Lesson 1: Overview of Data Science",
    "section": "",
    "text": "We will cover the following:\n\nThe Fear Factor\nThe Syllabus\nWhat is Data Science?\nWhat is Reproducibility?\n\"Hello, World\""
  },
  {
    "objectID": "lessons/lesson01_greater_data_science.html#data-preparation-and-exploration",
    "href": "lessons/lesson01_greater_data_science.html#data-preparation-and-exploration",
    "title": "Lesson 1: Overview of Data Science",
    "section": "Data Preparation and Exploration",
    "text": "Data Preparation and Exploration\nThis is the portion of data science that deals with structuring your data appropriately (more on this later), exploratory data analysis, and data cleaning and preprocessing. For this part of data science, traditional statistics departments discuss only exploratory data analysis.\n\nExamples: designing the questions on a patient survey, creating a database to hold clinical trials data, finding the most common answers to a question, finding the largest or smallest values of a measurement, reporting the proportion of missing answers to a battery of questions between three cohorts."
  },
  {
    "objectID": "lessons/lesson01_greater_data_science.html#data-representation-and-transformation",
    "href": "lessons/lesson01_greater_data_science.html#data-representation-and-transformation",
    "title": "Lesson 1: Overview of Data Science",
    "section": "Data Representation and Transformation",
    "text": "Data Representation and Transformation\nThis deals with retreving data from databases or online repositories, changing and organizing the format of the data files, and using mathematical or logical transformations on recorded values. For this portion of data science, traditional statistics departments only discuss mathematical transformations and their validity.\n\nExamples: extracting subject data from RedCap, building EMR reports, organizing hundreds or thousands of case report forms into a few data files, transforming age in months or weeks to age in years, grouping free-form text (“florida”, “Florida”, “fl”, and “FL” together)."
  },
  {
    "objectID": "lessons/lesson01_greater_data_science.html#computing-with-data",
    "href": "lessons/lesson01_greater_data_science.html#computing-with-data",
    "title": "Lesson 1: Overview of Data Science",
    "section": "Computing with Data",
    "text": "Computing with Data\nThis part of data science concerns creating new programming languages, developing algorithms, using programming languages to automate data preparation, representation, and exploration, and packaging code for easier use. Of these, traditional statistics departments have only cared about algorithms (and sometimes not even that). However, many statisticians are starting to change their focus where this area is concerned. In this class you will learn parts of a few different computing and reporting languages, such as R, SAS, SQL, markdown and LaTeX.\n\nExamples: the R language was created to give statisticians and data scientists more control over their research, algorithms to fit statistical and mathematical models are created all the time, and we can create “packages” of computer code to repeat the same types of analyses on new data sets."
  },
  {
    "objectID": "lessons/lesson01_greater_data_science.html#data-modeling",
    "href": "lessons/lesson01_greater_data_science.html#data-modeling",
    "title": "Lesson 1: Overview of Data Science",
    "section": "Data Modeling",
    "text": "Data Modeling\nThis part of data science is the most well-known portion. It is what most lay-people consider “data science”: statistical modelling and machine learning. This is where simple techniques like t-tests, linear regression, or ANOVA come in, but it also includes highly complex models and routines such as deep neural networks, random coefficient mixed models, support vector machines, or discriminant analysis. Traditional statistics departments have historically taught or developed most of these techniques, although some interesting modern research has come from computer science and econometrics."
  },
  {
    "objectID": "lessons/lesson01_greater_data_science.html#data-visualization-and-presentation",
    "href": "lessons/lesson01_greater_data_science.html#data-visualization-and-presentation",
    "title": "Lesson 1: Overview of Data Science",
    "section": "Data Visualization and Presentation",
    "text": "Data Visualization and Presentation\nThis portion of data science includes all sorts of visualizations, from plots to interactive websites and applets. Data visualisation itself is nice, but using computer code to generate these visualizations is of paramount importance. Without the data and code to create the visualization, it can not be reproducible. Furthermore, the presentation of data in order to further an argument or claim is part of visual rhetoric, and is subject to questions of ethics. In traditional statistics departments, some of these tools are used, but rarely taught.\n\nExamples: making a scatterplot comparing SAT scores at different levels of household income, making a map shading counties in Florida by their ovarian cancer rates, designing a website to plot demographic information based on user selections.\n\n“A picture is worth a thousand words. Make sure your picture says the right thousand words.”"
  },
  {
    "objectID": "lessons/lesson01_greater_data_science.html#science-about-data-science",
    "href": "lessons/lesson01_greater_data_science.html#science-about-data-science",
    "title": "Lesson 1: Overview of Data Science",
    "section": "Science about Data Science",
    "text": "Science about Data Science\nThis portion of data science involves research meta-analysis about the utility of statistical and computational tools across entire disciplines, including applying data science concepts in disciplines untouched by data science. Currently, this is an area of active research in data science itself. This portion of the discipline identifies the boundaries of the discipline itself, the proper and ethical uses for data science, and experiments with the best ways to teach data science concepts. As this section of data science deals with philosophy and ethics, it has hardly anything to do with academic statistics.\n\nExamples: apply machine learning to analyze the provenance of art owned by Jews that had been seized by the Nazis or property owned by political dissenters seized by the Soviets, creating online courses to teach the basics of data science and reproducible research to non-scientists, writing commentary on the ethics of misleading graphs and figures in political campaigns."
  },
  {
    "objectID": "lessons/lesson01_greater_data_science.html#the-reproducibility-crisis",
    "href": "lessons/lesson01_greater_data_science.html#the-reproducibility-crisis",
    "title": "Lesson 1: Overview of Data Science",
    "section": "The Reproducibility Crisis",
    "text": "The Reproducibility Crisis\nPublished bio-science is largely not reproducible:\n\nOncology: 53 published articles tested, six successes (11%) (Nature, 2012)\nPsychology: 100 published articles, 39 successes (Nature News, 2015); 71 published articles tested, 92 replication attempts, 35 successes (38%; the PsychFileDrawer project is ongoing).\nPharmacology: 67 published models tested, 14 successes (21%) (Nature Reviews, 2011)"
  },
  {
    "objectID": "lessons/lesson01_greater_data_science.html#the-ioannidis-crusade",
    "href": "lessons/lesson01_greater_data_science.html#the-ioannidis-crusade",
    "title": "Lesson 1: Overview of Data Science",
    "section": "The Ioannidis crusade",
    "text": "The Ioannidis crusade\nJohn Ioannidis, physician scientist at Stanford, speaks harshly against the lack of replicability in science:\n\n“Replication validity of genetic association studies” (2001)\n“Contradicted and Initially Stronger Effects in Highly Cited Clinical Research” (2005)\n“Why Most Published Research Findings Are False” (2005)\n“Why Most Clinical Research Is Not Useful” (2016)"
  },
  {
    "objectID": "lessons/lesson01_greater_data_science.html#reproducible-data-science",
    "href": "lessons/lesson01_greater_data_science.html#reproducible-data-science",
    "title": "Lesson 1: Overview of Data Science",
    "section": "Reproducible Data Science",
    "text": "Reproducible Data Science\nBefore reproducibility must come preproducibility.\n“Instead of arguing about whether results hold up, let’s push to provide enough information for others to repeat the experiments … In computational science, ‘reproducible’ often means that enough information is provided to allow a dedicated reader to repeat the calculations in the paper for herself.”\n– Philip B. Stark, Professor of Statistics, UC Berkeley"
  },
  {
    "objectID": "lessons/lesson01_greater_data_science.html#use-code",
    "href": "lessons/lesson01_greater_data_science.html#use-code",
    "title": "Lesson 1: Overview of Data Science",
    "section": "Use Code!",
    "text": "Use Code!\nIf you want your analyses and figures to be reproducible, then you must use computer code to do this. Point-and-click software does not (usually) give you a record of your steps or allow you to repeat them. Building your data management, data modelling, and visualizations steps in a programming language means that you always have the tools necessary to repeat your work. In this class, you will learn how to write computer code to clean and transform your data, perform your analyses, and build the figures and tables for your papers. If you do this properly, this will ensure that anyone can recreate your analysis results, figures, and tables relatively quickly and painlessly."
  },
  {
    "objectID": "lessons/lesson01_greater_data_science.html#downloading-and-installing-r",
    "href": "lessons/lesson01_greater_data_science.html#downloading-and-installing-r",
    "title": "Lesson 1: Overview of Data Science",
    "section": "Downloading and Installing R",
    "text": "Downloading and Installing R\n\nFor Windows\n\nOpen an internet browser and go to https://www.r-project.org.\nClick the “download R” link in the middle of the page under “Getting Started.”\nSelect a CRAN location (a mirror site) and click the corresponding link.\n\nClick on the “Download R for Windows” link at the top of the page.\n\nClick on the “install R for the first time” link at the top of the page.\nClick “Download R for Windows” and save the executable file somewhere on your computer (your desktop is fine, because you will delete this file later).\nDouble-click on the .exe file to “run” it and follow the installation instructions (click “Next” or “Allow” a bunch of times).\n\n\n\nFor Mac\n\nOpen an internet browser and go to https://www.r-project.org.\nClick the “download R” link in the middle of the page under “Getting Started.”\nSelect a CRAN location (a mirror site) and click the corresponding link.\nClick on the “Download R for (Mac) OS X” link at the top of the page.\nClick on the file containing the latest version of R under “Files.”\nSave the .pkg file (to your desktop; you will delete it at the end)\nDouble-click the .pkg file to open, and follow the installation instructions (click “Next” or “Allow” a bunch).\n\nNow that R is installed, you need to download and install RStudio."
  },
  {
    "objectID": "lessons/lesson01_greater_data_science.html#download-and-install-rstudio",
    "href": "lessons/lesson01_greater_data_science.html#download-and-install-rstudio",
    "title": "Lesson 1: Overview of Data Science",
    "section": "Download and Install RStudio",
    "text": "Download and Install RStudio\n\nFor Windows\n\nGo to https://www.rstudio.com and click on the “Download RStudio” button.\nClick on “Download RStudio Desktop.”\nClick on the version recommended for your system, or the latest Windows version, and save the executable file (probably to your desktop, because we’re just going to delete it afterwards).\nDouble-click on the .exe file and follow the installation instructions (click “Next” or “Allow” a bunch of times).\n\n\n\nFor Mac\n\nGo to https://www.rstudio.com and click on the “Download RStudio” button.\nClick on “Download RStudio Desktop.”\nClick on the version recommended for your system, or the latest Mac version, and save the .dmg (disk image) file on your computer (probably to your desktop, because we are just going to delete it later)\nDouble-click the .dmg file to open it, and then drag and drop it to your applications folder."
  },
  {
    "objectID": "lessons/lesson01_greater_data_science.html#check-the-install",
    "href": "lessons/lesson01_greater_data_science.html#check-the-install",
    "title": "Lesson 1: Overview of Data Science",
    "section": "Check the Install",
    "text": "Check the Install\nWhether the installation worked or not, you should delete the install files to clean up your computer. Hopefully you can find them easily (if you saved them to the desktop, they should be easy to find).\nFind RStudio on your computer and open it. You should see a window that looks like this:\n\nThis application window is broken into three panes: the console pane, the environment pane, and the file pane.\n\nOur Very First R Code\nIn the console pane, move your cursor to the prompt (the > symbol). Type (you don’t have to type the > symbol; it’s just there for reference)\n\n> \"Hello, world!\"\n\nYou should see your welcome message displayed back to you. Congratulations! You have just executed your very first R code. Unfortunately, things get a touch more challenging after this, but that is why we are here: to learn."
  },
  {
    "objectID": "lessons/lesson10_stringr.html",
    "href": "lessons/lesson10_stringr.html",
    "title": "Lesson 10: Wrangling Character Strings with stringr",
    "section": "",
    "text": "What did we learn last class?\n\nSubset Rows with filter()\nSort Rows with arrange()\nSelect and Move Columns with select()\nCreate New Columns with mutate()\nGrouping and Group Summaries with group_by() and summarise()\nUsing *_join() to Merge Tibbles"
  },
  {
    "objectID": "lessons/lesson10_stringr.html#more-about-this-lesson",
    "href": "lessons/lesson10_stringr.html#more-about-this-lesson",
    "title": "Lesson 10: Wrangling Character Strings with stringr",
    "section": "More About this Lesson",
    "text": "More About this Lesson\nThe original version of this material was largely from my memory and what Catalina and I needed to solve some problems, but “version 2” was restructured to draw from the training materials here: https://rstudio.github.io/cheatsheets/html/strings.html. The cool thing about the stringr package is that all of the functions start with str_. This means that you can more easily find helpful string functions. Also, as with all of the packages in the tidyverse, the stringr package comes with a nice cheat sheet: https://rstudio.github.io/cheatsheets/strings.pdf."
  },
  {
    "objectID": "lessons/lesson10_stringr.html#example-data",
    "href": "lessons/lesson10_stringr.html#example-data",
    "title": "Lesson 10: Wrangling Character Strings with stringr",
    "section": "Example Data",
    "text": "Example Data\nWe will use two data sets as examples in this lesson, one easy and one complex.\n\nEasy: the fruit object from the stringr package. This is a simple character vector of names of different fruits. This small data set comes automatically with the Tidyverse.\nMedium: the sentences object from the stringr package. This contains the 720 Harvard Sentences for North American English voice identification. This data set also comes automatically with the Tidyverse.\nComplex: the outcomesCTN0094 data frame, with column usePatternUDS, from the CTNote package. For more information about the character string in this data set, see Odom et al. (2023). Install this package via (make sure to uncomment the install line the first time you run it)\n\n\n# install.packages(\"CTNote\")\nlibrary(CTNote)\nlibrary(tidyverse)\n\ndata(\"outcomesCTN0094\")\n\n\n\n\n\n\n\nExercises\n\n\n\n\nInspect the vector fruit.\nInspect first 20 elements of the vector sentences.\nCreate a smaller version of the outcomesCTN0094 tibble with the following columns: who, usePatternUDS, and ctn0094_relapse_time. Save it as an object in your Global environment called outcome_df."
  },
  {
    "objectID": "lessons/lesson10_stringr.html#functions-to-know",
    "href": "lessons/lesson10_stringr.html#functions-to-know",
    "title": "Lesson 10: Wrangling Character Strings with stringr",
    "section": "Functions to Know",
    "text": "Functions to Know\n\nstr_detect(): detect the presence/absence of a matching pattern\nstr_count(): count number of times a matching pattern appears in a string"
  },
  {
    "objectID": "lessons/lesson10_stringr.html#finding-matches",
    "href": "lessons/lesson10_stringr.html#finding-matches",
    "title": "Lesson 10: Wrangling Character Strings with stringr",
    "section": "Finding Matches",
    "text": "Finding Matches\nIn the fruit vector, we may want to find which fruit names have the word “berry” or “berries” in them, then print those names. Because I want to detect both, I have two options.\nOption 1: the character intersection of “berry” and “berries”:\n\n# Create a logical vector to indicate which strings have the matching pattern\nstr_detect(string = fruit, pattern = \"berr\")\n\n [1] FALSE FALSE FALSE FALSE FALSE  TRUE  TRUE FALSE FALSE  TRUE  TRUE FALSE\n[13] FALSE FALSE FALSE FALSE FALSE FALSE  TRUE FALSE  TRUE FALSE FALSE FALSE\n[25] FALSE FALSE FALSE FALSE  TRUE FALSE FALSE  TRUE  TRUE FALSE FALSE FALSE\n[37] FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n[49] FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n[61] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE  TRUE FALSE FALSE\n[73]  TRUE FALSE FALSE  TRUE FALSE FALSE FALSE FALSE\n\n# Print the names of the fruits which have the matching pattern\nfruit[ str_detect(string = fruit, pattern = \"berr\") ]\n\n [1] \"bilberry\"    \"blackberry\"  \"blueberry\"   \"boysenberry\" \"cloudberry\" \n [6] \"cranberry\"   \"elderberry\"  \"goji berry\"  \"gooseberry\"  \"huckleberry\"\n[11] \"mulberry\"    \"raspberry\"   \"salal berry\" \"strawberry\" \n\n\nOption 2: using an “OR” statement (the | symbol):\n\n# Create a logical vector to indicate which strings have the matching pattern\nstr_detect(string = fruit, pattern = \"berry|berries\")\n\n [1] FALSE FALSE FALSE FALSE FALSE  TRUE  TRUE FALSE FALSE  TRUE  TRUE FALSE\n[13] FALSE FALSE FALSE FALSE FALSE FALSE  TRUE FALSE  TRUE FALSE FALSE FALSE\n[25] FALSE FALSE FALSE FALSE  TRUE FALSE FALSE  TRUE  TRUE FALSE FALSE FALSE\n[37] FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n[49] FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n[61] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE  TRUE FALSE FALSE\n[73]  TRUE FALSE FALSE  TRUE FALSE FALSE FALSE FALSE\n\n# Print the names of the fruits which have the matching pattern\nfruit[ str_detect(string = fruit, pattern = \"berry|berries\") ]\n\n [1] \"bilberry\"    \"blackberry\"  \"blueberry\"   \"boysenberry\" \"cloudberry\" \n [6] \"cranberry\"   \"elderberry\"  \"goji berry\"  \"gooseberry\"  \"huckleberry\"\n[11] \"mulberry\"    \"raspberry\"   \"salal berry\" \"strawberry\" \n\n\n\n\n\n\n\n\nExercise\n\n\n\nFind all the fruits with the word “fruit” in the name."
  },
  {
    "objectID": "lessons/lesson10_stringr.html#counting-matches",
    "href": "lessons/lesson10_stringr.html#counting-matches",
    "title": "Lesson 10: Wrangling Character Strings with stringr",
    "section": "Counting Matches",
    "text": "Counting Matches\nIn the outcome_df data set each symbol in the column usePatternUDS represents the patient status during the routine weekly clinic visit. The o symbol is used to represent a week when a clinical trial participant failed to visit the clinic for follow-up care. We can count how in many weeks each trial participant was missing (since this is an example, we will only look a the first 20 participants):\n\noutcome_df$usePatternUDS[1:20] %>% \n  str_count(pattern = \"o\")\n\n [1] 15  7 21  3 15 14 20 25 22  3  6  6 11 19 25  6  0 25  7 25\n\n\n\n\n\n\n\n\nExercise\n\n\n\nMissing 3 clinic visits in a row is often a strong prognostic signal for a negative health outcome. Count the number of times per participant that the pattern “ooo” is seen. Use the first 20 patients only."
  },
  {
    "objectID": "lessons/lesson10_stringr.html#functions-to-know-1",
    "href": "lessons/lesson10_stringr.html#functions-to-know-1",
    "title": "Lesson 10: Wrangling Character Strings with stringr",
    "section": "Functions to Know",
    "text": "Functions to Know\n\nstr_replace() / str_replace_all(): replace the first/all matches of a pattern in a string with new text\nstr_remove() / str_remove_all: remove the first/all matches of a pattern in a string\nstr_to_lower() / str_to_upper(): convert a string to lower case/UPPER CASE"
  },
  {
    "objectID": "lessons/lesson10_stringr.html#replacing-one-pattern-with-another",
    "href": "lessons/lesson10_stringr.html#replacing-one-pattern-with-another",
    "title": "Lesson 10: Wrangling Character Strings with stringr",
    "section": "Replacing one Pattern with Another",
    "text": "Replacing one Pattern with Another\nIn the fruit vector, we could replace all the vowels with upper case letters to help children identify vowels within words. Recall that str_replace() only replaces the first match in the character string, so we will use str_replace_all(). This will give an example of piping multiple string commands together (which is often how we perform string manipulation).\n\nfruit %>% \n  str_replace_all(pattern = \"a\", replacement = \"A\") %>% \n  str_replace_all(pattern = \"e\", replacement = \"E\") %>% \n  str_replace_all(pattern = \"i\", replacement = \"I\") %>% \n  str_replace_all(pattern = \"o\", replacement = \"O\") %>% \n  str_replace_all(pattern = \"u\", replacement = \"U\")\n\n [1] \"ApplE\"             \"AprIcOt\"           \"AvOcAdO\"          \n [4] \"bAnAnA\"            \"bEll pEppEr\"       \"bIlbErry\"         \n [7] \"blAckbErry\"        \"blAckcUrrAnt\"      \"blOOd OrAngE\"     \n[10] \"blUEbErry\"         \"bOysEnbErry\"       \"brEAdfrUIt\"       \n[13] \"cAnAry mElOn\"      \"cAntAlOUpE\"        \"chErImOyA\"        \n[16] \"chErry\"            \"chIlI pEppEr\"      \"clEmEntInE\"       \n[19] \"clOUdbErry\"        \"cOcOnUt\"           \"crAnbErry\"        \n[22] \"cUcUmbEr\"          \"cUrrAnt\"           \"dAmsOn\"           \n[25] \"dAtE\"              \"drAgOnfrUIt\"       \"dUrIAn\"           \n[28] \"EggplAnt\"          \"EldErbErry\"        \"fEIjOA\"           \n[31] \"fIg\"               \"gOjI bErry\"        \"gOOsEbErry\"       \n[34] \"grApE\"             \"grApEfrUIt\"        \"gUAvA\"            \n[37] \"hOnEydEw\"          \"hUcklEbErry\"       \"jAckfrUIt\"        \n[40] \"jAmbUl\"            \"jUjUbE\"            \"kIwI frUIt\"       \n[43] \"kUmqUAt\"           \"lEmOn\"             \"lImE\"             \n[46] \"lOqUAt\"            \"lychEE\"            \"mAndArInE\"        \n[49] \"mAngO\"             \"mUlbErry\"          \"nEctArInE\"        \n[52] \"nUt\"               \"OlIvE\"             \"OrAngE\"           \n[55] \"pAmElO\"            \"pApAyA\"            \"pAssIOnfrUIt\"     \n[58] \"pEAch\"             \"pEAr\"              \"pErsImmOn\"        \n[61] \"physAlIs\"          \"pInEApplE\"         \"plUm\"             \n[64] \"pOmEgrAnAtE\"       \"pOmElO\"            \"pUrplE mAngOstEEn\"\n[67] \"qUIncE\"            \"rAIsIn\"            \"rAmbUtAn\"         \n[70] \"rAspbErry\"         \"rEdcUrrAnt\"        \"rOck mElOn\"       \n[73] \"sAlAl bErry\"       \"sAtsUmA\"           \"stAr frUIt\"       \n[76] \"strAwbErry\"        \"tAmArIllO\"         \"tAngErInE\"        \n[79] \"UglI frUIt\"        \"wAtErmElOn\"       \n\n\n\n\n\n\n\n\nExercise\n\n\n\nIn the use pattern symbol vector the * symbol represents a mixture of positive and negative results. Change all * symbols to +. You will most likely need to escape the symbols with two backslashes."
  },
  {
    "objectID": "lessons/lesson10_stringr.html#removing-characters-that-match-a-pattern",
    "href": "lessons/lesson10_stringr.html#removing-characters-that-match-a-pattern",
    "title": "Lesson 10: Wrangling Character Strings with stringr",
    "section": "Removing Characters that Match a Pattern",
    "text": "Removing Characters that Match a Pattern\nIn much of text analysis, sentences are analyzed without the “filler words” (known as stop words), such as “and”, “to”, “the”, “of”, “a”, “was”, “is”, etc. We can remove these words from our set of sentences.\n\nsentences[1:20] %>% \n  str_remove_all(pattern = \"and\") %>% \n  str_remove_all(pattern = \"to\") %>% \n  str_remove_all(pattern = \"the\") %>% \n  str_remove_all(pattern = \"of\") %>% \n  str_remove_all(pattern = \"a\")\n\n [1] \"The birch cnoe slid on  smooth plnks.\"   \n [2] \"Glue  sheet   drk blue bckground.\"       \n [3] \"It's esy  tell  depth   well.\"           \n [4] \"These dys  chicken leg is  rre dish.\"    \n [5] \"Rice is ten served in round bowls.\"      \n [6] \"The juice  lemons mkes fine punch.\"      \n [7] \"The box ws thrown beside  prked truck.\"  \n [8] \"The hogs were fed chopped corn  grbge.\"  \n [9] \"Four hours  stedy work fced us.\"         \n[10] \"A lrge size in sckings is hrd  sell.\"    \n[11] \"The boy ws re when  sun rose.\"           \n[12] \"A rod is used  ctch pink slmon.\"         \n[13] \"The source   huge river is  cler spring.\"\n[14] \"Kick  bll stright  follow through.\"      \n[15] \"Help  womn get bck  her feet.\"           \n[16] \"A pot  te helps  pss  evening.\"          \n[17] \"Smoky fires lck flme  het.\"              \n[18] \"The st cushion broke  mn's fll.\"         \n[19] \"The slt breeze cme cross from  se.\"      \n[20] \"The girl t  booth sold fifty bonds.\"     \n\n\n\n\n\n\n\n\nExercises\n\n\n\n\nNotice that the results above may not be what you expected. Some problems include:\n\nstop words at the beginning of the sentence were not removed\nsome words are now misspelled\n\n\nBrainstorm with your neighbour what you think went wrong and how you could fix it. 2. Try a few solutions you suggested in Exercise 1. 3. Some of the words now have extra spaces between them. What could we modify in the code above to address this?"
  },
  {
    "objectID": "lessons/lesson10_stringr.html#changing-case",
    "href": "lessons/lesson10_stringr.html#changing-case",
    "title": "Lesson 10: Wrangling Character Strings with stringr",
    "section": "Changing Case",
    "text": "Changing Case\nIn the above example, some of the stop words were not removed because they were at the start of the sentence (and therefore had a capital letter). We can change all the letters in a string to be the same case (which makes pattern matching easier) with the str_to_lower() and str_to_upper() functions. Notice that we added the str_to_lower() call in the pipeline before removing the stop words.\n\nsentences[1:20] %>% \n  str_to_lower() %>% \n  str_remove_all(pattern = \"and \") %>% \n  str_remove_all(pattern = \"the \")\n\n [1] \"birch canoe slid on smooth planks.\"        \n [2] \"glue sheet to dark blue background.\"       \n [3] \"it's easy to tell depth of a well.\"        \n [4] \"these days a chicken leg is a rare dish.\"  \n [5] \"rice is often served in round bowls.\"      \n [6] \"juice of lemons makes fine punch.\"         \n [7] \"box was thrown beside parked truck.\"       \n [8] \"hogs were fed chopped corn garbage.\"       \n [9] \"four hours of steady work faced us.\"       \n[10] \"a large size in stockings is hard to sell.\"\n[11] \"boy was there when sun rose.\"              \n[12] \"a rod is used to catch pink salmon.\"       \n[13] \"source of huge river is clear spring.\"     \n[14] \"kick ball straight follow through.\"        \n[15] \"help woman get back to her feet.\"          \n[16] \"a pot of tea helps to pass evening.\"       \n[17] \"smoky fires lack flame heat.\"              \n[18] \"soft cushion broke man's fall.\"            \n[19] \"salt breeze came across from sea.\"         \n[20] \"girl at booth sold fifty bonds.\"           \n\n\n\n\n\n\n\n\nExercise\n\n\n\nNotice that I modified the two stop words slightly. What did that change? Discuss with your neighbor and modify your code from the last exercise if necessary.\n\n\n\n\n\n\n\n\nTip: Order Matters\n\n\n\nWhen calling string manipulation functions, the order of the function calls in the pipeline matters A LOT. Pay close attention to the orders of the actions you prescribe, and it’s usually very wise to run a stringr:: pipeline line-by-line as you build it."
  },
  {
    "objectID": "lessons/lesson10_stringr.html#functions-to-know-2",
    "href": "lessons/lesson10_stringr.html#functions-to-know-2",
    "title": "Lesson 10: Wrangling Character Strings with stringr",
    "section": "Functions to Know",
    "text": "Functions to Know\n\nstr_sub(): extracts or replaces the elements at a single position in each string\nstr_extract() / str_extract_all(): extract the first/all matches of a pattern from each string\n\nIn my experience, the functions in this section are most useful when dealing with very organized text data. For example, my students and I were working on a dataset that recorded the heights of participants as text. The entries of this data table would have been something like this:\n\nheightsF_char <- c(\"60in\", \"68in\", \"66in\", \"60in\", \"65in\", \"62in\", \"63in\")\nheightsM_char <- c(\"72in\", \"68in\", \"73in\", \"65in\", \"71in\", \"66in\", \"67in\")"
  },
  {
    "objectID": "lessons/lesson10_stringr.html#substrings-by-position",
    "href": "lessons/lesson10_stringr.html#substrings-by-position",
    "title": "Lesson 10: Wrangling Character Strings with stringr",
    "section": "Substrings by Position",
    "text": "Substrings by Position\nIf we know that the information we want is always in the same position, then we can create a substring using only the “letters” between these positions with str_sub().\n\n# Count forward (from the start of the string):\nheightsF_char %>% \n  str_sub(start = 1, end = 2)\n\n[1] \"60\" \"68\" \"66\" \"60\" \"65\" \"62\" \"63\"\n\n# Count backwards (from the end of the string):\nheightsF_char %>% \n  str_sub(start = -4, end = -3)\n\n[1] \"60\" \"68\" \"66\" \"60\" \"65\" \"62\" \"63\"\n\n\n\n\n\n\n\n\nExercise\n\n\n\nPretend that you spoke with a clinician about the use patterns in the outcome_df data set. She informed you that the first three weeks should be considered an onboarding period for each participant, and therefore should be removed from the data before final analysis. Remove the symbols for the first three weeks."
  },
  {
    "objectID": "lessons/lesson10_stringr.html#substrings-by-pattern",
    "href": "lessons/lesson10_stringr.html#substrings-by-pattern",
    "title": "Lesson 10: Wrangling Character Strings with stringr",
    "section": "Substrings by Pattern",
    "text": "Substrings by Pattern\nInstead, if we know that the information we want is always the same pattern, then we can extract the matching pattern with str_extract().\n\nheightsF_char %>% \n  # We want the numeric digits (\\\\d) that are two characters long ({2})\n  str_extract(pattern = \"\\\\d{2}\")\n\n[1] \"60\" \"68\" \"66\" \"60\" \"65\" \"62\" \"63\"\n\n\nIf you are wondering where in the world that \\\\d{2} stuff came from, you’re not alone. It’s something called a regular expression. I don’t expect you all to become experts in this, but it’s worth studying the Posit Regular Expressions guide for how these character matching codes can be used in R.\n\n\n\n\n\n\nExercises\n\n\n\n\nIf you attempt to extract a pattern from a string that doesn’t exist, what happens?\nIf you attempt to extract a range of characters that doesn’t exist (for instance, using start = 2 and end = 1 to have the end of the range before the start of the range), what happens?\nDiscuss these two results from the str_sub() and str_extract() functions with your neighbours. Think about cases where each might be useful."
  },
  {
    "objectID": "lessons/lesson10_stringr.html#functions-to-know-3",
    "href": "lessons/lesson10_stringr.html#functions-to-know-3",
    "title": "Lesson 10: Wrangling Character Strings with stringr",
    "section": "Functions to Know",
    "text": "Functions to Know\n\nstr_length(): compute the number of “letters” in a string\nstr_trim(): remove spaces from the start and end of string\nstr_pad(): add spaces (or some other “letter”) to the start or end of a string until the string is a specified length\n\nOverall, it’s often not immediately obvious when these functions would be useful to you, but know that from my experience that they are often unexpected lifesavers. I’m going to give three such examples from when these functions have helped me in the past."
  },
  {
    "objectID": "lessons/lesson10_stringr.html#string-lengths",
    "href": "lessons/lesson10_stringr.html#string-lengths",
    "title": "Lesson 10: Wrangling Character Strings with stringr",
    "section": "String Lengths",
    "text": "String Lengths\nThe str_length() functions is useful when dealing with \\(n\\)-ary words. These are sets of letters or numbers where each single symbol from a pre-defined set of \\(n\\) possible symbols represents a state in a system. Examples include the use pattern “words” in the outcome_df data set; DNA/RNA (“CCCCAACGTGTG” is a string of letters where each single letter represents a one of the four DNA nucleotides bases—Cytosine, Adenine, Thymine, and Guanine); or class attendance (“PPPPPAPP” represents a student’s attendance record over eight weeks as “Present” or “Absent”).\n\n# How many nucleotides in the strand?\nstr_length(\"CCCCAACGTGTG\")\n\n[1] 12\n\n# How many weeks of attendance data?\nstr_length(\"PPPPPAPP\")\n\n[1] 8"
  },
  {
    "objectID": "lessons/lesson10_stringr.html#trimming-strings",
    "href": "lessons/lesson10_stringr.html#trimming-strings",
    "title": "Lesson 10: Wrangling Character Strings with stringr",
    "section": "Trimming Strings",
    "text": "Trimming Strings\nThis comes up for me most often when dealing with very long labels in ggplot figures. Sometimes a factor label is really long, and ggplot tries to fit the whole label in the figure, which ends up making the whole figure look weird.\nHere’s an example. I’m going to create a simple data set with one very long factor label.\n\nbookPages_df <- tibble(\n  title = c(\"Germinal\", \"Frankenstein; or, The Modern Prometheus\"),\n  author = c(\"Emile Zola\", \"Mary Shelley\"),\n  pageCountOriginal = c(591L, 362L),\n  year = c(1885, 1818)\n)\n\n# Original\nggplot(data = bookPages_df) + \n  aes(x = year, y = pageCountOriginal, shape = title) + \n  geom_point()\n\n\n\n\nNow I’m going to truncate the very long title of Frankenstein.\n\n# Truncated text\nbookPages_df %>% \n  mutate(\n    title = str_trunc(title, width = 15)\n  ) %>% \n  ggplot() +\n    aes(x = year, y = pageCountOriginal, shape = title) + \n    geom_point()"
  },
  {
    "objectID": "lessons/lesson10_stringr.html#padding-strings",
    "href": "lessons/lesson10_stringr.html#padding-strings",
    "title": "Lesson 10: Wrangling Character Strings with stringr",
    "section": "Padding Strings",
    "text": "Padding Strings\nThis comes up when I’m trying to create file names in a computer. Here’s the issue:\n\n1:11 %>% \n  as.character() %>% \n  sort()\n\n [1] \"1\"  \"10\" \"11\" \"2\"  \"3\"  \"4\"  \"5\"  \"6\"  \"7\"  \"8\"  \"9\" \n\n\nWhen the computer turns numbers into characters, the ordering of the numbers gets destroyed. We all know that I want 10 and 11 to come last, but the computer doesn’t interpret these numbers the way that I do. The solution is to pad the numbers on the left with “0” so that the ordering is preserved:\n\n1:11 %>% \n  as.character() %>% \n  # Set the width to 2 digits if 99 is enough, but increase to 3 digits in case\n  #   I need to go past 99 (up to 999)\n  str_pad(width = 3, side = \"left\", pad = \"0\") %>% \n  sort()\n\n [1] \"001\" \"002\" \"003\" \"004\" \"005\" \"006\" \"007\" \"008\" \"009\" \"010\" \"011\""
  },
  {
    "objectID": "lessons/lesson10_stringr.html#example-plotting-participant-heights",
    "href": "lessons/lesson10_stringr.html#example-plotting-participant-heights",
    "title": "Lesson 10: Wrangling Character Strings with stringr",
    "section": "Example: Plotting Participant Heights",
    "text": "Example: Plotting Participant Heights\nHere I show an entire (simplified) workflow to take in the height data and plot it by biological sex.\n\n###  Create tidy data  ###\nheights_df <- tibble(\n  is_female = c(\n    rep(TRUE, length(heightsF_char)),\n    rep(FALSE, length(heightsM_char))\n  ),\n  heights = c(heightsF_char, heightsM_char)\n)\n\n###  Wrangle the Data  ###\nheightsClean_df <- \n  heights_df %>% \n  # Step 1: Split the Units into another column\n  mutate(\n    units = str_sub(heights, start = -2, end = -1)\n  ) %>% \n  # Step 2: Extract the height values\n  mutate(\n    value = str_extract(heights, pattern = \"\\\\d{2}\")\n  ) %>% \n  # Step 3: change heights from character to numeric\n  mutate(\n    value = as.numeric(value)\n  ) %>% \n  # Step 4: remove the original column (check your work beforehand)\n  select(-heights) %>% \n  # Step 5: rename\n  rename(height = value)\n\n###  Plot the Relationship  ###\nggplot(data = heightsClean_df) + \n  theme_classic() + \n  aes(x = is_female, y = height) + \n  geom_boxplot()\n\n\n\n\n\n\n\n\n\n\nExercise\n\n\n\nBetween this lesson and the dplyr:: lesson, you now have the skills to join the ACS SNAP data to the Miami-Dade and Broward ZIP code data. Here are some basic steps:\n\nImport the data sets.\nUse the string manipulation functions to clean up the ZIP code columns until they can match.\nJoin the data sets so that you have one table with all the ACS SNAP data combined for Miami-Dade and Broward counties."
  },
  {
    "objectID": "lessons/lesson07_lists_and_tibbles.html",
    "href": "lessons/lesson07_lists_and_tibbles.html",
    "title": "Lesson 7: Lists and Tibbles",
    "section": "",
    "text": "What did we learn last class?\n\nAtomic Vectors\nBasic Subsetting\nType Coercion\nAttributes\nNamed Subsetting\nFactors\nMissing Values"
  },
  {
    "objectID": "lessons/lesson07_lists_and_tibbles.html#review-of-objects",
    "href": "lessons/lesson07_lists_and_tibbles.html#review-of-objects",
    "title": "Lesson 7: Lists and Tibbles",
    "section": "Review of Objects",
    "text": "Review of Objects\nRecall that everything in R is an object. The objects in R are broken up primarily like this:\n\nAlso, because R is a vectorised language, most non-function objects we encounter are vectors. Vectors in R are broken into two main types: atomic and non-atomic. Atomic vectors mean that all of the elements in the vector have the same type or class. Non-atomic vectors are everything else. Last lesson, we worked on creating and subsetting atomic vectors."
  },
  {
    "objectID": "lessons/lesson07_lists_and_tibbles.html#object-dimensions",
    "href": "lessons/lesson07_lists_and_tibbles.html#object-dimensions",
    "title": "Lesson 7: Lists and Tibbles",
    "section": "Object Dimensions",
    "text": "Object Dimensions\nThe rules and techniques for subsetting data depend on two things:\n\nIs the object atomic or non-atomic? E.g., an integer vector vs a list.\nIs the object 1-dimensional or higher-dimensional? E.g., a list vs a tibble.\n\nFor these considerations, we use the class of the object to decide the proper subsetting rules (rather than the type).\nHere is a table of example vector types, their dimensions, and their resulting classes (this is not exhaustive):\n\n\n\n\nAtomic\nNon-Atomic\n\n\n\n\n1-D\nlogical\nlist\n\n\n2-D\nmatrix\ndata.frame"
  },
  {
    "objectID": "lessons/lesson07_lists_and_tibbles.html#example-data",
    "href": "lessons/lesson07_lists_and_tibbles.html#example-data",
    "title": "Lesson 7: Lists and Tibbles",
    "section": "Example Data",
    "text": "Example Data\n\nNames and Ages\nLast lesson, we had created a basic vector for my sibling’s ages, named with their first names.\n\nages_int   <- c(31, 29, 27, 25, 23, 21)\nnames_char <- c(\n  \"Gabriel\", \"Britni\", \"Michael\", \"Christiana\", \"Olivia\", \"Hannah\"\n)\nnames(ages_int) <- names_char\n\n\n\nElectronic ID Object\nAlso, recall the ID vector we created in the last lesson:\n\nDrGabriel <- c(\n  Surname = \"Odom\",\n  FirstName = \"Gabriel\",\n  HighestDegrees = \"PhD, ThD\",\n  Age = 31,\n  City = \"Pembroke Pines\",\n  State = \"FL\",\n  MovedFrom = \"TX\",\n  timeEmployed = 2.1\n)\n\nWe discovered last lesson that the values for Age and timeEmployed were coerced from numeric to character information due to the restrictions of atomic vectors. However, non-atomic vectors are vectors such that the type / class of each element in the vector is not forced to be the same. So far, we have created ID vectors for ourselves, but these do not allow us to mix different classes of data. We need something more flexible."
  },
  {
    "objectID": "lessons/lesson07_lists_and_tibbles.html#creating-lists",
    "href": "lessons/lesson07_lists_and_tibbles.html#creating-lists",
    "title": "Lesson 7: Lists and Tibbles",
    "section": "Creating Lists",
    "text": "Creating Lists\nLists are vectors that can have any class of object as its elements—even other lists! They are the opposite of atomic. We have seen one such example so far: the attributes of an atomic vector are a list:\n\nattributes(DrGabriel)\n\n$names\n[1] \"Surname\"        \"FirstName\"      \"HighestDegrees\" \"Age\"           \n[5] \"City\"           \"State\"          \"MovedFrom\"      \"timeEmployed\"  \n\nclass(attributes(DrGabriel))\n\n[1] \"list\"\n\n\nLists give us flexibility to create an ID vector that has different classes of information, including other vectors! We create a new list with the function list():\n\n# Create a List\nDrGabriel_ls <- list(\n  Surname   = \"Odom\",\n  Forename  = \"Gabriel\",\n  Male      = TRUE,\n  City      = \"Pembroke Pines\",\n  State     = factor(\"FL\", levels = state.abb),\n  CurrZIP   = 33025,\n  MovedFrom = \"TX\",\n  Age       = 31,\n  MaxDegree = c(\"PhD\", \"ThD\"),\n  TimeEmpl  = 2.1\n)\n\n# Inspect\nDrGabriel_ls\n\n$Surname\n[1] \"Odom\"\n\n$Forename\n[1] \"Gabriel\"\n\n$Male\n[1] TRUE\n\n$City\n[1] \"Pembroke Pines\"\n\n$State\n[1] FL\n50 Levels: AL AK AZ AR CA CO CT DE FL GA HI ID IL IN IA KS KY LA ME MD ... WY\n\n$CurrZIP\n[1] 33025\n\n$MovedFrom\n[1] \"TX\"\n\n$Age\n[1] 31\n\n$MaxDegree\n[1] \"PhD\" \"ThD\"\n\n$TimeEmpl\n[1] 2.1\n\n\nIf we want to inspect the internal structure of this list, we can see that the classes of our original atomic vectors have been preserved. There is no class coercion in a list.\n\nstr(DrGabriel_ls)\n\nList of 10\n $ Surname  : chr \"Odom\"\n $ Forename : chr \"Gabriel\"\n $ Male     : logi TRUE\n $ City     : chr \"Pembroke Pines\"\n $ State    : Factor w/ 50 levels \"AL\",\"AK\",\"AZ\",..: 9\n $ CurrZIP  : num 33025\n $ MovedFrom: chr \"TX\"\n $ Age      : num 31\n $ MaxDegree: chr [1:2] \"PhD\" \"ThD\"\n $ TimeEmpl : num 2.1\n\n\nAs with the atomic vectors, we can also find what R thinks about lists and how R stores this information:\n\nclass(DrGabriel_ls)\n\n[1] \"list\"\n\ntypeof(DrGabriel_ls)\n\n[1] \"list\"\n\n\n\n\n\n\n\n\nExercises\n\n\n\n\nReview constructing sequential integer vectors. Create a vector from -4 to -1 without the c() function.\nUse the help files to read about the state.abb object I used when making the factor for my current state. Did I create it? Where did it come from?\nThe DrGabriel_ls object itself contains an atomic vector of length 2. Is this still a 1-D object? Why or why not?\nUpdate your ID card to a list format. Include an entry for at least two of your favourite foods as an atomic character vector.\nOpen the R script you created last class. Make sure this script includes code to build the atomic vectors above, as well as the example ID lists."
  },
  {
    "objectID": "lessons/lesson07_lists_and_tibbles.html#creating-tibbles",
    "href": "lessons/lesson07_lists_and_tibbles.html#creating-tibbles",
    "title": "Lesson 7: Lists and Tibbles",
    "section": "Creating Tibbles",
    "text": "Creating Tibbles\nIn order to use tibbles, we need functions from the tidyverse. A tibble can be created by hand, but most commonly we generate them by importing tabular / spreasheet data (with the functions read_csv() or read_delim(); more on these in a week or so).\n\nlibrary(tidyverse)\n\nWe can create the same ID card as we did with the list() function, but in a rectangular / tabular form. We create a tibble with the tibble() function. Similar to the c() function, we can supply as many inputs as we want, as long as they are all atomic vectors with the same length (notice that I changed the “highest degrees” back to a single character because of this restriction).\n\n# Create a Tibble\nDrGabriel_df <- tibble(\n  Surname = \"Odom\",\n  FirstName = \"Gabriel\",\n  HighestDegrees = \"PhD, ThD\",\n  Age = 31,\n  City = \"Pembroke Pines\",\n  State = \"FL\",\n  MovedFrom = \"TX\",\n  TimeEmployed = 2.1\n)\n\n# Inspect\nDrGabriel_df\n\n# A tibble: 1 × 8\n  Surname FirstName HighestDegrees   Age City       State MovedFrom TimeEmployed\n  <chr>   <chr>     <chr>          <dbl> <chr>      <chr> <chr>            <dbl>\n1 Odom    Gabriel   PhD, ThD          31 Pembroke … FL    TX                 2.1\n\n\n(Technically I could have left the degrees entry as an atomic vector with 2 entries, but the tibble() function would have to try to figure out what I meant. Sometimes it guesses correctly, sometimes not. We will discuss the tibble() function more in a few weeks.)\nAs with the atomic vectors, we can also find what R thinks about lists and how R stores this information:\n\nclass(DrGabriel_df)\n\n[1] \"tbl_df\"     \"tbl\"        \"data.frame\"\n\ntypeof(DrGabriel_df)\n\n[1] \"list\"\n\n\nNotice that R still stores a tibble as a list (we see this from the typeof() function). In a tibble, the individual columns must have the same class and all columns must have the same length, but the entire data set often has different classes of data in each column. Here’s the example from the figure above.\n\nheroes_df <- tibble(\n  subject_ID = factor(c(\"008\", \"016\", \"115\", \"027\", \"001\")),\n  name = c(\n    \"Wonder Woman\", \"Green Lantern\", \"Spider-Man\", \"Batman\", \"Superman\"\n  ),\n  alias = c(\n    \"Diana Prince\", \"Alan Scott\", \"Peter Parker\", \"Bruce Wayne\",\n    \"Clark Kent / Kal-El\"\n  ),\n  city = c(\n    \"Gateway City\", \"Capitol City\", \"New York City\", \"Gotham\", \"Metropolis\"\n  ),\n  male = c(FALSE, TRUE, TRUE, TRUE, TRUE),\n  heightCM = c(183.5, 182.9, 177.8, 188.0, 190.5),\n  weightKg = c(74.8, 91.2, 75.7, 95.3, 106.6),\n  firstRun = c(1941L, 1940L, 1962L, 1939L, 1938L)\n)\n\nNotice that when I create this tibble, each of the entries (columns) are the same length (5 elements each), within each column the classes do not change (column heightCM is all numeric, column city is all character, etc.).\nWe check what this looks like:\n\nheroes_df\n\n# A tibble: 5 × 8\n  subject_ID name          alias          city  male  heightCM weightKg firstRun\n  <fct>      <chr>         <chr>          <chr> <lgl>    <dbl>    <dbl>    <int>\n1 008        Wonder Woman  Diana Prince   Gate… FALSE     184.     74.8     1941\n2 016        Green Lantern Alan Scott     Capi… TRUE      183.     91.2     1940\n3 115        Spider-Man    Peter Parker   New … TRUE      178.     75.7     1962\n4 027        Batman        Bruce Wayne    Goth… TRUE      188      95.3     1939\n5 001        Superman      Clark Kent / … Metr… TRUE      190.    107.      1938\n\n\nWe see that the classes of the columns are displayed under the column names.\n\n\n\n\n\n\nExercise\n\n\n\nAdd the code to create the tibble above to your script from last lesson."
  },
  {
    "objectID": "lessons/lesson07_lists_and_tibbles.html#optional-data-frames",
    "href": "lessons/lesson07_lists_and_tibbles.html#optional-data-frames",
    "title": "Lesson 7: Lists and Tibbles",
    "section": "(OPTIONAL) Data Frames",
    "text": "(OPTIONAL) Data Frames\nData frames are and have been the de facto data structure in R for most tabular data for over two decades. They are what people commonly used for statistics and plotting. However, tibbles are simply a modern hybrid of a table and a data frame, which includes many nice attributes, properties, and features. The main difference between tibbles and data frames is that data frames can only have columns of atomic vectors; the other restrictions are the same: only one class per column and all columns have the same length.\nMoving forward, we will make use of tibbles, but you will most likely see older code that uses data frames as you learn more of R. We create the “antique” tibble with the data.frame() function.\n\n# Create a Data Frame\nheroes_OldDF <- data.frame(\n  subjectID = factor(c(\"008\", \"016\", \"115\", \"027\", \"001\")),\n  name = c(\"Wonder Woman\", \"Green Lantern\", \"Spider-Man\", \"Batman\", \"Superman\"),\n  alias = c(\n    \"Diana Prince\", \"Alan Scott\", \"Peter Parker\", \"Bruce Wayne\",\n    \"Clark Kent / Kal-El\"\n  ),\n  city = c(\n    \"Gateway City\", \"Capitol City\", \"New York City\", \"Gotham\", \"Metropolis\"\n  ),\n  male = c(FALSE, TRUE, TRUE, TRUE, TRUE),\n  heightCM = c(183.5, 182.9, 177.8, 188.0, 190.5),\n  weightKg = c(74.8, 91.2, 75.7, 95.3, 106.6),\n  firstRun = c(1941L, 1940L, 1962L, 1939L, 1938L)\n)\n\n# Inspect\nheroes_OldDF\n\n  subjectID          name               alias          city  male heightCM\n1       008  Wonder Woman        Diana Prince  Gateway City FALSE    183.5\n2       016 Green Lantern          Alan Scott  Capitol City  TRUE    182.9\n3       115    Spider-Man        Peter Parker New York City  TRUE    177.8\n4       027        Batman         Bruce Wayne        Gotham  TRUE    188.0\n5       001      Superman Clark Kent / Kal-El    Metropolis  TRUE    190.5\n  weightKg firstRun\n1     74.8     1941\n2     91.2     1940\n3     75.7     1962\n4     95.3     1939\n5    106.6     1938\n\n\nIf you want some more details on this data frame, use the str() function:\n\nstr(heroes_OldDF)\n\n'data.frame':   5 obs. of  8 variables:\n $ subjectID: Factor w/ 5 levels \"001\",\"008\",\"016\",..: 2 3 5 4 1\n $ name     : chr  \"Wonder Woman\" \"Green Lantern\" \"Spider-Man\" \"Batman\" ...\n $ alias    : chr  \"Diana Prince\" \"Alan Scott\" \"Peter Parker\" \"Bruce Wayne\" ...\n $ city     : chr  \"Gateway City\" \"Capitol City\" \"New York City\" \"Gotham\" ...\n $ male     : logi  FALSE TRUE TRUE TRUE TRUE\n $ heightCM : num  184 183 178 188 190\n $ weightKg : num  74.8 91.2 75.7 95.3 106.6\n $ firstRun : int  1941 1940 1962 1939 1938\n\n\n\n\n\n\n\n\nExercises\n\n\n\n\nWhat are some differences between tibbles and data frames that you can find?\nCheck the help file of the data.frame() function to find out how to preserve character information. What option should you add to the code above?\nLast class, we discussed naming conventions. Are the names within my vectors consistent? Why or why not? What might I do to make them better?"
  },
  {
    "objectID": "lessons/lesson07_lists_and_tibbles.html#inspecting-tibbles",
    "href": "lessons/lesson07_lists_and_tibbles.html#inspecting-tibbles",
    "title": "Lesson 7: Lists and Tibbles",
    "section": "Inspecting Tibbles",
    "text": "Inspecting Tibbles\nWe already saw how the printing the tibble and caling the str() function can be useful to check the content and the structure of data. Because we want to see something more interesting than our ID card, let’s take a look at the mpg data set from last week.\n\nmpg\n\n# A tibble: 234 × 11\n   manufacturer model      displ  year   cyl trans drv     cty   hwy fl    class\n   <chr>        <chr>      <dbl> <int> <int> <chr> <chr> <int> <int> <chr> <chr>\n 1 audi         a4           1.8  1999     4 auto… f        18    29 p     comp…\n 2 audi         a4           1.8  1999     4 manu… f        21    29 p     comp…\n 3 audi         a4           2    2008     4 manu… f        20    31 p     comp…\n 4 audi         a4           2    2008     4 auto… f        21    30 p     comp…\n 5 audi         a4           2.8  1999     6 auto… f        16    26 p     comp…\n 6 audi         a4           2.8  1999     6 manu… f        18    26 p     comp…\n 7 audi         a4           3.1  2008     6 auto… f        18    27 p     comp…\n 8 audi         a4 quattro   1.8  1999     4 manu… 4        18    26 p     comp…\n 9 audi         a4 quattro   1.8  1999     4 auto… 4        16    25 p     comp…\n10 audi         a4 quattro   2    2008     4 manu… 4        20    28 p     comp…\n# ℹ 224 more rows\n\n\nHere is a non-exhaustive list of functions to get a sense of the content/structure of your data. Note that—while these functions are very useful, we get most of this information for free if we are using tibbles (one of the main reasons we use tibbles instead of the older data frame structure).\n\nStructure:\n\nstr(mpg): a list of the vectors used to create the mpg data set, their classes, and their lengths (this includes excerpts from most of the functions below)\n\nSize:\n\ndim(mpg): a vector with the number of rows in the first element, and the number of columns as the second element (these are the dimensions of the object)\nnrow(mpg): the number of rows\nncol(mpg): the number of columns\n\nContent:\n\nhead(mpg): the first 6 rows\ntail(mpg): the last 6 rows\nsummary(mpg): summary statistics for each column\n\nNames:\n\nnames(mpg) or colnames(mpg): the column names\nrownames(mpg): the row names\n\n\nNote: the head, tail, summary, and names functions are “generic”; that is, they can be used on most other types of objects besides tibbles, including data frames and even atomic vectors. The dim, nrow, and ncol functions are also generic, but they are only applicable to rectangular, layered, or tabular data.\n\n\n\n\n\n\nExercise (OPTIONAL)\n\n\n\nTibbles include a lot of meta-data about themselves when they are printed. Which of the above functions would you have to use to find out the same information about a regular data frame?"
  },
  {
    "objectID": "lessons/lesson07_lists_and_tibbles.html#positive-positional-subsetting",
    "href": "lessons/lesson07_lists_and_tibbles.html#positive-positional-subsetting",
    "title": "Lesson 7: Lists and Tibbles",
    "section": "Positive Positional Subsetting",
    "text": "Positive Positional Subsetting\n\nLists\nLet’s extract the eighth element (my age) of a non-atomic vector:\n\nDrGabriel_ls[8]\n\n$Age\n[1] 31\n\n\nRemember that [ takes in the position of the element of the vector and returns the contents at that position. One of the special things about non-atomic vectors (lists) is that their sub-contents are themselves lists.\n\nclass(DrGabriel_ls[8])\n\n[1] \"list\"\n\n\nIn its list form, this value doesn’t help us very much. For instance, we can’t find my age in months with this:\n\nDrGabriel_ls[8] * 12\n\nError in DrGabriel_ls[8] * 12: non-numeric argument to binary operator\n\n\nIn order to extract the contents of the inner list (the contents of the sixth position of DrGabriel_ls), we need to use a second-level extractor:\n\nDrGabriel_ls[[8]]\n\n[1] 31\n\nDrGabriel_ls[[8]] * 12\n\n[1] 372\n\n\nThis is the primary difference between atomic and non-atomic positional subsetting. Consider this figure:\n\nThe original object x is a list (the pepper container), and the first element of x is also a list (x[1]; still the pepper container, but now with only one packet of pepper). The contents of the first element’s inner list is an atomic vector (x[[1]]; the packet of pepper). To extract the contents of the x[[1]] atomic vector (the pepper), we subset one last time. Because x[[1]] itself is atomic, we can subset it by either [ or [[; common standards have use use [ for atomic vectors, however.\n\n\n\n\n\n\nExercises\n\n\n\n\nExtract the first through third elements of the ID vector you created above using the [ function.\nExtract the first through third elements of the ID vector you created above using the [[ function. Does this work? What is different? Why?\n\n\n\n\n\nTibbles\nTo extract the element in the second row and third column from a tibble, we can type (using row, column notation):\n\nheroes_df[2, 3]\n\n# A tibble: 1 × 1\n  alias     \n  <chr>     \n1 Alan Scott\n\n\nTo extract the third and fourth row within the first and third column:\n\nheroes_df[3:4, c(1, 3)]\n\n# A tibble: 2 × 2\n  subject_ID alias       \n  <fct>      <chr>       \n1 115        Peter Parker\n2 027        Bruce Wayne \n\n\nTo extract an entire column:\n\nheroes_df[, 2]\n\n# A tibble: 5 × 1\n  name         \n  <chr>        \n1 Wonder Woman \n2 Green Lantern\n3 Spider-Man   \n4 Batman       \n5 Superman     \n\n\n\n\n\n\n\n\nExercises\n\n\n\n\nExtract the second column for all rows. What is the class of this object? Do you think this is connected to the differences between [ and [[ for a list? Why or why not?\nWhat is the class of the second row, third column of this tibble?\nLook up the help file for the pull() function. How could this be useful?"
  },
  {
    "objectID": "lessons/lesson07_lists_and_tibbles.html#negative-positional-subsetting",
    "href": "lessons/lesson07_lists_and_tibbles.html#negative-positional-subsetting",
    "title": "Lesson 7: Lists and Tibbles",
    "section": "Negative Positional Subsetting",
    "text": "Negative Positional Subsetting\n\nLists\nUsing the same negative subsetting framework, I’m going to “de-identify” my electronic ID card.\n\nDrGabriel_ls[-(1:2)]\n\n$Male\n[1] TRUE\n\n$City\n[1] \"Pembroke Pines\"\n\n$State\n[1] FL\n50 Levels: AL AK AZ AR CA CO CT DE FL GA HI ID IL IN IA KS KY LA ME MD ... WY\n\n$CurrZIP\n[1] 33025\n\n$MovedFrom\n[1] \"TX\"\n\n$Age\n[1] 31\n\n$MaxDegree\n[1] \"PhD\" \"ThD\"\n\n$TimeEmpl\n[1] 2.1\n\n\n\n\n\n\n\n\nExercises\n\n\n\n\nRemove the age and ZIP from your ID vector.\nCan you use the [[ function for negative subsetting with a list? Why not? Hint: think back to the class of the objects returned by the [ function vs the [[ function.\n\n\n\n\n\nTibbles\nFor tibbles, negative subsetting uses the same row, column notation as it does for positive subsetting.\n\nheroes_df[-1, ]\n\n# A tibble: 4 × 8\n  subject_ID name          alias          city  male  heightCM weightKg firstRun\n  <fct>      <chr>         <chr>          <chr> <lgl>    <dbl>    <dbl>    <int>\n1 016        Green Lantern Alan Scott     Capi… TRUE      183.     91.2     1940\n2 115        Spider-Man    Peter Parker   New … TRUE      178.     75.7     1962\n3 027        Batman        Bruce Wayne    Goth… TRUE      188      95.3     1939\n4 001        Superman      Clark Kent / … Metr… TRUE      190.    107.      1938\n\nheroes_df[-c(1, 3), -c(1, 3, 4)]\n\n# A tibble: 3 × 5\n  name          male  heightCM weightKg firstRun\n  <chr>         <lgl>    <dbl>    <dbl>    <int>\n1 Green Lantern TRUE      183.     91.2     1940\n2 Batman        TRUE      188      95.3     1939\n3 Superman      TRUE      190.    107.      1938\n\n\n\n\n\n\n\n\nExercises\n\n\n\n\nCombine postive and negative subsetting to create a table subset comparing the height of Wonder Woman and Green Lantern. Remove all other rows and columns.\nCombine postive and negative subsetting to create a table subset comparing each hero’s city and first publication date. Create a hypothesis to explain what you see."
  },
  {
    "objectID": "lessons/lesson07_lists_and_tibbles.html#boolean-subsetting",
    "href": "lessons/lesson07_lists_and_tibbles.html#boolean-subsetting",
    "title": "Lesson 7: Lists and Tibbles",
    "section": "Boolean Subsetting",
    "text": "Boolean Subsetting\nBecause relational subsetting is Boolean (logical) subsetting with an additional step, we first discuss how logical subsetting rules work for non-atomic vectors. For lists, these rules work the same for lists in one dimension as they do for atomic vectors in one dimension.\nTibbles, however, are different. Recall that tibbles have positional subsetting properties through the row, column syntax and also the positional subsetting properties of lists. These properties hold true for logical subsetting.\n\nRow and Column Subsetting\nWe can create logical atomic vectors of the same lengths as the number of rows and columns of the tibble (as returned by the dim() function).\n\n# Dimension of the tibble:\ndim(heroes_df)\n\n[1] 5 8\n\n# Logical vector to match the rows (keep the lat two):\nc(rep(FALSE, 3), rep(TRUE, 2))\n\n[1] FALSE FALSE FALSE  TRUE  TRUE\n\n# Logical vector to match the columns (keep the last four):\nrep(c(FALSE, TRUE), each = 4)\n\n[1] FALSE FALSE FALSE FALSE  TRUE  TRUE  TRUE  TRUE\n\n# Subset the tibble:\nheroes_df[c(rep(FALSE, 3), rep(TRUE, 2)), rep(c(FALSE, TRUE), each = 4)]\n\n# A tibble: 2 × 4\n  male  heightCM weightKg firstRun\n  <lgl>    <dbl>    <dbl>    <int>\n1 TRUE      188      95.3     1939\n2 TRUE      190.    107.      1938\n\n\n\n\nList Subsetting\nBecause tibbles are also lists, we can subset the columns of the tibble using a logical atomic vector with length equal to the number of columns. This code will let us keep every other column starting with the second column:\n\nheroes_df[rep(c(FALSE, TRUE), times = 4)]\n\n# A tibble: 5 × 4\n  name          city          heightCM firstRun\n  <chr>         <chr>            <dbl>    <int>\n1 Wonder Woman  Gateway City      184.     1941\n2 Green Lantern Capitol City      183.     1940\n3 Spider-Man    New York City     178.     1962\n4 Batman        Gotham            188      1939\n5 Superman      Metropolis        190.     1938\n\n\n\n\n\n\n\n\nExercise\n\n\n\nSubset the tibble by every other row and column.\n\n\n\n\nCharacter Set Membership\nFor numeric and logical atomic vectors, we can make easy Boolean comparisons. “Is this value TRUE?” “Are these numbers less than 0?” Unfortunately, comparisons for character vectors are not as easy. We need new functions to measure if one character string belongs to a character vector. However, character set membership operators share this with other comparison operators: they must return logical values.\n\nExact Matching\nIf we want to find if one string is an element of a set of strings exactly, we can use the “infix” operator: %in%. This is helpful if you have many possible spellings or abbriviations of the same word or idea:\n\n\"Florida\" %in% c(\"FL\", \"Fl\", \"fl\", \"Florida\", \"florida\")\n\n[1] TRUE\n\n\"Georgia\" %in% c(\"FL\", \"Fl\", \"fl\", \"Florida\", \"florida\")\n\n[1] FALSE\n\n\nThis matching is exact: the character string on the left of %in% must match exactly to one of the elements of the character vector on the right. This means the following checks will fail:\n\n\"Florida State\" %in% c(\"FL\", \"Fl\", \"fl\", \"Florida\", \"florida\")\n\n[1] FALSE\n\n\"Florida\" %in% c(\"FL\", \"Fl\", \"fl\", \"State of Florida\", \"florida\")\n\n[1] FALSE\n\n\n\n\nPartial Matching\nIf we want to find if a string is part of another string, we use the string detection function: str_detect(). This function is from the stringr package, which is part of the tidyverse.\n\nstr_detect(\n  string = c(\"FL\", \"Fl\", \"fl\", \"State of Florida\", \"florida\", \"Florida\"),\n  pattern = \"Florida\"\n)\n\n[1] FALSE FALSE FALSE  TRUE FALSE  TRUE\n\n\nWe know that the labels \"State of Florida\" and \"Florida\" match our search, but \"florida\" does not."
  },
  {
    "objectID": "lessons/lesson07_lists_and_tibbles.html#relational-subsetting-for-tibbles",
    "href": "lessons/lesson07_lists_and_tibbles.html#relational-subsetting-for-tibbles",
    "title": "Lesson 7: Lists and Tibbles",
    "section": "Relational Subsetting for Tibbles",
    "text": "Relational Subsetting for Tibbles\nThe tibble uses both the row, column and list subsetting rules, which gives it more flexibility than lists alone. Finally, we can use relational subsetting to get at some powerful results.\n\nNumerical Relationships\nIf we would like to see which superheroes were in print prior to the US involvement in WWII, we will use a numeric comparison of the first print run year vs 1941.\n\n# Step 1: subset the first print year of the superheroes:\nheroes_df[[\"firstRun\"]]\n\n[1] 1941 1940 1962 1939 1938\n\n# Step 2: compare these print years to the start of WWII for the US:\nheroes_df[[\"firstRun\"]] <= 1941\n\n[1]  TRUE  TRUE FALSE  TRUE  TRUE\n\n# Step 3: subset the tibble to return only the pre-war heroes\nheroes_df[heroes_df[[\"firstRun\"]] <= 1941, ]\n\n# A tibble: 4 × 8\n  subject_ID name          alias          city  male  heightCM weightKg firstRun\n  <fct>      <chr>         <chr>          <chr> <lgl>    <dbl>    <dbl>    <int>\n1 008        Wonder Woman  Diana Prince   Gate… FALSE     184.     74.8     1941\n2 016        Green Lantern Alan Scott     Capi… TRUE      183.     91.2     1940\n3 027        Batman        Bruce Wayne    Goth… TRUE      188      95.3     1939\n4 001        Superman      Clark Kent / … Metr… TRUE      190.    107.      1938\n\n\n\n\nCharacter Relationships\nHow many heroes include the name “man” somewhere in their name? (We will learn more about the str_detect() function in the stringr:: lesson; for now, note that it returns TRUE or FALSE values.)\n\n# Step 1: subset the names of the superheroes:\nheroes_df[[\"name\"]]\n\n[1] \"Wonder Woman\"  \"Green Lantern\" \"Spider-Man\"    \"Batman\"       \n[5] \"Superman\"     \n\n# Step 2: compare these names to the character strings \"man\":\nstr_detect(string = heroes_df[[\"name\"]], pattern = \"man\")\n\n[1]  TRUE FALSE FALSE  TRUE  TRUE\n\n# Step 3: subset the tibble to return only the heroes with \"man\" in their names\nheroes_df[str_detect(string = heroes_df[[\"name\"]], pattern = \"man\"), ]\n\n# A tibble: 3 × 8\n  subject_ID name         alias           city  male  heightCM weightKg firstRun\n  <fct>      <chr>        <chr>           <chr> <lgl>    <dbl>    <dbl>    <int>\n1 008        Wonder Woman Diana Prince    Gate… FALSE     184.     74.8     1941\n2 027        Batman       Bruce Wayne     Goth… TRUE      188      95.3     1939\n3 001        Superman     Clark Kent / K… Metr… TRUE      190.    107.      1938\n\n\n\n\n\n\n\n\nExercises\n\n\n\n\nIn the example above, why couldn’t we find Spider-Man?\nFind all the heroes who’s home city has the word “City” in it.\nBecause the columns of a tibble are usually a 1-D atomic vector, we can subset 1-D atomic vectors using Steps 2 and 3 only. Find who among my siblings are under 25 years old (use the named ages_int vector from last lesson).\nUse compound logic (recall the AND and OR symbols) to find the superheroes with less than average height and greater than average weight.\nRecall that code-writing best practices include that lines should not be longer than 80 characters wide. Your solution for the last question was most likely longer than that. What can you do to make the lines shorter and more easily readable?"
  },
  {
    "objectID": "lessons/lesson07_lists_and_tibbles.html#lists-2",
    "href": "lessons/lesson07_lists_and_tibbles.html#lists-2",
    "title": "Lesson 7: Lists and Tibbles",
    "section": "Lists",
    "text": "Lists\nThe rules for 1-dimensional non-atomic vectors are very different. The main difference is that most relational functions, such as str_detect(), %in%, <, and others don’t always work on lists.\n\n\n\n\n\n\nExercises\n\n\n\n\nAttempt to use logical subsetting to extract the following components of your ID vector:\n\nAny elements less than 150 (this is a good cutoff for age)\nYour last name using the %in% function\nYour last name using the str_detect function\nYour last name using the == function\n\nFor the last three parts of Exercise 1, what were the major differences?\nWhen you received warning or error messages, can you explain what they mean?"
  },
  {
    "objectID": "lessons/lesson07_lists_and_tibbles.html#lists-3",
    "href": "lessons/lesson07_lists_and_tibbles.html#lists-3",
    "title": "Lesson 7: Lists and Tibbles",
    "section": "Lists",
    "text": "Lists\nWe know that the electronic ID list we made has names, but we can check to be sure:\n\nnames(DrGabriel_ls)\n\n [1] \"Surname\"   \"Forename\"  \"Male\"      \"City\"      \"State\"     \"CurrZIP\"  \n [7] \"MovedFrom\" \"Age\"       \"MaxDegree\" \"TimeEmpl\" \n\n\nTherefore, we can extract the contents of this list by position name:\n\nDrGabriel_ls[\"Age\"]\n\n$Age\n[1] 31\n\n\n\n\n\n\n\n\nExercises\n\n\n\n\nExtract the last name of your ID object with the [ function. What is the class of this object?\nExtract the last name of your ID object with the [[ function. What is the class of this object?\nIf you need to extract your first name, last name, and age, should you use the [ or the [[ function? Why?"
  },
  {
    "objectID": "lessons/lesson07_lists_and_tibbles.html#tibbles-2",
    "href": "lessons/lesson07_lists_and_tibbles.html#tibbles-2",
    "title": "Lesson 7: Lists and Tibbles",
    "section": "Tibbles",
    "text": "Tibbles\nAll of the same name-based extraction / subsetting rules that work on the names of list elements work on tibbles, because a tibble is a type of list (check this with the typeof() function):\n\nheroes_df[\"alias\"]\n\n# A tibble: 5 × 1\n  alias              \n  <chr>              \n1 Diana Prince       \n2 Alan Scott         \n3 Peter Parker       \n4 Bruce Wayne        \n5 Clark Kent / Kal-El\n\nheroes_df[[\"alias\"]]\n\n[1] \"Diana Prince\"        \"Alan Scott\"          \"Peter Parker\"       \n[4] \"Bruce Wayne\"         \"Clark Kent / Kal-El\"\n\n\nHowever, we also get the column-based subsetting options too!\n\nheroes_df[, \"alias\"]\n\n# A tibble: 5 × 1\n  alias              \n  <chr>              \n1 Diana Prince       \n2 Alan Scott         \n3 Peter Parker       \n4 Bruce Wayne        \n5 Clark Kent / Kal-El\n\n\n\n\n\n\n\n\nExercises\n\n\n\n\nExtract the names of the heroes with the [ function. What is the class of this object?\nExtract the names of the heroes with the [ function using row, column syntax. What is the class of this object?\nExtract the names of the heroes with the [[ function. What is the class of this object?\nIf you need to extract the heroes’ name, height, and weight, should you use the [ or the [[ function? Why?\nUsing both [ and [[, extract from the tibble a column that doesn’t exist, \"Publisher\" for instance. What happens in these two cases?"
  },
  {
    "objectID": "lessons/lesson07_lists_and_tibbles.html#the-operator",
    "href": "lessons/lesson07_lists_and_tibbles.html#the-operator",
    "title": "Lesson 7: Lists and Tibbles",
    "section": "The $ Operator",
    "text": "The $ Operator\nThere is one other subsetting operator that only works for name-based subsetting of non-atomic vectors, the $ function. We can subset any object of type list with the $ function in the following manner:\n\n# From a list\nDrGabriel_ls$MaxDegree\n\n[1] \"PhD\" \"ThD\"\n\n# From a tibble\nheroes_df$name\n\n[1] \"Wonder Woman\"  \"Green Lantern\" \"Spider-Man\"    \"Batman\"       \n[5] \"Superman\"     \n\n\nWhat is the class of the object returned by $?\n\nclass(heroes_df$city)\n\n[1] \"character\"\n\n\nIn this case, this is similar to the output of the pull() function we saw earlier.\n\nSymbol Objects\nThis function is very different. Instead of taking in the name of the element as a character string, it takes in the name as a symbol. If you remember our flowchart on objects from last class, recall that there was a small box connecting “Functions” to “Vectors” labelled “Languages”; symbols are language objects: they help R connect functions to vectors. You have technically used symbols since the second day of class. Consider this example:\n\nmyIntegers <- 1:10\nmean(x = myIntegers)\n\nNotice that I did not type myIntegers in quotes (as \"myIntegers\"). When R sees a reference to something other than all letters, crazy symbols, or TRUE / FALSE, R interprets what you typed as a symbol to be evaluated (think back to our rules for naming objects in lesson 5). R will look in your Global Environment for the object named what you typed. In the example above, R isn’t taking the mean of the letters myIntegers, but rather replacing that symbol with the atomic vector 1:10.\n\n\nSymbol Subsetting\nWe have seen this behaviour before, when we created plots with ggplot. The aes() function took in displ and hwy as symbols, and looked for objects with those names in the supplied mpg data set instead of in the Global environment. Because this is a very complex but powerful tool, we will return to it in a few lessons.\n\n\n\n\n\n\nExercises\n\n\n\n\nExtract the non-existent Publisher column from the heroes_df tibble using the $ function. What happens?\nFind all the heroes who’s home city has the word “City” in it using the [ or the $ functions (instead of the [[ function). Remember that $ takes in symbols instead of character strings. What is different? Did you expect some of this behaviour based on the list exercises?"
  },
  {
    "objectID": "lessons/lesson06_atomic_vectors.html",
    "href": "lessons/lesson06_atomic_vectors.html",
    "title": "Lesson 6: Atomic Vectors",
    "section": "",
    "text": "What did we learn last class?\n\nNaming Objects\nMy First R Function\nFormatting Scripts\nOrganizing your Files\nRStudio Projects"
  },
  {
    "objectID": "lessons/lesson06_atomic_vectors.html#review-1",
    "href": "lessons/lesson06_atomic_vectors.html#review-1",
    "title": "Lesson 6: Atomic Vectors",
    "section": "Review",
    "text": "Review\nWe can assign a series of values to a vector using the c() function. For example we can create a vector of animal weights and assign it to a new object weight_g:\n\nweight_g <- c(50, 60, 65, 82)\nweight_g\n\n[1] 50 60 65 82\n\n\nA vector can also contain characters:\n\nanimals <- c(\"mouse\", \"rat\", \"dog\")\nanimals\n\n[1] \"mouse\" \"rat\"   \"dog\"  \n\n\nRembember that the quotes around “mouse”, “rat”, etc. are essential here. Without these quotes, R will assume there are objects named mouse, rat, and dog. Unless these objects exist in the Global Environment or some of the other environments you have loaded (they shouldn’t), you will get an error message.\n\nanimals <- c(mouse, rat)\n\nError in eval(expr, envir, enclos): object 'mouse' not found\n\n\nYou can also use the c() function to add other elements to one of your existing vectors:\n\n# add to the end of the vector\nweight_g <- c(weight_g, 90) \n# add to the beginning of the vector\nweight_g <- c(30, weight_g) \nweight_g\n\n[1] 30 50 60 65 82 90\n\n\nIn the first line, we take the original vector weight_g, add the value 90 to the end of it, and save the result back into weight_g. Then we add the value 30 to the beginning, again saving the result back into weight_g. While we can do this over and over again to grow a vector, there are usually better ways to make a bigger vector (more on this in our lesson on functions).\n\n\n\n\n\n\nExercise\n\n\n\nWhen you execute the code animals <- c(mouse, rat), R returns an error complaining about the object mouse but not rat. Why?"
  },
  {
    "objectID": "lessons/lesson06_atomic_vectors.html#atomic-classes",
    "href": "lessons/lesson06_atomic_vectors.html#atomic-classes",
    "title": "Lesson 6: Atomic Vectors",
    "section": "Atomic Classes",
    "text": "Atomic Classes\nThe basic atomic classes in R (in order of complexity) are\n\nlogical: This is the most basic type of information that can be stored in R. A vector with elements of class logical is a vector of only TRUE or FALSE values.\ninteger: This is the second-most basic type of information. An integer vector is a vector of positive or negative counting numbers (and 0).\nnumeric: This is the class for the Real numbers in R. Any object of class integer is necessarily also an object of class numeric, but the reverse is not true.\ncomplex: This class allows us to represent complex numbers (real and imaginary parts; e.g., 1 + 4i). In the health sciences, we won’t use objects of this class very often, if ever.\ncharacter: This is the most complex class of atomic information. This class ensures that the information you type into R stays marked with the keystrokes you typed to enter it. Therefore, \"10\" is not recorded as the integer 10, or the real number 10.000000…, but rather the combined keystrokes of the “1” and “0” keys on your keyboard (to be very technical, “1” and “0” are stored with the ASCII code 049 and 048, respectively, or perhaps as a UTF-8 encoded value).\n\nThere is one other class below logical in complexity: raw. It measures bits of computer information. We do not use objects of this class."
  },
  {
    "objectID": "lessons/lesson06_atomic_vectors.html#examples",
    "href": "lessons/lesson06_atomic_vectors.html#examples",
    "title": "Lesson 6: Atomic Vectors",
    "section": "Examples",
    "text": "Examples\n\n“Names and Ages” Vectors\nWe can create a vector of ages and a vector of names for me and my siblings.\n\nages_int   <- c(31, 29, 27, 25, 23, 21)\nnames_char <- c(\n  \"Gabriel\", \"Britni\", \"Michael\", \"Christiana\", \"Olivia\", \"Hannah\"\n)\n\nages_int\n\n[1] 31 29 27 25 23 21\n\n\n\n\n“User ID” Vector\nLet’s consider another example. Suppose we need to create an electronic ID card for ourselves. What information could we put on the ID? We want things like our name, our age, where we live, etc. The medical school wants to know where we’re from, our highest degrees earned, and how long we’ve worked here. We can create a vector with all of this information:\n\n# Build the vector\nDrGabriel <- c(\n  \"Odom\", \"Gabriel\", \"PhD, ThD\", 31, \"Pembroke Pines\", \"FL\", \"TX\", 2.1\n  )\n\n# Inspect the Vector\nDrGabriel\n\n[1] \"Odom\"           \"Gabriel\"        \"PhD, ThD\"       \"31\"            \n[5] \"Pembroke Pines\" \"FL\"             \"TX\"             \"2.1\""
  },
  {
    "objectID": "lessons/lesson06_atomic_vectors.html#positive-position-subsetting",
    "href": "lessons/lesson06_atomic_vectors.html#positive-position-subsetting",
    "title": "Lesson 6: Atomic Vectors",
    "section": "Positive Position Subsetting",
    "text": "Positive Position Subsetting\nThe main idea of positive position subsetting is you ask for the positions of the atomic vector based on what you want to keep.\nTo extract the third element of an atomic vector:\n\nnames_char[3]\n\n[1] \"Michael\"\n\n\nRemember that everything in R is an object. The bracket, [, is an object—specifically a function: it takes in the position of the element of the vector and returns the contents at that position.\nTo extract more than one element at once by position, we subset the vector by an atomic vector of integers. To extract names of the first and third sibling:\n\nnames_char[c(1, 3)]\n\n[1] \"Gabriel\" \"Michael\"\n\n\n\n\n\n\n\n\nExercise\n\n\n\nExtract the names of my sisters. Extract their ages from the ages_int vector."
  },
  {
    "objectID": "lessons/lesson06_atomic_vectors.html#negative-position-subsetting",
    "href": "lessons/lesson06_atomic_vectors.html#negative-position-subsetting",
    "title": "Lesson 6: Atomic Vectors",
    "section": "Negative Position Subsetting",
    "text": "Negative Position Subsetting\nThe main idea of negative position subsetting is you ask for the positions of the atomic vector based on what you want to discard. That is, we specify which entries we don’t want. We specify the elements we don’t want with the negative sign.\nTo remove my oldest sister’s name from the names_char (the second name in the vector), we subset the vector with a -2.\n\nnames_char[-2]\n\n[1] \"Gabriel\"    \"Michael\"    \"Christiana\" \"Olivia\"     \"Hannah\"    \n\n\n\n\n\n\n\n\nExercise\n\n\n\nRemove me and my brother’s names from the names_char vector. Where did you have to put the negative sign? Could you put it somewhere else?"
  },
  {
    "objectID": "lessons/lesson06_atomic_vectors.html#boolean-subsetting",
    "href": "lessons/lesson06_atomic_vectors.html#boolean-subsetting",
    "title": "Lesson 6: Atomic Vectors",
    "section": "Boolean Subsetting",
    "text": "Boolean Subsetting\nThe main idea of logical or Boolean subsetting is to answer TRUE or FALSE to whether or not you would like to keep a set of values from the atomic vector. The other methods had you specify the vector element(s) you would like to keep or the vector element(s) you would like to discard. However, the Boolean subsetting method has you create a logical vector of the same length as dimension you are interested in subsetting over, and passing it through the [ function.\n\nReview: Logic and Logical Operators\nRecall that logical values in R are represented by the reserved symbols TRUE and FALSE. Here is a nice picture (shamelessly borrowed from R for Data Science). \n\nAND, OR, and NOT\nThere are three logical operators we will commonly employ: AND, OR, and NOT.\n\nx <- TRUE\ny <- FALSE\n\n# OR: Are either x or y TRUE?\nx | y \n\n[1] TRUE\n\n# AND: Are both x and y TRUE?\nx & y \n\n[1] FALSE\n\n# NOT: What is the opposite of x?\n!x    \n\n[1] FALSE\n\n\n\n\nSet Membership and XOR\nThere are two more operators to think about, but they are shorthands for the primary three.\nThe XOR operator asks “are x or y TRUE, but not both?”\n\n(x | y) & !(x & y)\n\n[1] TRUE\n\nxor(x, y)\n\n[1] TRUE\n\n\nThe set membership operator, %in%, is also known as the “infix” operator. It checks if a value is included in a set of values.\n\nA <- 2\nA == 1 | A == 2 | A == 3\n\n[1] TRUE\n\nA %in% c(1, 2, 3)\n\n[1] TRUE\n\n\n\n\n\nRepeating Values\nBefore we move on to the specific vector-type examples, it is helpful to have a function to repeat values. If you would like to create a vector of six true values in a row, we can use the rep() function.\n\nrep(TRUE, times = 6)\n\n[1] TRUE TRUE TRUE TRUE TRUE TRUE\n\n\nWe can combine this with the c() function for very powerful results.\n\n\n\n\n\n\nExercises\n\n\n\n\nUse the c() function with the rep() function to repeat the vector TRUE, FALSE, FALSE four times.\nCheck the help file of the rep() function to create the vector below:\n\n1 1 1 1 1 2 2 2 2 2 3 3 3 3 3 4 4 4 4 4 5 5 5 5 5\n\nNow create this vector:\n\n1 2 2 3 3 3 4 4 4 4 5 5 5 5 5\n\n\n\n\nLogical Subsetting\nWe want to keep the ages for every other child starting after me:\n\nages_int\n\n[1] 31 29 27 25 23 21\n\nages_int[rep(c(FALSE, TRUE), times = 3)]\n\n[1] 29 25 21\n\n\n\n\n\n\n\n\nExercises\n\n\n\n\nUse Boolean subsetting with the rep() function to extract the last three ages.\nUse Boolean subsetting to “de-identify” your electronic ID vector."
  },
  {
    "objectID": "lessons/lesson06_atomic_vectors.html#id-example-part-2",
    "href": "lessons/lesson06_atomic_vectors.html#id-example-part-2",
    "title": "Lesson 6: Atomic Vectors",
    "section": "ID Example, Part 2",
    "text": "ID Example, Part 2\nHow can we make our ID vector better? Well, we have discussed what these fields are, but we haven’t formally named them. Let’s do that:\n\n# Re-build\nDrGabriel <- c(\n  Surname = \"Odom\",\n  FirstName = \"Gabriel\",\n  HighestDegrees = \"PhD, ThD\",\n  Age = 31,\n  City = \"Pembroke Pines\",\n  State = \"FL\",\n  MovedFrom = \"TX\",\n  timeEmployed = 2.1 # since Aug 2017\n)\n\n# Inspect\nDrGabriel\n\n         Surname        FirstName   HighestDegrees              Age \n          \"Odom\"        \"Gabriel\"       \"PhD, ThD\"             \"31\" \n            City            State        MovedFrom     timeEmployed \n\"Pembroke Pines\"             \"FL\"             \"TX\"            \"2.1\" \n\n\nWhat if I want my employment in years instead of months?\n\nDrGabriel[8] * 12\n\nError in DrGabriel[8] * 12: non-numeric argument to binary operator\n\n\nWe immediately see an error: non-numeric argument to binary operator. What caused this? R says my age is non-numeric, but we clearly typed a number. What’s going on?\n\n\n\n\n\n\nExercise\n\n\n\nCreate an ID vector with the same components as mine for yourself and your neighbour."
  },
  {
    "objectID": "lessons/lesson06_atomic_vectors.html#vector-helper-functions",
    "href": "lessons/lesson06_atomic_vectors.html#vector-helper-functions",
    "title": "Lesson 6: Atomic Vectors",
    "section": "Vector Helper Functions",
    "text": "Vector Helper Functions\nIn order to answer these questions, we need to use some helper functions. There are many functions that allow you to inspect the contents of a vector. The error above tells us that one of the values in DrGabriel[8] / 12 is non-numeric. We can use the class() function to tell us what type of information is stored in DrGabriel[8]. One other function you can use is typeof(). This function measures how objects are stored in R’s allocated memory. For most of the atomic vectors, these are identical.\n\nclass(DrGabriel[8])\n\n[1] \"character\"\n\ntypeof(DrGabriel[8])\n\n[1] \"character\"\n\n\n\n\n\n\n\n\nExercise\n\n\n\nObjects of the class numeric have two storage modes (as returned by the typeof() function). What are they? What do you think these names mean, and how might they be related to the storge mode (how the computer stores objects)?\n\n\nlength() tells you how many elements are in a particular vector:\n\nlength(weight_g)\n\n[1] 6\n\nlength(animals)\n\n[1] 3\n\n\nThe function str() provides an overview of the structure of an object and its elements. This is one of the most useful R functions you can learn, but it really shines when working with large and complex (non-atomic) objects. We will cover those next lesson.\n\nstr(DrGabriel)\n\n Named chr [1:8] \"Odom\" \"Gabriel\" \"PhD, ThD\" \"31\" \"Pembroke Pines\" \"FL\" ...\n - attr(*, \"names\")= chr [1:8] \"Surname\" \"FirstName\" \"HighestDegrees\" \"Age\" ...\n\nstr(animals)\n\n chr [1:3] \"mouse\" \"rat\" \"dog\""
  },
  {
    "objectID": "lessons/lesson06_atomic_vectors.html#type-promotion",
    "href": "lessons/lesson06_atomic_vectors.html#type-promotion",
    "title": "Lesson 6: Atomic Vectors",
    "section": "Type Promotion",
    "text": "Type Promotion\nWe see that when we created the DrGabriel vector, the numeric age and tenure information was promoted to have class character. When we included both numeric and character information in the same atomic vector, R coerced the numeric information to match the type of information with the highest complexity (the characters). If you ever try to “mix” object of different complexities in an atomic vector, the elements of lower complexity will be “promoted” by force to match the highest complexity level. This is because basic vectors in R must be atomic: all elements they contain must have the same class. For example:\n\nclass(TRUE)\n\n[1] \"logical\"\n\nclass(c(TRUE, 1L))\n\n[1] \"integer\"\n\nclass(c(TRUE, 1L, 2.1))\n\n[1] \"numeric\"\n\nclass(c(TRUE, 1L, 2.1, \"yeeeeeaaaaaaaaaaaahhhhhhhh\"))\n\n[1] \"character\"\n\n\n\n\n\n\n\n\nExercise\n\n\n\nRecall the logical operators. Explain R’s results for the following:\n\n1 == TRUE\n\"1\" == TRUE\n1 == \"1\"\n!1\n!0\n\nHint: it may be helpful to combine some of these values into a single vector in order to see how R coerces their classes."
  },
  {
    "objectID": "lessons/lesson06_atomic_vectors.html#finding-attributes",
    "href": "lessons/lesson06_atomic_vectors.html#finding-attributes",
    "title": "Lesson 6: Atomic Vectors",
    "section": "Finding Attributes",
    "text": "Finding Attributes\nWe use the attributes() function to find out what the attributes of an object are.\n\nattributes(animals)\n\nNULL\n\nattributes(DrGabriel)\n\n$names\n[1] \"Surname\"        \"FirstName\"      \"HighestDegrees\" \"Age\"           \n[5] \"City\"           \"State\"          \"MovedFrom\"      \"timeEmployed\"  \n\n\nCurrently, the attributes of the animals object is NULL (this is how R describes something that is completely empty; this is not the same as R’s missing data tag, NA, that we saw earlier). However, the attributes of the DrGabriel object is not empty. In fact, it is a new type of data structure called a list that we will discuss in the next lesson.\n\n\n\n\n\n\nExercise\n\n\n\nFind the structure of the attributes of your ID vector."
  },
  {
    "objectID": "lessons/lesson06_atomic_vectors.html#creating-attributes",
    "href": "lessons/lesson06_atomic_vectors.html#creating-attributes",
    "title": "Lesson 6: Atomic Vectors",
    "section": "Creating Attributes",
    "text": "Creating Attributes\nOne cool thing about attributes is that you can create your own at any time. Let’s create a playing card object. We want the value of the object to be a single number, but we want the attributes to mark the suit of the card.\nWe can create or edit attributes with the attr() function. This function uses a special form of the assignment syntax. We have seen objectName <- value before. For attributes, we have to use a modified syntax because they are part of another object\n\ncard <- 2\nattr(card, \"suit\") <- \"hearts\"\n\ncard\n\n[1] 2\nattr(,\"suit\")\n[1] \"hearts\"\n\n\nThis code says to assign the character \"hearts\" to a container named \"suit\" that is itself contained entirely within another object, the object card.\n\n\n\n\n\n\nExercises\n\n\n\n\nFind the type and class of 1L and 1. What does the L do?\nAdd an attribute to your ID vector. It can be anything you like."
  },
  {
    "objectID": "lessons/lesson06_atomic_vectors.html#classes-are-attribute-dependent",
    "href": "lessons/lesson06_atomic_vectors.html#classes-are-attribute-dependent",
    "title": "Lesson 6: Atomic Vectors",
    "section": "Classes are Attribute-Dependent",
    "text": "Classes are Attribute-Dependent\nOne of the ways that R makes new classes available to you is by giving a normal atomic object a new set of attributes.\n\nExample\nLet’s make a vector of two pairs of names:\n\nsuperheroes <- c(\n  \"Wonder Woman\", \"Green Lantern\", \"Superman\", \"Diana Prince\", \"Alan Scott\",\n  \"Clark Kent\"\n)\n\nYou may be wondering why Wonder Woman’s name isn’t paired with her alias (Diana Prince). We will fix that momentarily.\nWhat is the current class and type of this vector?\n\nclass(superheroes)\n\n[1] \"character\"\n\ntypeof(superheroes)\n\n[1] \"character\"\n\n\nOne of the special attributes that R objects can have is dimension. We can set the dimension of our superheroes vector by:\n\nattr(superheroes, \"dim\") <- c(3, 2)\nsuperheroes\n\n     [,1]            [,2]          \n[1,] \"Wonder Woman\"  \"Diana Prince\"\n[2,] \"Green Lantern\" \"Alan Scott\"  \n[3,] \"Superman\"      \"Clark Kent\"  \n\n\nNotice that adding a dimension attribute to a character vector puts the same data into a rectangular form. What is the class of this vector now?\n\nclass(superheroes)\n\n[1] \"matrix\" \"array\" \n\ntypeof(superheroes)\n\n[1] \"character\"\n\n\nWe can then see that many of the more exotic types of data are simple types with additional attributes. In R, matrices are just atomic vectors with a dim attribute.\n\n\n\n\n\n\nExercise\n\n\n\nLook in the help file for the attr() function. What are some of the other “special” attributes that might change how R treats an atomic vector?"
  },
  {
    "objectID": "lessons/lesson06_atomic_vectors.html#missing-data-in-atomic-vectors",
    "href": "lessons/lesson06_atomic_vectors.html#missing-data-in-atomic-vectors",
    "title": "Lesson 6: Atomic Vectors",
    "section": "Missing Data in Atomic Vectors",
    "text": "Missing Data in Atomic Vectors\nMissing values in R are represented by NA: not -999, ?, \" \", \".\", or even NaN. When you import any data into R, pay attention to the missing value codes from other data analysis software. R treats missing values (the NAs) as a statement saying “I don’t know”. Also, understand that missing values are “contagious” in R. Here are some examples:\n\nNA < 3    # Is something I don't know less than 3? I don't know.\n\n[1] NA\n\nNA * 2    # What is \"I don't know\" multiplied by 2? I don't know.\n\n[1] NA\n\nNA & TRUE # Are these both TRUE? I don't know.\n\n[1] NA\n\nNA | TRUE # Are either of these TRUE? Yes, one of them is TRUE.\n\n[1] TRUE\n\nNA == NA  # Is something I don't know equal to something else I don't know? I don't know.\n\n[1] NA\n\nis.na(NA) # Is this something we don't know? Yes.\n\n[1] TRUE\n\n\n\nReview: Atomic Vector Types\nBecause there are multiple types of atomic data, there are technically multiple types of NA. Recall the atomic data types:\n\nlogical: This is the most basic type of information that can be stored in R. A vector with elements of class logical is a vector of only TRUE or FALSE values.\ninteger: This is the second-most basic type of information. An integer vector is a vector of positive or negative counting numbers (and 0).\nnumeric: This is the class for the Real numbers in R. Any object of class integer is necessarily also an object of class numeric, but the reverse is not true.\ncharacter: This is the most complex class of atomic information. This class ensures that the information you type into R stays marked with the keystrokes you typed to enter it. Therefore, \"10\" is not recorded as the integer 10, or the real number 10.000000…, but rather the combined keystrokes of the “1” and “0” keys on your keyboard (to be very technical, “1” and “0” are stored with the ASCII code 049 and 048, respectively, or perhaps as a UTF-8 encoded value).\n\n\n\nType-Specific Missing Values\nBecause we have four major atomic types, we have four ways that data from atomic vectors could be missing. They all start with NA.\n\nNA: This is the missing value marker for a logical vector.\nNA_integer_: This is the missing value marker for an integer vector.\nNA_real_: This is the missing value marker for a double vector. Remember that numeric vectors have two types: integer or double. This missing value breaks with the naming convention, but I don’t know why.\nNA_character_: This is the missing value marker for a character vector.\n\n\n\n\n\n\n\nExercise\n\n\n\nConfirm with both the typeof() and class() functions that these missing values have the types and classes that they should.\n\n\n\n\nArithmetically-Induced “Missing” Values\nThere are some times that the results of a function are mathematically “missing” (I am putting this word in quotes because it’s not true; the values aren’t missing, people just think they are). For instance, from algebra we remember that anything divided by 0 does not exist. It’s not that this value is “missing”, it’s that this value cannot exist by definition.\nHere is how R handles special arthimetically-induced “missingness”:\n\nlog(-1)\n\n[1] NaN\n\n1 / (0 ^ 2)\n\n[1] Inf\n\n-1 / (0 ^ 2)\n\n[1] -Inf\n\n\n*Note: most computer languages differ in how they handle the quantity 1 / 0. R, Mathematica, and FORTRAN treat it as Inf; C++ treats it as a “floating point exception”; Python has a special class of results to handle these cases called a ZeroDivisionError; SAS issues a warning and replaces the value with the missing value symbol, .. Overall, you shouldn’t be dividing by 0 very often, but just be aware that these exceptions in computer arithmetic can trip you up."
  },
  {
    "objectID": "lessons/lesson06_atomic_vectors.html#missing-values-in-non-atomic-vector-types",
    "href": "lessons/lesson06_atomic_vectors.html#missing-values-in-non-atomic-vector-types",
    "title": "Lesson 6: Atomic Vectors",
    "section": "Missing Values in Non-Atomic Vector Types",
    "text": "Missing Values in Non-Atomic Vector Types\nWe will cover non-atomic vectors in the next lesson, but I want to give a brief comment about the NULL value we saw earlier. Because non-atomic vectors are defined by what behaviour they don’t show, it’s nearly impossible to list all of the types on non-atomic vectors. It would be like trying to define the idea of “cold” without having any idea of what “warm” or “hot” means. Non-atomic vectors are what they are simply because they are not atomic.\nBecause of this, we use the NULL symbol to denote a missing non-atomic value. Recall the attributes of an atomic vector:\n\n# With Attributes\nx1 <- c(height = 73)\nattributes(x1)\n\n$names\n[1] \"height\"\n\n# Without Attributes\nx2 <- 73\nattributes(x2)\n\nNULL\n\n\nWhat is the difference between these two? Recall that attributes are stored as a list, making them non-atomic. Therefore, when attributes are missing or empty, R treats them as NULL. Again, don’t worry so much about this yet, because the next lesson is all about lists (non-atomic data)."
  },
  {
    "objectID": "lessons/lesson04s_examples.html",
    "href": "lessons/lesson04s_examples.html",
    "title": "Lesson 4 Supplement: ggplot Examples",
    "section": "",
    "text": "This chapter is a supplemental chapter to Lesson 04 containing many more ggplot2 examples and a thorough discussion of colour palettes. These examples also make use of some other R packages we haven’t seen yet. If you need some of these packages, make sure to “uncomment” the install.packages() call for the packages you need.\n\n# install.packages(\"Stat2Data\")\n# install.packages(\"RColorBrewer\")\n# install.packages(\"jtools\")\n# install.packages(\"viridis\")\n# install.packages(\"ggthemes\")\n# install.packages(\"xkcd\")\n\nlibrary(Stat2Data)\nlibrary(RColorBrewer)\nlibrary(jtools)\nlibrary(viridis)\nlibrary(xkcd)\nlibrary(ggthemes)\nlibrary(tidyverse)\nset.seed(012922)"
  },
  {
    "objectID": "lessons/lesson04s_examples.html#title-and-related",
    "href": "lessons/lesson04s_examples.html#title-and-related",
    "title": "Lesson 4 Supplement: ggplot Examples",
    "section": "Title (and related)",
    "text": "Title (and related)\nGive your plots informative titles. An informative title helps tell the story of the plot. Here are two examples:\n\nBAD: Relationship between HS GPA and college GPA\n\n\nGOOD: High school GPA is positively related to college GPA\n\nHere’s a title with more information (to show how you can add additional details).\n\nggplot(data = FirstYearGPA) +\n  aes(\n    x = HSGPA, \n    y = GPA, \n    color = as_factor(Male)\n  ) + \n  labs(\n    title = \"High school GPA is positively related to college GPA, \\nespecially for girls\", \n    subtitle = \"Among students at X University\", \n    caption = \"Data from FirstYearGPA in the Stat2Data package\", \n    tag = \"Figure 1\",\n    alt = \"Scatter plot showing the positive relationship between HS GPA and\n    college GPA, colored by student gender\",\n    x = \"High School GPA\",\n    y = \"College GPA\"\n  ) +\n  geom_point() \n\n\n\n\nThat’s a bit much, so let’s just stick with the title going forward.\n\nggplot(data = FirstYearGPA) +\n  aes(\n    x = HSGPA, \n    y = GPA, \n    color = as_factor(Male)\n  )  +\n  labs(\n    title = \"High school GPA is positively related to college GPA, \\nespecially for girls\"\n  ) +\n  geom_point()"
  },
  {
    "objectID": "lessons/lesson04s_examples.html#x-and-y-axis-labels",
    "href": "lessons/lesson04s_examples.html#x-and-y-axis-labels",
    "title": "Lesson 4 Supplement: ggplot Examples",
    "section": "X and Y axis labels",
    "text": "X and Y axis labels\nLet’s change the X and Y axes to be more informative. These aren’t the worst named variables, but you do need to infer that GPA is probably for college. Unless you go look at the information about the dataset – but we want our plot to speak for itself.\n\nggplot(data = FirstYearGPA) +\n  aes(\n    x = HSGPA, \n    y = GPA, \n    color = as_factor(Male)\n  )  +\n  labs(\n    x = \"High school GPA\", \n    y = \"First year college GPA\"\n  ) +\n  geom_point()\n\n\n\n\nYou can also do this using the scale() functions:\n\nggplot(data = FirstYearGPA) +\n  aes(\n    x = HSGPA, \n    y = GPA, \n    color = as_factor(Male)\n  ) + \n  scale_x_continuous(name = \"High school GPA\") +\n  scale_y_continuous(name = \"First year college GPA\") +\n  geom_point()"
  },
  {
    "objectID": "lessons/lesson04s_examples.html#x-and-y-axis-limits",
    "href": "lessons/lesson04s_examples.html#x-and-y-axis-limits",
    "title": "Lesson 4 Supplement: ggplot Examples",
    "section": "X and Y axis limits",
    "text": "X and Y axis limits\nSomething else you might want to do sometimes to provide context for your plot and data is adjust the limits of the axes beyond the values of the data. In this case, it would make it easier to see if the values run the full (potential) range of the variable.\n\nggplot(data = FirstYearGPA) +\n  aes(\n    x = HSGPA, \n    y = GPA, \n    color = as_factor(Male)\n  ) + \n  xlim(0, 4) + \n  ylim(0, 4) +\n  geom_point()\n\nWarning: Removed 1 rows containing missing values (`geom_point()`).\n\n\n\n\n\nYou can also do this using the scale() functions:\n\nggplot(data = FirstYearGPA) +\n  aes(\n    x = HSGPA, \n    y = GPA, \n    color = as_factor(Male)\n  ) + \n  scale_x_continuous(limits = c(2, 4)) +\n  scale_y_continuous(limits = c(2, 4)) +\n  geom_point()\n\nWarning: Removed 3 rows containing missing values (`geom_point()`).\n\n\n\n\n\nEither way, you can see that the values don’t run the full range of potential values. The X axis is probably because they collected data from college students and it’s harder to get into college if you have a very low GPA."
  },
  {
    "objectID": "lessons/lesson04s_examples.html#legend-title-and-labels",
    "href": "lessons/lesson04s_examples.html#legend-title-and-labels",
    "title": "Lesson 4 Supplement: ggplot Examples",
    "section": "Legend title and labels",
    "text": "Legend title and labels\nThe way to change the legend title is not at all obvious. And there are multiple ways to do it.\nThe easiest thing to do is use the labs() function, but there’s not an argument that explicitly has to do with the legend. The argument ties back to how you mapped the variable in the original plot. You can also only change the title of the legend with this function, not the labels.\nIn base_plot_gg, we used color = as_factor(Male) to map color onto the variable Male. So we’ll use color here.\n\nggplot(data = FirstYearGPA) +\n  aes(\n    x = HSGPA, \n    y = GPA, \n    color = as_factor(Male)\n  ) + \n  labs(color = \"Gender\") +\n  geom_point()\n\n\n\n\nA more general way is to use the scale_color_discrete() function, which allows you to change the title and labels. There are several of these functions, all of the same form:\n\nscale_color_discrete()\nscale_fill_discrete()\nscale_linetype_discrete()\nscale_shape_discrete()\nscale_size_discrete()\nscale_alpha_discrete()\n\nUse the appropriate one for your variable type: if you mapped the variable to the fill attribute then use fill; if you mapped the variable to the shape attribute then use shape; etc.\n\nggplot(data = FirstYearGPA) +\n  aes(\n    x = HSGPA, \n    y = GPA, \n    color = as_factor(Male)\n  ) +\n  scale_color_discrete(\n    name = \"Sex\",\n    labels = c(\"Female\", \"Male\")\n  ) +\n  geom_point()\n\n\n\n\n\nggplot(data = FirstYearGPA) +\n  aes(\n    x = HSGPA, \n    y = GPA, \n    color = as_factor(Male)\n  ) +\n  scale_color_discrete(\n    name = \"Sex\",\n    labels = c(\"Female\", \"Male\")\n  ) +\n  geom_point()"
  },
  {
    "objectID": "lessons/lesson04s_examples.html#color-palettes",
    "href": "lessons/lesson04s_examples.html#color-palettes",
    "title": "Lesson 4 Supplement: ggplot Examples",
    "section": "Color palettes",
    "text": "Color palettes\n\nset theme for whole document\nAdd titles\nChanging axis, legend, and other labels\nText, size, font, color, etc.\nModifying background colors\nRotating objects\nOrdering variable options (alphabetical, increasing, etc.)"
  },
  {
    "objectID": "lessons/lesson04s_examples.html#changing-the-color-palette",
    "href": "lessons/lesson04s_examples.html#changing-the-color-palette",
    "title": "Lesson 4 Supplement: ggplot Examples",
    "section": "Changing the color palette",
    "text": "Changing the color palette\nThe default colors are fine. They’re easy to distinguish (for me), but they might not work well for someone who is color blind."
  },
  {
    "objectID": "lessons/lesson04s_examples.html#color-blind-friendly-color-palettes",
    "href": "lessons/lesson04s_examples.html#color-blind-friendly-color-palettes",
    "title": "Lesson 4 Supplement: ggplot Examples",
    "section": "Color blind friendly color palettes",
    "text": "Color blind friendly color palettes\nviridis is a widely-used color palette package that has several colorblind-friendly (and black-and-white friendly) color palettes. The vignette for the package, which is kind of the article introducing it and how it works, is here: https://cran.r-project.org/web/packages/viridis/vignettes/intro-to-viridis.html\n\nbase_plot_gg + \n  scale_color_viridis(discrete = TRUE)\n\n\n\n\nI find this a little hard to see. So maybe not the best choice.\nNotice the warning:\n## Scale for 'colour' is already present. Adding another scale for 'colour',\n## which will replace the existing scale.\nThis means that scale_color_viridis() overwrites scale_color_discrete() that we used above to label the legend. Notice that the legend title and labels are gone. We can add those arguments back into the viridis function and get them back.\n\nbase_plot_gg + \n  scale_color_viridis(\n    discrete = TRUE,\n    name = \"Sex\",\n    labels = c(\"Female\", \"Male\")\n  )"
  },
  {
    "objectID": "lessons/lesson04s_examples.html#just-pick-some-colors",
    "href": "lessons/lesson04s_examples.html#just-pick-some-colors",
    "title": "Lesson 4 Supplement: ggplot Examples",
    "section": "Just pick some colors",
    "text": "Just pick some colors\nYou can also just choose some colors from the default ones available in R. Here, I’m using some hex color values, but you can also use RBG or CMYK or default R ones (i.e, “blue” or “red”).\nAgain, I’m adding the legend arguments back to this function.\n\nbase_plot_gg +\n  scale_color_manual(\n    values = c(\"#999999\", \"#E69F00\", \"#56B4E9\"), \n    name = \"Sex\",\n    labels = c(\"Female\", \"Male\")\n  )\n\n\n\n\nFor a plot that uses the fill() option (like a bar plot), the command is fill_color_manual()."
  },
  {
    "objectID": "lessons/lesson04s_examples.html#some-other-color-palettes",
    "href": "lessons/lesson04s_examples.html#some-other-color-palettes",
    "title": "Lesson 4 Supplement: ggplot Examples",
    "section": "Some other color palettes",
    "text": "Some other color palettes\nThe RColorBrewer package has several pre-built color palettes that you can use. You can view all the RColorBrewer palettes using\n\ndisplay.brewer.all()\n\n\n\n\nHere are just the palettes that work for color blind people:\n\ndisplay.brewer.all(colorblindFriendly = TRUE)\n\n\n\n\nThis is a qualitative palette, meaning that it works for nominal type variables. Again, adding the legend arguments back.\n\nbase_plot_gg +\n  scale_color_brewer(\n    palette = \"Set2\",\n    name = \"Sex\", \n    labels = c(\"Female\", \"Male\")\n  )\n\n\n\n\nA diverging palette that goes from red to yellow to blue:\n\nbase_plot_gg +\n  scale_color_brewer(\n    palette = \"RdYlBu\", \n    name = \"Sex\",\n    labels = c(\"Female\", \"Male\")\n  )\n\n\n\n\nThis is a sequential palette of blues:\n\nbase_plot_gg +\n  scale_color_brewer(\n    palette = \"Blues\",\n    name = \"Sex\", \n    labels = c(\"Female\", \"Male\")\n  )\n\n\n\n\nVery hard to see the lighter dots on the grey background."
  },
  {
    "objectID": "lessons/lesson04s_examples.html#color-based-on-continuous-variable",
    "href": "lessons/lesson04s_examples.html#color-based-on-continuous-variable",
    "title": "Lesson 4 Supplement: ggplot Examples",
    "section": "Color based on continuous variable",
    "text": "Color based on continuous variable\nIf you wanted to color based on a continuous variable, you would get many more colors than just the two here. Imagine that, instead of gender, we wanted to color the points based on how many social sciences units they enrolled in (SS in the dataset).\n\nbase_plot_cont_gg <- \n  ggplot(data = FirstYearGPA) +\n  aes(\n    x = HSGPA, \n    y = GPA, \n    color = SS\n  ) +\n  labs(\n    title = \"First year college GPA versus high school GPA\", \n    x = \"High school GPA\", \n    y = \"First year college GPA\", \n    color = \"Social studies units\"\n  ) +\n  geom_point()\n\nbase_plot_cont_gg\n\n\n\n\nAbove is the default color scheme from ggplot. Let’s create a gradient for the SS variable, starting at blue and increasing to red. The function scale_color_gradient() lets you specify just the ends and it fills in between.\n\nbase_plot_cont_gg +\n    scale_color_gradient(low = \"blue\", high = \"red\")\n\n\n\n\nNotice that the continuous variable doesn’t need any edits to the legend labels, so the we don’t have to repeat those options like we did for the plot with the gender variable."
  },
  {
    "objectID": "lessons/lesson04s_examples.html#color-fill-commands",
    "href": "lessons/lesson04s_examples.html#color-fill-commands",
    "title": "Lesson 4 Supplement: ggplot Examples",
    "section": "Color fill commands",
    "text": "Color fill commands\nWhen you’re using plots that fill rather than create lines or points, the commands are similar but include fill in them. Here is an unedited bar plot that uses one of the RColorBrewer color palettes.\n\nggplot(data = FirstYearGPA) +\n  aes(\n    x = as_factor(Male), \n    fill = as_factor(FirstGen)\n  ) +\n  scale_fill_brewer(\n    palette = \"Set2\", \n    name = \"First generation status\", \n    labels = c(\"Not 1st gen\", \"1st gen\")\n  ) +\n  scale_x_discrete(\n    name = \"Gender\", \n    labels = c(\"Female\", \"Male\")\n  ) +\n  labs(y = \"Frequency\") +\n  geom_bar(position = \"dodge\")\n\n\n\n\nNotice that I added labels to the (discrete) X axis and (continuous) Y axis too."
  },
  {
    "objectID": "lessons/lesson04s_examples.html#adding-annotations",
    "href": "lessons/lesson04s_examples.html#adding-annotations",
    "title": "Lesson 4 Supplement: ggplot Examples",
    "section": "Adding annotations",
    "text": "Adding annotations\nLet’s return to our base plot of first year college GPA versus high school GPA. We can add annotations to the plot to make things more clear or to point out specific aspects of the plot. For example, we can highlight the area of the plot that includes high school honor roll students, those with GPA > 3.8.\n\nbase_plot_gg +\n  annotate(\n    geom = \"rect\", \n    xmin = 3.8, \n    xmax = 4.01, \n    ymin = 2.0, \n    ymax = 4.2, \n    fill = \"red\", \n    alpha = 0.2\n  ) +\n  annotate(\n    geom = \"text\", \n    x = 3.4, \n    y = 4.1, \n    label = \"High school honor roll students \\n (GPA > 3.8)\"\n  )\n\n\n\n\nThis is pretty basic and built in as an annotation.\nWhat about a line indicating academic probation?\n\nbase_plot_gg +\n  annotate(\n    geom = \"segment\", \n    x = 2.25, \n    xend = 4.25, \n    y = 2.5, \n    yend = 2.5, \n    linetype = \"dashed\", \n    color = \"blue\"\n  ) +\n  annotate(\n    geom = \"text\", \n    x = 2.95, \n    y = 4.5, \n    label = \"Students below the line are on probation\"\n  )\n\n\n\n\nWe can add a line indicating equal GPAs in high school and college and add text explaining why that line is important.\n\nbase_plot_gg +\n  annotate(\n    geom = \"segment\", \n    x = 2.25, \n    xend = 4.25, \n    y = 2.25, \n    yend = 4.25, \n    linetype = \"dashed\", \n    color = \"blue\"\n  ) +\n  annotate(\n    geom = \"text\", \n    x = 3.5, \n    y = 2, \n    label = \"Students below the line did better in high school\"\n  ) +\n  annotate(\n    geom = \"text\", \n    x = 2.9, \n    y = 4.0, \n    label = \"Students above the line did better in college\"\n  )\n\n\n\n\nAnother use of the line segment could be to indicate which groups are significantly different from one another in a bar plot.\n\nggplot(data = FirstYearGPA) + \n  aes(\n    x = Male, \n    fill = as_factor(FirstGen)\n  ) +\n  scale_fill_brewer(palette = \"Set2\") +\n  geom_bar(position = \"dodge\") +\n  annotate(\n    geom = \"segment\", \n    x = -0.25, \n    xend = 0.25, \n    y = 105, \n    yend = 105, \n    color = \"black\"\n  ) +\n  annotate(\n    geom = \"text\", \n    x = 0, \n    y = 108, \n    size = 8,\n    label = \"*\"\n  )\n\n\n\n\nThis doesn’t look as good as it could, so let’s clean up the axes and labels.\n\nggplot(data = FirstYearGPA) + \n  aes(\n    x = as_factor(Male), \n    fill = as_factor(FirstGen)\n  ) +\n  scale_fill_brewer(\n    palette = \"Set2\", \n    name = \"First generation status\", \n    labels = c(\"Not 1st gen\", \"1st gen\")\n  ) +\n  scale_x_discrete(\n    name = \"Sex\", \n    labels = c(\"0\" = \"Female\", \"1\" = \"Male\")\n  ) +\n  labs(y = \"Frequency\")+\n  geom_bar(position = \"dodge\") +\n  annotate(\n    geom = \"segment\", \n    x = 0.75, \n    xend = 1.25, \n    y = 105, \n    yend = 105, \n    color = \"black\"\n  ) +\n  annotate(\n    geom = \"text\", \n    x = 1, \n    y = 108, \n    size = 8,\n    label = \"*\"\n  )\n\n\n\n\nNotice a couple of things here:\n\nI had to specify that the gender variable was categorical with as_factor(Male). If I didn’t, the X axis labels didn’t show up at all (axis label or category labels).\nIn scale_x_discrete(), I specified which category the labels go with: \"0\" = \"Female\", \"1\" = \"Male\". This is not actually required but may be helpful.\nNotice the location of the line and star. I had to adjust their horizontal locations because factors in R do unexpected things: ggplot now places the bars at x = 1 and 2 instead of 0 and 1 because R is interpreting these factors as the numbers 1 and 2. We will discuss this more when we talk about atomic type coercion later this semester."
  },
  {
    "objectID": "lessons/lesson04s_examples.html#built-in-themes",
    "href": "lessons/lesson04s_examples.html#built-in-themes",
    "title": "Lesson 4 Supplement: ggplot Examples",
    "section": "Built-in themes",
    "text": "Built-in themes\nBlack and white theme:\n\nbase_plot_gg +\n  theme_bw()\n\n\n\n\nMinimal theme:\n\nbase_plot_gg + \n  theme_minimal()\n\n\n\n\nClassic theme:\n\nbase_plot_gg + \n  theme_classic()"
  },
  {
    "objectID": "lessons/lesson04s_examples.html#package-themes",
    "href": "lessons/lesson04s_examples.html#package-themes",
    "title": "Lesson 4 Supplement: ggplot Examples",
    "section": "Package themes",
    "text": "Package themes\nThere is an APA theme in the jtools package, which was installed and loaded above. As of today, it is APA Publication Manual Version 6 compliant.\n\nbase_plot_gg +\n  theme_apa()\n\n\n\n\nWhat if I want my plot to look like it could be in the Wall Street Journal? (from the ggthemes package)\n\nbase_plot_gg + \n  theme_wsj()\n\n\n\n\nWell, maybe not ready for prime time there. They sure like LARGE titles. Our title has been mostly chopped off.\nWhat about the Economist? (also ggthemes)\n\nbase_plot_gg +\n  theme_economist()"
  },
  {
    "objectID": "lessons/lesson04s_examples.html#editing-your-own-theme",
    "href": "lessons/lesson04s_examples.html#editing-your-own-theme",
    "title": "Lesson 4 Supplement: ggplot Examples",
    "section": "Editing your own theme",
    "text": "Editing your own theme\nYou can also change individual parts of the plot yourself. Maybe you just want all the text to be a little larger in a theme. This is good for presentations—the fonts are always a little too small to read well.\n\nbase_plot_gg + \n  theme_bw(base_size = 16)\n\n\n\n\nHow about changing the background of the plot (and the gridlines) to black to make it really striking?\n\nbase_plot_gg + \n  theme(\n    panel.background = element_rect(fill = \"black\"), \n    panel.grid = element_line(color = \"black\")\n  )\n\n\n\n\nAll of the objects you can modify are listed here: https://ggplot2.tidyverse.org/reference/theme.html.\n\n\n\n\n\n\nExercises\n\n\n\n\nChange base_plot_gg to have larger font throughout, purple points for females, green points for males, a white background inside the plot area, and a grey background outside the plot area. Do this layer by layer. Take your time.\nDiscuss with your neighbour the strengths and weaknesses of this plot. Would you be proud to submit this plot to a journal? What could you do to improve it?"
  },
  {
    "objectID": "lessons/lesson11_functions.html",
    "href": "lessons/lesson11_functions.html",
    "title": "Lesson 11: Functions and Control Flow in R",
    "section": "",
    "text": "What did we learn last class?\n\nString Matching\nModifying Strings\nSubstring Extraction\nTrim and Pad Strings\nManipulate Strings within Tibbles"
  },
  {
    "objectID": "lessons/lesson11_functions.html#preliminary-comments",
    "href": "lessons/lesson11_functions.html#preliminary-comments",
    "title": "Lesson 11: Functions and Control Flow in R",
    "section": "Preliminary Comments",
    "text": "Preliminary Comments\nFunctions are what gives R its power and flexibility, but it is also what gives R its incredibly steep learning curve. All of the material in this lesson is considerably more challenging than what you’ve done in this class so far. However, if you can understand functions and how to apply them to the vectors you have already created, you can do almost anything you will ever need to do.\n\n\n\n\n\n\nWarning\n\n\n\nThis lesson on functions and the next lesson on purrr are high-difficulty, high-reward."
  },
  {
    "objectID": "lessons/lesson11_functions.html#expressions",
    "href": "lessons/lesson11_functions.html#expressions",
    "title": "Lesson 11: Functions and Control Flow in R",
    "section": "Expressions",
    "text": "Expressions\nAll of these sections make use of expressions. An expression in R is a line of code or multiple lines of code that accomplish one or more tasks when executed. In this sense, we have been using expressions since day 1. For this lesson, when we say expression, think “some code that will do something without errors”. Some expressions are simple, like \"Hello, world!\", while others are far more complicated (like the chains of dplyr functions)."
  },
  {
    "objectID": "lessons/lesson11_functions.html#if-then-else-then",
    "href": "lessons/lesson11_functions.html#if-then-else-then",
    "title": "Lesson 11: Functions and Control Flow in R",
    "section": "IF then ELSE then",
    "text": "IF then ELSE then\nThe IF/ELSE router controls a set of expressions and evaluates them based on a single logical condition (that is, a logical atomic vector with length 1). We saw a variant of this when we used the case_when() function in the dplyr:: lesson. Here is an example.\n\n# Draw a single random number from the normal distribution\nxRand <- rnorm(1)\n\n# If the value is negative, say so\nif (xRand < 0) { \"This value is negative.\" }\n\nLet’s unpack this example. The if function is a special function that does not use the normal functionName(arg1 = val1) syntax. The syntax is if (CONDITION is TRUE) {DO TASK}. If the single atomic logical value in the parentheses is TRUE, then execute the expression in the curly braces. That is, if xRand < 0 evaluates to TRUE, then print \"This value is negative.\"\nWhat about if the value is positive? We could add another if () {} control, or we could use the else function. Like the if function, it also has a special syntax that can only be used with an if function. That syntax is if (CONDITION is TRUE) {DO TASK} else {DO OTHER TASK}. For example:\n\nxRand <- rnorm(1)\n\nif (xRand < 0) { \"This value is negative.\" } else { \"You're a winner!\" }\n\n[1] \"This value is negative.\"\n\n\nBecause these expressions can often span multiple lines, we often write IF/ ELSE controls like this:\n\nxRand <- rnorm(1)\n\nif (xRand < 0) {\n  \"This value is negative.\"\n} else {\n  \"You're a winner!\"\n}\n\n[1] \"You're a winner!\"\n\n\n\n\n\n\n\n\nExercise\n\n\n\nUse an IF/ELSE chain to replicate the functionality of the absolute value function (abs())."
  },
  {
    "objectID": "lessons/lesson11_functions.html#for",
    "href": "lessons/lesson11_functions.html#for",
    "title": "Lesson 11: Functions and Control Flow in R",
    "section": "FOR",
    "text": "FOR\nThe FOR controller allows us to repeat a task for some pre-defined number of times. Unlike the IF/ELSE control, the FOR control only makes sense to use with vectors with length greater than 1.\n\nfor (j in 1:10) { print(j + 1) }\n\n[1] 2\n[1] 3\n[1] 4\n[1] 5\n[1] 6\n[1] 7\n[1] 8\n[1] 9\n[1] 10\n[1] 11\n\n\nLet’s unpack the FOR loop. The FOR loop has the following syntax: for (INDEX in VECTOR) {EVALUATE f(INDEX)}, where f(INDEX) is some expression or function using the value of the index (though in some FOR loops the value of the index isn’t used at all).\nNow, it is important to understand the following: FOR loops are rarely useful for us to write directly in R, because R is a vectorised language. We could have done the exact same computation much simpler if we make use of R’s natural processing of vectors:\n\n(1:10) + 1\n\n [1]  2  3  4  5  6  7  8  9 10 11\n\n\nBecause R is a vectorized language, the FOR loops are written for you already and hidden deep in the computer (if you want to know more, see this excellent post on vectorization in R). However, FOR loops in R are critical when we need to create a function whose values at one position depend on the values before it; these constraints occur when simulating or analyzing observations over time, where the value of the vector at position i depends on the value at i - 1. As a more complicated example, we will create the Fibonacci Sequence:\n\n# Create empty vector of length 50\nfiboRes_int <- rep(NA_integer_, 50)\n# Initialize\nfiboRes_int[1] <- 1L\nfiboRes_int[2] <- 1L\n\nfor (i in 3:50) {\n  fiboRes_int[i] <- fiboRes_int[i - 1] + fiboRes_int[i - 2]\n}\n\nWarning in fiboRes_int[i - 1] + fiboRes_int[i - 2]: NAs produced by integer\noverflow\n\nfiboRes_int\n\n [1]          1          1          2          3          5          8\n [7]         13         21         34         55         89        144\n[13]        233        377        610        987       1597       2584\n[19]       4181       6765      10946      17711      28657      46368\n[25]      75025     121393     196418     317811     514229     832040\n[31]    1346269    2178309    3524578    5702887    9227465   14930352\n[37]   24157817   39088169   63245986  102334155  165580141  267914296\n[43]  433494437  701408733 1134903170 1836311903         NA         NA\n[49]         NA         NA\n\n\nThe warning we see, and the missing values in the results vector, should serve as a warning that FOR loops are indeed powerful, but must be used with great care.\n\n\n\n\n\n\nExercise\n\n\n\nRemove the print() call within the expression for the first FOR loop. What happens? Can you infer anything special about what happens inside the { }?"
  },
  {
    "objectID": "lessons/lesson11_functions.html#while-and-break",
    "href": "lessons/lesson11_functions.html#while-and-break",
    "title": "Lesson 11: Functions and Control Flow in R",
    "section": "WHILE and BREAK",
    "text": "WHILE and BREAK\nThe WHILE controller allows us to repeat a task for an undefined number of times. Unlike the FOR control, the WHILE control can continue to run indefinitely. USE WITH EXTREME CAUTION.\nWHILE loops are the foundation controller for most iterative mathematical algorithms. Because they can continue to compute indefinitely, they are also used to model scenarios where unknown or random forces act on objects. For example, pretend that we have a social game where an individual will continue to play until they reach a condition; e.g. speed dating, where a person (say “Todd, a software developer”) will continue to move from table to table until they find “the one”, upon which they exit the game.\nBecause WHILE loops can execute until the heat death of the universe, we recommend that you add a print statement that counts how many loops have been made. For example, let’s find out how many dates Todd goes on during the speed dating event:\n\n# Initialize\nhasDate <- 0\nattempts <- 1\n\nwhile (hasDate != 1) {\n  \n  # Make a condition that only happens with 2.5% chance\n  hasDate <- rnorm(1) < -1.96\n  attempts <- attempts + 1\n  print(attempts)\n  \n}\n\n[1] 2\n[1] 3\n[1] 4\n[1] 5\n[1] 6\n[1] 7\n[1] 8\n[1] 9\n[1] 10\n[1] 11\n[1] 12\n\n\nNow, as I played this example on my computer, I had one time where the WHILE loop repeated 60 times before the success condition was reached. In these cases, it would be nice to have a stopping condition. In our example, we can assume that there are only 30 potential date candidates for Todd to meet at the event, so we break the loop if we reach 30 attempts. This “exit” strategy uses the BREAK controller:\n\n# Initialize\nhasDate <- 0\nattempts <- 1\n\nwhile (hasDate != 1) {\n  \n  # Make a condition that only happens with 2.5% chance\n  hasDate <- rnorm(1) < -1.96\n  attempts <- attempts + 1\n  \n  if(attempts > 30L){\n    \n    print(\"No date found.\")\n    break\n    \n  }\n  \n  print(attempts)\n  \n}\n\n[1] 2\n[1] 3\n[1] 4\n[1] 5\n[1] 6\n[1] 7\n[1] 8\n[1] 9\n[1] 10\n[1] 11\n[1] 12\n[1] 13\n[1] 14\n[1] 15\n[1] 16\n[1] 17\n[1] 18\n[1] 19\n[1] 20\n[1] 21\n[1] 22\n[1] 23\n[1] 24\n[1] 25\n[1] 26\n[1] 27\n[1] 28\n[1] 29\n[1] 30\n[1] \"No date found.\"\n\n\n\n\n\n\n\n\nExercises\n\n\n\n\nIf you have accidentally written a WHILE loop that runs for eternity, how do you stop it without closing RStudio entirely?\nRead the lessons under the “Decision and Loop” section of DataMentor’s R Programming page: https://www.datamentor.io/r-programming/#tutorial\n\n\n\nDid you notice that if, else, for, while, and break all changed colour when you typed them? That is R telling you that these objects—remember that everything in R is an object—are reserved. That means that we cannot assign values to them or use them for any reason other than their designed purpose."
  },
  {
    "objectID": "lessons/lesson11_functions.html#function-arguments",
    "href": "lessons/lesson11_functions.html#function-arguments",
    "title": "Lesson 11: Functions and Control Flow in R",
    "section": "Function Arguments",
    "text": "Function Arguments\nMost functions we have used take in arguments; that is, they change their behaviour based on the values supplied to them. For example, we can create a function that finds the geometric mean of two numbers. In mathematics, this is\n\\[\nf(x_1, x_2) := \\sqrt{x_1 \\cdot x_2},\n\\]\nwhere the dot between the numbers is for multiplication. In code, this would be:\n\ngeomMean <- function(a, b){ sqrt( a * b ) }\n\nOnce again, any time we create a function, we test it using values we know. For example, we know that the product of 5 and 20 is 100, and that the square root of 100 is 10. Thus, the geometric mean of 5 and 20 calculated by our function should be 10:\n\ngeomMean(5, 20)\n\n[1] 10"
  },
  {
    "objectID": "lessons/lesson11_functions.html#overview-of-function-syntax",
    "href": "lessons/lesson11_functions.html#overview-of-function-syntax",
    "title": "Lesson 11: Functions and Control Flow in R",
    "section": "Overview of Function Syntax",
    "text": "Overview of Function Syntax\nJust like the control flow functions, the function operator has very special syntax: funName <- function(ARGUMENTS){ EXPRESSION USING ARGUMENTS }. Moreover, because the expression inside the { } can be quite long and complex, the function returns whatever happens on the last line. Up to this point, both of our functions have only had one line, so that was the last line by default.\nFor example, we can write a version of the abs() function by nesting an an IF statement within a function. If we ever need to have our function stop execution and return a value early, we can use the RETURN controller:\n\nabsoluteValue <- function(num){\n  \n  out <- num\n  \n  if(num < 0){\n    return(-out)\n  }\n  \n  out\n  \n}\n\nWhen we test this function, we need to try it with both a positive and a negative number for num:\n\nabsoluteValue(5)\n\n[1] 5\n\nabsoluteValue(-5)\n\n[1] 5\n\n\n\n\n\n\n\n\nExercises\n\n\n\n\nCreate a function that finds out if Todd gets a date. The argument of the function is the number of pairs at the event. Replace the 30L in the WHILE loop above with this argument.\nGo back an read the section on functions in HOPR Chapter 1."
  },
  {
    "objectID": "lessons/lesson11_functions.html#environments",
    "href": "lessons/lesson11_functions.html#environments",
    "title": "Lesson 11: Functions and Control Flow in R",
    "section": "Environments",
    "text": "Environments\nWhen we executed the function above, R created a brand new environment for the function to work in. Think back to our first lesson on vectors. We saw this image:\n An environment is a special type of object that makes it possible to create other objects. Environments connect, or bind, object names to their values. Technically speaking, the figure above is wrong, because it puts all objects inside an environment, when an environment itself is an object. Remember that everything in R is an object. However, this figure is a useful abstraction to help us understand the connections between functions and vectors.\n\n\n\n\n\n\nTip\n\n\n\nEnvironments connect, or bind, object names to their values.\n\n\nOn the second day of class, when we first used the assignment operator (<-), we used it to create an object named x that held the value 2. However, we now understand that x <- 2 binds the value 2 to the name x within our current environment (in our case, the Global Environment). Think about an environment like a sandbox that we can sit in to play with all of our objects."
  },
  {
    "objectID": "lessons/lesson11_functions.html#function-environments-and-scoping",
    "href": "lessons/lesson11_functions.html#function-environments-and-scoping",
    "title": "Lesson 11: Functions and Control Flow in R",
    "section": "Function Environments and Scoping",
    "text": "Function Environments and Scoping\nWhen we called the function absoluteValue(num = 5), R created a brand new environment with one object binding: the name num was bound to the object 5. (This is the primary use of the = operator; it creates objects to be used within a function environment.) Note that we could not see this environment, but it was there. Our absoluteValue() function did its work, returned the absolute value of 5, and then R destroyed the environment it created. When we called the function a second time, R created a brand new environment that had no memory that the first environment ever existed and repeated the same process.\n\nInspecting the Function Expression\nLet’s take a look at the arguments and expression of the function:\n(num){\n  \n  out <- num\n  \n  if(num < 0){\n    return(-out)\n  }\n  \n  out\n  \n}\nWhen we execute this function by running the code absoluteValue(5), R first creates a brand-new, completely empty environment, and then performs the assignment num = 5 in it. This action is also known as binding, so we could also say that R binds 5 to the name “num” in the function environment.\nThen, R executes the code in our expression, line by line, until the last line. So,\n\nR creates an object called out in this new environment and stores the number 5 in it. Then,\nR checks to see if the original value of num is negative; if so,\n\nR RETURNs the value of out multiplied by negative 1.\nIf this check was not TRUE, then R reaches the last line of the function.\n\nFinally, if R reaches the last line, it sees the expression out. If you type the name of an object in your “Console” and hit “Enter”, R will print the contents of that object. Because the function has reached its last line, we don’t need to explicitly type a RETURN control—it’s called automatically. Thus, the last line of this expression is to print to the “Console” the contents of the object out contained in the function environment.\n\n\n\nLooking “Up”\nWhen a function can’t find an object you reference in one environment, it “looks up” to the “next” environment. This action of “looking up” through environments is called scoping. The “next” environment up from your current environment is called the parent environment.\nNow, let’s create a new function that RETURNs the object out without defining it in the function environment:\n\nbadTestFun <- function(){\n  out\n}\n\nbadTestFun()\n\n[1] \"This is a character string, and clearly not a number.\"\n\n\nNow, let’s try it on an object we know doesn’t exist in any environment:\n\nbadTestFun2 <- function(){\n  object_that_I_know_doesnt_exist_because_this_name_is_long_and_dumb\n}\n\nbadTestFun2()\n\nError in badTestFun2(): object 'object_that_I_know_doesnt_exist_because_this_name_is_long_and_dumb' not found\n\n\n\n\n\n\n\n\nExercises\n\n\n\n\nDiscuss what you think just happened. Why did badTestFun() return something while badTestFun2() triggered an error?\nExecute the search() function. What do you think this function returns?"
  },
  {
    "objectID": "lessons/lesson09s_dplyr_v_base.html",
    "href": "lessons/lesson09s_dplyr_v_base.html",
    "title": "Lesson 9 Supplement: Compare dplyr and base R Subsetting",
    "section": "",
    "text": "We will discuss/review\n\nThe data sets\nRow subsetting\nColumn subsetting\nRelational subsetting\n\nThis lesson will not compare merging two data sets using basic R, because the dplyr version is superior in almost every way."
  },
  {
    "objectID": "lessons/lesson09s_dplyr_v_base.html#the-heroes_tbldf-data",
    "href": "lessons/lesson09s_dplyr_v_base.html#the-heroes_tbldf-data",
    "title": "Lesson 9 Supplement: Compare dplyr and base R Subsetting",
    "section": "The heroes_tbldf Data",
    "text": "The heroes_tbldf Data\n\nheroes_tbldf <- tibble(\n  subject_ID = factor(c(\"008\", \"016\", \"115\", \"027\", \"001\")),\n  name = c(\"Wonder Woman\", \"Green Lantern\", \"Spider-Man\", \"Batman\", \"Superman\"),\n  alias = c(\n    \"Diana Prince\", \"Alan Scott\", \"Peter Parker\", \"Bruce Wayne\",\n    \"Clark Kent / Kal-El\"\n  ),\n  city = c(\n    \"Gateway City\", \"Capitol City\", \"New York City\", \"Gotham\", \"Metropolis\"\n  ),\n  male = c(FALSE, TRUE, TRUE, TRUE, TRUE),\n  heightCM = c(183.5, 182.9, 177.8, 188.0, 190.5),\n  weightKg = c(74.8, 91.2, 75.7, 95.3, 106.6),\n  firstRun = c(1941L, 1940L, 1962L, 1939L, 1938L)\n)"
  },
  {
    "objectID": "lessons/lesson09s_dplyr_v_base.html#framingham-data",
    "href": "lessons/lesson09s_dplyr_v_base.html#framingham-data",
    "title": "Lesson 9 Supplement: Compare dplyr and base R Subsetting",
    "section": "Framingham Data",
    "text": "Framingham Data\nFor the examples in this comparison document, we will use the first 20 records of the Framingham data only. Notice that the only difference between framingham_df and framingham_tbldf is that we forced the _tbldf version to be a tibble (modern data frame).\n\n# install.packages(\"LocalControl\")\nlibrary(LocalControl)\n\n# Base R data frame\nframingham_dataframe <- \n  framingham %>% \n  mutate(sex = ifelse(female == 1, yes = \"Female\", no = \"Male\")) %>% \n  mutate(curSmoke = cursmoke == 1) %>% \n  mutate(highBP = outcome == 1) %>% \n  mutate(death = outcome == 2) %>% \n  select(-female, -cursmoke, -outcome) %>% \n  slice(1:20)\n\n# Tibble\nframingham_tbldf <- as_tibble(framingham_dataframe)"
  },
  {
    "objectID": "lessons/lesson09s_dplyr_v_base.html#gapminder-data",
    "href": "lessons/lesson09s_dplyr_v_base.html#gapminder-data",
    "title": "Lesson 9 Supplement: Compare dplyr and base R Subsetting",
    "section": "Gapminder Data",
    "text": "Gapminder Data\n\n# install.packages(\"dslabs\")\nlibrary(dslabs)\n\n# Base R data frame\ngapminder_dataframe <-\n  gapminder %>% \n  mutate(gdpPerCap = gdp / population)\n\n# Tibble\ngapminder_tbldf <- as_tibble(gapminder_dataframe)"
  },
  {
    "objectID": "lessons/lesson09s_dplyr_v_base.html#base",
    "href": "lessons/lesson09s_dplyr_v_base.html#base",
    "title": "Lesson 9 Supplement: Compare dplyr and base R Subsetting",
    "section": "base",
    "text": "base\nTo select the first row of a tibble using basic R subsetting rules, use the [ function. This follows row, column syntax.\n\nframingham_dataframe[1, ]\n\n  totchol age   bmi BPVar heartrte glucose time_outcome cigpday  sex curSmoke\n1     195  39 26.97   -17       80      77           24       0 Male    FALSE\n  highBP death\n1  FALSE FALSE\n\n\nThis returns a 1-row data frame."
  },
  {
    "objectID": "lessons/lesson09s_dplyr_v_base.html#dplyr",
    "href": "lessons/lesson09s_dplyr_v_base.html#dplyr",
    "title": "Lesson 9 Supplement: Compare dplyr and base R Subsetting",
    "section": "dplyr",
    "text": "dplyr\nTo select the first row of a tibble using dplyr subsetting rules, use the slice() function. This uses row position only.\n\nframingham_tbldf %>% \n  slice(1)\n\n# A tibble: 1 × 12\n  totchol   age   bmi BPVar heartrte glucose time_outcome cigpday sex   curSmoke\n    <int> <int> <dbl> <dbl>    <int>   <int>        <dbl>   <int> <chr> <lgl>   \n1     195    39  27.0   -17       80      77           24       0 Male  FALSE   \n# ℹ 2 more variables: highBP <lgl>, death <lgl>\n\nframingham_tbldf[1, ]\n\n# A tibble: 1 × 12\n  totchol   age   bmi BPVar heartrte glucose time_outcome cigpday sex   curSmoke\n    <int> <int> <dbl> <dbl>    <int>   <int>        <dbl>   <int> <chr> <lgl>   \n1     195    39  27.0   -17       80      77           24       0 Male  FALSE   \n# ℹ 2 more variables: highBP <lgl>, death <lgl>\n\n\nThese both return the same 1-row tibble."
  },
  {
    "objectID": "lessons/lesson09s_dplyr_v_base.html#base-r",
    "href": "lessons/lesson09s_dplyr_v_base.html#base-r",
    "title": "Lesson 9 Supplement: Compare dplyr and base R Subsetting",
    "section": "base R",
    "text": "base R\nTo select the first column of a tibble using basic R subsetting rules, again use the [ function. This follows row, column syntax, so move the 1 on the other side of the comma.\n\nframingham_dataframe[, 1]\n\n [1] 195 250 245 285 205 313 254 247 291 195 195 190 215 294 247 295 226 175 180\n[20] 243\n\n\nThis returns an atomic vector of length 20.\nBecause tibbles are also lists, we can use the list subsetting rules for columns as well. To subset by column position, we can use the [ or the [[ functions (for single-level or double-level subsetting). Note that [[ can only take in a single scalar argument, rather than a vector of positions.\n\nframingham_dataframe[1]\n\n   totchol\n1      195\n2      250\n3      245\n4      285\n5      205\n6      313\n7      254\n8      247\n9      291\n10     195\n11     195\n12     190\n13     215\n14     294\n15     247\n16     295\n17     226\n18     175\n19     180\n20     243\n\n\nThis returns a 1-column data frame.\n\nframingham_dataframe[[1]]\n\n [1] 195 250 245 285 205 313 254 247 291 195 195 190 215 294 247 295 226 175 180\n[20] 243\n\n\nThis returns an atomic vector of length 20 with the contents of the first column.\nNote that these functions also work when we supply the name of a column as a character string:\n\nframingham_dataframe[, \"totchol\"] # atomic vector\n\n [1] 195 250 245 285 205 313 254 247 291 195 195 190 215 294 247 295 226 175 180\n[20] 243\n\nframingham_dataframe[\"totchol\"]   # 1-column data frame\n\n   totchol\n1      195\n2      250\n3      245\n4      285\n5      205\n6      313\n7      254\n8      247\n9      291\n10     195\n11     195\n12     190\n13     215\n14     294\n15     247\n16     295\n17     226\n18     175\n19     180\n20     243\n\nframingham_dataframe[[\"totchol\"]] # atomic vector\n\n [1] 195 250 245 285 205 313 254 247 291 195 195 190 215 294 247 295 226 175 180\n[20] 243\n\n\nInfuriatingly, the [ function changes behaviour if you request two or more columns using [row, c(col1, col2, ...)] syntax:\n\nframingham_dataframe[, c(\"totchol\", \"death\")] # now a data frame\n\n   totchol death\n1      195 FALSE\n2      250 FALSE\n3      245 FALSE\n4      285 FALSE\n5      205 FALSE\n6      313 FALSE\n7      254 FALSE\n8      247 FALSE\n9      291  TRUE\n10     195 FALSE\n11     195 FALSE\n12     190 FALSE\n13     215 FALSE\n14     294  TRUE\n15     247 FALSE\n16     295 FALSE\n17     226 FALSE\n18     175 FALSE\n19     180 FALSE\n20     243 FALSE\n\n\nOne of the main differences between [ and [[ is that the single-subset operator can take in multiple column names, while [[ cannot. For example:\n\nframingham_dataframe[[c(\"totchol\", \"death\")]]\n\nError in .subset2(x, i, exact = exact): subscript out of bounds\n\n\nFinally, we can use the $ function to extract the contents of a single column by name as a symbol (not using quotes):\n\nframingham_dataframe$totchol\n\n [1] 195 250 245 285 205 313 254 247 291 195 195 190 215 294 247 295 226 175 180\n[20] 243\n\n\nThis returns an atomic vector of length 20 with the contents of the first column."
  },
  {
    "objectID": "lessons/lesson09s_dplyr_v_base.html#dplyr-1",
    "href": "lessons/lesson09s_dplyr_v_base.html#dplyr-1",
    "title": "Lesson 9 Supplement: Compare dplyr and base R Subsetting",
    "section": "dplyr",
    "text": "dplyr\nTo select the first column of a tibble using dplyr subsetting rules, use the select() function. This uses column position only.\n\nframingham_tbldf %>% \n  select(1)\n\n# A tibble: 20 × 1\n   totchol\n     <int>\n 1     195\n 2     250\n 3     245\n 4     285\n 5     205\n 6     313\n 7     254\n 8     247\n 9     291\n10     195\n11     195\n12     190\n13     215\n14     294\n15     247\n16     295\n17     226\n18     175\n19     180\n20     243\n\nframingham_tbldf[, 1]\n\n# A tibble: 20 × 1\n   totchol\n     <int>\n 1     195\n 2     250\n 3     245\n 4     285\n 5     205\n 6     313\n 7     254\n 8     247\n 9     291\n10     195\n11     195\n12     190\n13     215\n14     294\n15     247\n16     295\n17     226\n18     175\n19     180\n20     243\n\nframingham_tbldf[1]\n\n# A tibble: 20 × 1\n   totchol\n     <int>\n 1     195\n 2     250\n 3     245\n 4     285\n 5     205\n 6     313\n 7     254\n 8     247\n 9     291\n10     195\n11     195\n12     190\n13     215\n14     294\n15     247\n16     295\n17     226\n18     175\n19     180\n20     243\n\n\nThese all return the same 1-column tibble.\nTo access a column by name, we have two options: do we want the contents of the column or do we want the column itself.\n\nColumn Itself\nWe can use the select() function in addition to the [ function to extract one or more columns. However, for the select() function, we are not required to supply the name in quotes, but rather we can use column names as a symbol object.\n\nframingham_tbldf %>% \n  select(totchol)\n\n# A tibble: 20 × 1\n   totchol\n     <int>\n 1     195\n 2     250\n 3     245\n 4     285\n 5     205\n 6     313\n 7     254\n 8     247\n 9     291\n10     195\n11     195\n12     190\n13     215\n14     294\n15     247\n16     295\n17     226\n18     175\n19     180\n20     243\n\nframingham_tbldf[, \"totchol\"]\n\n# A tibble: 20 × 1\n   totchol\n     <int>\n 1     195\n 2     250\n 3     245\n 4     285\n 5     205\n 6     313\n 7     254\n 8     247\n 9     291\n10     195\n11     195\n12     190\n13     215\n14     294\n15     247\n16     295\n17     226\n18     175\n19     180\n20     243\n\nframingham_tbldf[\"totchol\"]\n\n# A tibble: 20 × 1\n   totchol\n     <int>\n 1     195\n 2     250\n 3     245\n 4     285\n 5     205\n 6     313\n 7     254\n 8     247\n 9     291\n10     195\n11     195\n12     190\n13     215\n14     294\n15     247\n16     295\n17     226\n18     175\n19     180\n20     243\n\n\nAs with subsetting by position, these all return the same 1-column tibble. What’s more, is that—unlike a base R data frame—selecting more than one column does not change the behaviour of the function. Tibbles stay tibbles.\n\nframingham_tbldf %>% \n  select(totchol, death)\n\n# A tibble: 20 × 2\n   totchol death\n     <int> <lgl>\n 1     195 FALSE\n 2     250 FALSE\n 3     245 FALSE\n 4     285 FALSE\n 5     205 FALSE\n 6     313 FALSE\n 7     254 FALSE\n 8     247 FALSE\n 9     291 TRUE \n10     195 FALSE\n11     195 FALSE\n12     190 FALSE\n13     215 FALSE\n14     294 TRUE \n15     247 FALSE\n16     295 FALSE\n17     226 FALSE\n18     175 FALSE\n19     180 FALSE\n20     243 FALSE\n\nframingham_tbldf[, c(\"totchol\", \"death\")]\n\n# A tibble: 20 × 2\n   totchol death\n     <int> <lgl>\n 1     195 FALSE\n 2     250 FALSE\n 3     245 FALSE\n 4     285 FALSE\n 5     205 FALSE\n 6     313 FALSE\n 7     254 FALSE\n 8     247 FALSE\n 9     291 TRUE \n10     195 FALSE\n11     195 FALSE\n12     190 FALSE\n13     215 FALSE\n14     294 TRUE \n15     247 FALSE\n16     295 FALSE\n17     226 FALSE\n18     175 FALSE\n19     180 FALSE\n20     243 FALSE\n\nframingham_tbldf[c(\"totchol\", \"death\")]\n\n# A tibble: 20 × 2\n   totchol death\n     <int> <lgl>\n 1     195 FALSE\n 2     250 FALSE\n 3     245 FALSE\n 4     285 FALSE\n 5     205 FALSE\n 6     313 FALSE\n 7     254 FALSE\n 8     247 FALSE\n 9     291 TRUE \n10     195 FALSE\n11     195 FALSE\n12     190 FALSE\n13     215 FALSE\n14     294 TRUE \n15     247 FALSE\n16     295 FALSE\n17     226 FALSE\n18     175 FALSE\n19     180 FALSE\n20     243 FALSE\n\n\n\n\nColumn Contents\nThe pull() function works almost exactly like the $ function: it takes in the name of a single column as a symbol object rather than a character string, and it returns the contents of the column as a vector.\n\nframingham_tbldf %>% \n  pull(totchol)\n\n [1] 195 250 245 285 205 313 254 247 291 195 195 190 215 294 247 295 226 175 180\n[20] 243\n\nframingham_tbldf$totchol\n\n [1] 195 250 245 285 205 313 254 247 291 195 195 190 215 294 247 295 226 175 180\n[20] 243\n\nframingham_tbldf[[1]]\n\n [1] 195 250 245 285 205 313 254 247 291 195 195 190 215 294 247 295 226 175 180\n[20] 243\n\nframingham_tbldf[[\"totchol\"]]\n\n [1] 195 250 245 285 205 313 254 247 291 195 195 190 215 294 247 295 226 175 180\n[20] 243\n\n\nThese all return the same atomic vector of length 20 with the contents of the first column."
  },
  {
    "objectID": "lessons/lesson09s_dplyr_v_base.html#example-1-framingham-young-women",
    "href": "lessons/lesson09s_dplyr_v_base.html#example-1-framingham-young-women",
    "title": "Lesson 9 Supplement: Compare dplyr and base R Subsetting",
    "section": "Example 1: Framingham Young Women",
    "text": "Example 1: Framingham Young Women\nFor example, we want to find all the females in the Framingham data set younger than the 75th percentile for the ages of these recorded females. (Remember that this lesson uses a subset of the Framingham data, not the full data set. Your results will look different.)\n\nUsing base\n\n# Subset the women\nframinghamWomen_tbldf <- \n  framingham_tbldf[framingham_tbldf$sex == \"Female\", ]\n\n# Find the age threshold for P75\nwomenP75_num <- quantile(framinghamWomen_tbldf$age, 0.75)\nframinghamWomenYoung_tbldf <- \n  framinghamWomen_tbldf[framinghamWomen_tbldf$age < womenP75_num, ]\n\n# Remove intermediary pieces from memory\nrm(framinghamWomen_tbldf, womenP75_num)\n\n# Inspect\nframinghamWomenYoung_tbldf\n\n# A tibble: 9 × 12\n  totchol   age   bmi  BPVar heartrte glucose time_outcome cigpday sex   \n    <int> <int> <dbl>  <dbl>    <int>   <int>        <dbl>   <int> <chr> \n1     250    46  28.7   1.5        95      76        24          0 Female\n2     285    46  23.1   9          85      85        11.7       23 Female\n3     313    45  21.7 -19          79      78        23.8       20 Female\n4     254    50  22.9   2.5        75      76        24          0 Female\n5     247    43  27.6  13.5        72      61        24          0 Female\n6     291    46  23.4  -6          80      89         3.95      20 Female\n7     195    38  23.2   5.5        75      78         5.91       5 Female\n8     190    42  21.6 -15.5        72      85        16.2       30 Female\n9     243    43  26.9  -1.75       68      78        24         10 Female\n# ℹ 3 more variables: curSmoke <lgl>, highBP <lgl>, death <lgl>\n\n\n\n\nUsing dplyr\n\nframingham_tbldf %>%\n  filter(sex == \"Female\") %>%\n  filter(age < quantile(age, 0.75))\n\n# A tibble: 9 × 12\n  totchol   age   bmi  BPVar heartrte glucose time_outcome cigpday sex   \n    <int> <int> <dbl>  <dbl>    <int>   <int>        <dbl>   <int> <chr> \n1     250    46  28.7   1.5        95      76        24          0 Female\n2     285    46  23.1   9          85      85        11.7       23 Female\n3     313    45  21.7 -19          79      78        23.8       20 Female\n4     254    50  22.9   2.5        75      76        24          0 Female\n5     247    43  27.6  13.5        72      61        24          0 Female\n6     291    46  23.4  -6          80      89         3.95      20 Female\n7     195    38  23.2   5.5        75      78         5.91       5 Female\n8     190    42  21.6 -15.5        72      85        16.2       30 Female\n9     243    43  26.9  -1.75       68      78        24         10 Female\n# ℹ 3 more variables: curSmoke <lgl>, highBP <lgl>, death <lgl>"
  },
  {
    "objectID": "lessons/lesson09s_dplyr_v_base.html#example-2-countries-with-highest-infant-mortality",
    "href": "lessons/lesson09s_dplyr_v_base.html#example-2-countries-with-highest-infant-mortality",
    "title": "Lesson 9 Supplement: Compare dplyr and base R Subsetting",
    "section": "Example 2: Countries with Highest Infant Mortality",
    "text": "Example 2: Countries with Highest Infant Mortality\nAs another example, we want to find the 25 countries in the Gapminder data set which had the largest infant mortality rate in 2010.\n\nUsing base\n\n# Save a subset of the Gapminder data only for the year 2010\ngapminder2010_tbldf <- \n  gapminder_tbldf[gapminder_tbldf[[\"year\"]] == 2010, ]\n\n# Find the order of the rows by worst infant mortality to best\nworstInfMort_idx <- order(\n  gapminder2010_tbldf[[\"infant_mortality\"]],\n  decreasing = TRUE\n)\n\n# Subset the 2010 data by the first 25 indices in the \"worst\" vector\ngapminderInfMort2010_tbldf <-\n  gapminder2010_tbldf[worstInfMort_idx[1:25], ]\n\n# Inspect\ngapminderInfMort2010_tbldf\n\n# A tibble: 25 × 10\n   country    year infant_mortality life_expectancy fertility population     gdp\n   <fct>     <int>            <dbl>           <dbl>     <dbl>      <dbl>   <dbl>\n 1 Angola     2010            110.             57.6      6.22   21219954 2.61e10\n 2 Sierra L…  2010            107              55        4.94    5775902 1.57e 9\n 3 Central …  2010            102.             47.9      4.63    4444973 1.05e 9\n 4 Chad       2010             93.6            55.8      6.6    11896380 3.37e 9\n 5 Haiti      2010             85.5            32.2      3.35    9999617 3.70e 9\n 6 Congo, D…  2010             84.8            58.4      6.25   65938712 6.96e 9\n 7 Mali       2010             82.9            59.2      6.84   15167286 4.20e 9\n 8 Nigeria    2010             81.5            61.2      6.02  159424742 8.56e10\n 9 Equatori…  2010             78.9            58.6      5.14     728710 5.98e 9\n10 Cote d'I…  2010             76.9            56.6      4.91   20131707 1.16e10\n# ℹ 15 more rows\n# ℹ 3 more variables: continent <fct>, region <fct>, gdpPerCap <dbl>\n\n\n\n\nUsing dplyr\n\ngapminder_tbldf %>% \n  filter(year == 2010) %>% \n  arrange(desc(infant_mortality)) %>% \n  slice(1:25)\n\n# A tibble: 25 × 10\n   country    year infant_mortality life_expectancy fertility population     gdp\n   <fct>     <int>            <dbl>           <dbl>     <dbl>      <dbl>   <dbl>\n 1 Angola     2010            110.             57.6      6.22   21219954 2.61e10\n 2 Sierra L…  2010            107              55        4.94    5775902 1.57e 9\n 3 Central …  2010            102.             47.9      4.63    4444973 1.05e 9\n 4 Chad       2010             93.6            55.8      6.6    11896380 3.37e 9\n 5 Haiti      2010             85.5            32.2      3.35    9999617 3.70e 9\n 6 Congo, D…  2010             84.8            58.4      6.25   65938712 6.96e 9\n 7 Mali       2010             82.9            59.2      6.84   15167286 4.20e 9\n 8 Nigeria    2010             81.5            61.2      6.02  159424742 8.56e10\n 9 Equatori…  2010             78.9            58.6      5.14     728710 5.98e 9\n10 Cote d'I…  2010             76.9            56.6      4.91   20131707 1.16e10\n# ℹ 15 more rows\n# ℹ 3 more variables: continent <fct>, region <fct>, gdpPerCap <dbl>"
  },
  {
    "objectID": "lessons/lesson04_ggplot.html",
    "href": "lessons/lesson04_ggplot.html",
    "title": "Lesson 4: ggplot and the Layered Grammar of Graphics",
    "section": "",
    "text": "What did we learn last class?\n\nBenefits of reproducible reports\nR packages and how to install them\nThe components of a basic RMarkdown report\nMarkdown customisation options"
  },
  {
    "objectID": "lessons/lesson04_ggplot.html#unpacking-the-title",
    "href": "lessons/lesson04_ggplot.html#unpacking-the-title",
    "title": "Lesson 4: ggplot and the Layered Grammar of Graphics",
    "section": "Unpacking the Title",
    "text": "Unpacking the Title\nWe will start with “graphics”, because most people are most familar with graphs. Then we will work backwards.\n\nGraphics\nIn computational parlance, a graphic is a visual representation of organized information, displayed to the screen or stored in a file. Consider this picture:\n\nThis is a visual representation of information, but it isn’t useful. It isn’t organized, and we cannot draw any meaning from it. The most basic graphic of our data is a screenshot of it, but that usually doesn’t help anyone!\n\n\nGrammar of Graphics\nAs we see in the figure above, we need our graphics to follow a set of rules. A grammar is a set of the fundamental principles and rules of a discipline, so the grammar of graphics is the set of fundamental rules for displaying organised information (Wickham, 2010).\n\nA grammar provides a strong foundation for understanding a diverse range of graphics. A grammar may also help guide us on what a well-formed or correct graphic looks like, but there will still be many grammatically correct but nonsensical graphics. This is easy to see by analogy to the English language: good grammar is just the first step in creating a good sentence. - Hadley Wickham\n\n\n\nLayering\nIf grammar helps us construct a sentence in the proper way, layering helps us combine multiple sentences into a paragraph. We use layers to “stack” different levels of results and statistics. Let’s walk through Wickham’s original example (ibid., p. 4).\n\nExample Data\nConsider the following toy data:\n\n\n\nA\nB\nC\nD\n\n\n\n\n2\n3\n4\na\n\n\n1\n2\n1\na\n\n\n4\n5\n15\nb\n\n\n9\n9\n80\nb\n\n\n\nA simple research question we may have is, does changing C affect A, and is this effect mitigated by D? To answer this, we would probably build a scatterplot of C and A, with point size, shape, or colour set by D. That is, we assign C to take values on the horizontal axis, A to take values on the vertical axis, and D to take values on some other axis (shape, for instance). The resulting data set looks like this:\n\n\n\nx\ny\nShape\n\n\n\n\n2\n4\na\n\n\n1\n1\na\n\n\n4\n15\nb\n\n\n9\n80\nb\n\n\n\nNow, we are making some progress, but we still haven’t told the computer what to do with this information. Recall that one of the major goals of this class is to help you tell the computer what you want. Your computer needs to translate these points and shape labels into actual pixels on the screen.\n\n\nExample Data Mapped\nLet’s pretend that we give a 200 x 300 window to R to plot these points. The resulting pixel locations and shapes will look like this:\n\n\n\nx\ny\nShape\n\n\n\n\n25\n11\ncircle\n\n\n0\n0\ncircle\n\n\n75\n53\nsquare\n\n\n200\n300\nsquare\n\n\n\nThis yields one layer with the overall shape and behaviour of the data:\n\nNotice however, that we don’t have any scales for these values. The values R supplied to the computer are in shapes and pixel locations, but we humans can’t interpret what this means. We need another layer for the axes.\n\nFinally, we need a layer for the labels. When we stack these layers (axes, labels, then data), we see the following composed graph:\n\nWhen we construct figures, we often take for granted the complexity inherent in the task. For our work, we will be constructing figures layer by layer, so it is important to understand these mechanics."
  },
  {
    "objectID": "lessons/lesson04_ggplot.html#the-tidyverse",
    "href": "lessons/lesson04_ggplot.html#the-tidyverse",
    "title": "Lesson 4: ggplot and the Layered Grammar of Graphics",
    "section": "The Tidyverse",
    "text": "The Tidyverse\nThe Tidyverse is a suite of inter-related packages that make data science in R easier. The components of the Tidyverse are:\n\nggplot2: make graphs\ntibble: create very nice “tidy” data tables from scratch\ntidyr: clean “messy” data into “tidy” data\nreadr: import raw data\npurrr: help you create and apply functions to your data\ndplyr: manipulate “tidy” data tables\nstringr: operate on character strings\nforcats: recode and modify catagorical variables in R, also known as factors (“forcats” is an abbreviation of for categorical variables, and also an anagram of “factors”)\n\nTo be completely honest, we could spend the entire semester on these eight packages. However, we will not be able to do that at this juncture. We are not going to cover the forcats package, and we will use some of the time in this semester diving deeper into the “inner workings” of R (we will use the Advanced R textbook for that)."
  },
  {
    "objectID": "lessons/lesson04_ggplot.html#the-variables",
    "href": "lessons/lesson04_ggplot.html#the-variables",
    "title": "Lesson 4: ggplot and the Layered Grammar of Graphics",
    "section": "The Variables",
    "text": "The Variables\nThere are a few variables in this data set, including\n\ndispl: the engine displacement in litres, and\nhwy: the highway fuel efficiency in miles per gallon.\n\n\n\n\n\n\n\nExercise\n\n\n\nCheck the definitions and explanations of the other variables in the help file on the mpg object.\n\n\nRecalling that data science is an intersection of statistics, computing, and domain knowledge, we think about what domain knowledge we have concerning automobiles to create an hypothesis. Some of this domain knowledge comes from our previous courses in physics: we think that engines that are heavier probably aren’t as fuel efficient. We will now test this hypothesis graphically."
  },
  {
    "objectID": "lessons/lesson04_ggplot.html#engine-size-by-fuel-economy",
    "href": "lessons/lesson04_ggplot.html#engine-size-by-fuel-economy",
    "title": "Lesson 4: ggplot and the Layered Grammar of Graphics",
    "section": "Engine Size by Fuel Economy",
    "text": "Engine Size by Fuel Economy\nWe are going to construct a graph first. I will give you the code and the figure, then we will deconstruct it.\n\nggplot(data = mpg) +\n  aes(x = displ, y = hwy) +\n  geom_point()\n\n\n\n\nWell, at first glance, it certainly seems that larger engines are less fuel efficient.\nWithin the code itself, the components in this code are organized in a logical manner and with a corresponding set of rules—that is, a grammar. That’s what the gg part stands for—the grammar of graphics.\n\n+: The Layer Glue\nNotice that each of the lines above are connected by the plus sign, “+”. In this context, the + symbol operates to “add” layers together, but you can still use it to add numbers too. If you are more familiar with R, but not familiar with the tidyverse, then the idea of “adding” one function to another seems absurd. However, as you’ll see soon, we can “add” more and more layers to a single graph with this + operator.\n\n\nThe data Layer\nThe first line in the code, ggplot(data = mpg), provides the base layer of the graphic. Recall the function syntax we have learned previously:\n\nThe function is named ggplot\nThe first argument of the function is called data\nWe supply the data set mpg as the value to this data argument\n\nThink of this as a blank canvas that you will paint on. In this case, the data set mpg provides the material from which to create the canvas.\n\n\n\n\n\n\nExercise\n\n\n\nRun ggplot(data = mpg). What does this look like?\n\n\nThe ggplot() function takes data tables only in a certain form. Recall the exercise from Lesson 1 on finding help? We first read about the str function then.\n\n\n\n\n\n\nExercise\n\n\n\nUse the str() function to confirm that the mpg object has data.frame as one of its classes.\n\n\nIf you ever have trouble with ggplot(), make sure your data frame is tidy! Later this semester, we will discuss some things to do if your data table is not tidy (using the tidyr, tibble, and readr packages in the tidyverse).\n\n\nThe Aesthetic Mapping Layer\nNow that we have created a canvas to paint on, we need to choose our proverbial “colour palette” and plan where our “paintbrush” will go. That is, we need to specify which measurements contained in the mpg data set we are going to use, and how they will influence the blank canvas. Now, consider the second line of code: aes(x = displ, y = hwy). Following what we know about function syntax, we can deconstruct this line as follows:\n\nThe function is named aes\nThe first argument of the function is named x\nWe supply the value of the object displ as to the argument x\nThe second argument of the function is named y\nWe supply the value of the object hwy as to the argument y\n\nNow, if you have been paying attention, you’ll notice that we don’t have any objects named displ or hwy in the “Environment” pane.\n\n\n\n\n\n\nExercises\n\n\n\n\nRun displ and hwy in the “Console”. What happens?\nRun\n\n\nggplot(data = mpg) +\n  aes(x = displ, y = hwy)\n\n\nHow is this different from the first layer alone? Remember to use the “+” symbol to add one layer to another.\n\nWhere did R find the values for displ and hwy? What would you do if you needed to add different values to the aesthetic layer?\nAdd 3 and 5 together. Is there anything else different with the + function?\n\n\n\n\n\nThe Geometric Object Layer\nWe now have a canvas to plot our points, and a system of axes to know where the points belong. Now we need to tell ggplot() how to plot x and y. This is where the the geom_*() functions come into play: we wanted a scatterplot, so we picked geom_point(). This is simply a call to the function geom_point with no arguments. “Geom” is short for “geometric object”, and there are quite a few geometric shapes we can bend our data into (more on this later).\n\n\n\n\n\n\nExercises\n\n\n\n\nRun the original code (copied below) and compare it to the previous figure. What did the geometric layer add to the plot?\n\n\nggplot(data = mpg) +\n  aes(x = displ, y = hwy) +\n  geom_point()\n\n\nLook up the help manual for the geom_point function. Recall our conversation on functions in Lesson 1. What are some of the arguments for the geom_point function? Where do you think the values of the arguments for this function came from?"
  },
  {
    "objectID": "lessons/lesson04_ggplot.html#common-aesthetics",
    "href": "lessons/lesson04_ggplot.html#common-aesthetics",
    "title": "Lesson 4: ggplot and the Layered Grammar of Graphics",
    "section": "Common Aesthetics",
    "text": "Common Aesthetics\nThere are quite a few aesthetics to choose from to modify our scatterplot:\n\ncolour: What color to make our points? Good for continuous and discrete features.\nsize: How big should the points be? Better for continuous features.\nalpha: How opaque / transparent should the points be? Values range from \\([0,1]\\), with \\(1\\) being completely opaque. Better for continuous features.\nshape: What shape should the points have? Better for discrete features. Options are shown below \nfill: For the shapes filled with red, what color should you put instead? Better for discrete features, but is limited when plotting points. The fill aesthetic truly shines with geoms other than point, but more on that later.\n\nFor most of these aesthetics, the behavior of the graph will change depending on if you map a discrete or continuous feature to it. For example, if you map a continuous feature to the colour aesthetic, the points will be given a continuous color gradient (by default, from dark blue to light blue). However, if you map character information to the colour aesthetic, the points will be distinctly different (discrete) in color."
  },
  {
    "objectID": "lessons/lesson04_ggplot.html#examples",
    "href": "lessons/lesson04_ggplot.html#examples",
    "title": "Lesson 4: ggplot and the Layered Grammar of Graphics",
    "section": "Examples",
    "text": "Examples\n\n\n\n\n\nLook back to the figure. You might notice that there is a group of five points on the top right that stick out: these cars have large engines but higher MPG than other vehicles with large engines. We could ask a few questions to try to explain this disparity:\n\nAre these vehicles hybrids?\nDo these vehicles use diesel?\nAre these vehicles newer?\n\nEach question is a hypothesis, and we will attempt to “test” these hypotheses visually.\n\nHypothesis 1: Outlier Cars are Hybrids\nCheck the help documentation for the mpg data set to find out which column measures the type of the car. We probably won’t see “hybrid”” in this list, because we know that very few hybrid cars were in production in both 1998 and 2008. These cars would have all been classified as “compact” or “sub-compact”. Note: this is where “domain knowledge” is critical for proper data science.\nNow what type of feature is class? The column header of the mpg data table informs us that this feature is a character feature (chr), and therefore discrete. Therefore, we can add it to the graph with the colour or shape aesthetics.\n\n\n\n\n\nIt appears that our hypothesis was incorrect. These vehicles are not small, hybrid cars at all, but sports cars or midsize cars.\n\n\n\n\n\n\nExercise\n\n\n\nWrite the code necessary to create the above graph.\n\n\n\n\nHypothesis 2: Outlier Cars take Diesel\n\n\n\n\n\nOur hypothesis is incorrect. It appears that all five of our outlier vehicles take premium fuel (“p”), not diesel (“d”). This graph, when paired with the previous graph on car class, gives us a better understanding of factors that could influence the relationship between engine size and fuel economy.\n\n\n\n\n\n\nExercises\n\n\n\n\nUsing the help manual for the mpg data set, find which feature of the data measures fuel type.\nWrite the code necessary to create the above graph. Hint: the shape of the points is controlled by the shape argument to the aes() function.\n\n\n\n\n\nHypothesis 3: Outlier Cars are Newer\nWe know that vehicle year can be either 1998 or 2008. Because the manufacture year is a time, we should add it to the graph with the colour, size, fill, or alpha aesthetics.\n\n\n\n\n\nThe manufacture year doesn’t help explain the five outlier points very well. They are rather evenly split between 2000 and 2008.\n\n\n\n\n\n\nExercise\n\n\n\nWrite the code necessary to create the above graph. Hint: the shape is not dependent on the data, so it is not an aesthetic. Think about where you should put the shape argument if you can’t put it in the aes() function.\n\n\n\n\nUpdated Hypothesis: Outlier Cars are Sportscars\nWe can add more than 3 features to a plot. Let’s create an engine size by MPG plot with fuel type and car class added.\n\n\n\n\n\nThis looks promising: it appears that all five outliers take premium fuel, and four of the five outliers are 2-seater coupes. This means that our outliers are probably sports / performance cars: larger engines but lighter bodies.\n\n\n\n\n\n\nExercise\n\n\n\nWrite the code necessary to create the above graph.\n\n\nIf you’re thinking to yourself, “I wish there was a way to clean this graph up, to only show the premium fuel and two-seater cars”, then you are thinking what I’m thinking. However, we need some functions from the dplyr package first, which we will cover in a few weeks. The ggplot package also gives us a way to break graphs into mutually-exclusive pieces, called facets, which we will discuss shortly."
  },
  {
    "objectID": "lessons/lesson12_purrr.html",
    "href": "lessons/lesson12_purrr.html",
    "title": "Lesson 12: Functional Iteration with purrr",
    "section": "",
    "text": "What did we learn last class?\n\nControl Flow in R\nCreating Functions\nBest Practices\nFunction Scoping"
  },
  {
    "objectID": "lessons/lesson12_purrr.html#learning-resources",
    "href": "lessons/lesson12_purrr.html#learning-resources",
    "title": "Lesson 12: Functional Iteration with purrr",
    "section": "Learning Resources",
    "text": "Learning Resources\nThis lesson borrows data from some material from Washington State University’s Department of Statistics. The link to the zipped data (1.7Mb unzipped) is https://drive.google.com/drive/folders/1HDeAg0EtqE_T1PuRBjKsczR8_ev3XKIA.\nFor this lesson, we will use a simple subset of the Gapminder data. Also, we will need the tidyverse again:\n\n# install.packages(\"gapminder\")\nlibrary(gapminder)\nlibrary(tidyverse)\n\ngapminder_df <- as_tibble(gapminder)\n\n\n\n\n\n\n\nExercises\n\n\n\n\nDownload the compressed file from the link above; unzip it on your desktop.\nRename the data/ subdirectory in the folder above to purrr_example_data/; move it to your data folder for this class.\nDelete the compressed and unzipped folders from your desktop."
  },
  {
    "objectID": "lessons/lesson12_purrr.html#an-example",
    "href": "lessons/lesson12_purrr.html#an-example",
    "title": "Lesson 12: Functional Iteration with purrr",
    "section": "An Example",
    "text": "An Example\nThankfully, before we get completely lost, we have actually seen something similar to a functional already. Let’s use the Gapminder data and find the 10 countries with the smallest maximum life expectancy:\n\ngapminder_df %>% \n  group_by(country) %>% \n  summarise(best_life_expectancy = max(lifeExp, na.rm = TRUE)) %>% \n  slice_min(order_by = best_life_expectancy, n = 10)\n\n# A tibble: 10 × 2\n   country          best_life_expectancy\n   <fct>                           <dbl>\n 1 Sierra Leone                     42.6\n 2 Angola                           42.7\n 3 Afghanistan                      43.8\n 4 Liberia                          46.0\n 5 Rwanda                           46.2\n 6 Mozambique                       46.3\n 7 Guinea-Bissau                    46.4\n 8 Nigeria                          47.5\n 9 Congo, Dem. Rep.                 47.8\n10 Somalia                          48.2\n\n\nHere, the summarize() function is like a functional. It says “find the life expectancy column, and take the maximum of it”; that is, it is similar to\n\nDO(TO = lifeExp, THIS = max(), WITH = {na.rm = TRUE})\n\n\n\n\n\n\n\nImportant\n\n\n\nFunctionals are functions which take in another function as one of its arguments.."
  },
  {
    "objectID": "lessons/lesson12_purrr.html#example-the-convergence-of-the-sample-mean",
    "href": "lessons/lesson12_purrr.html#example-the-convergence-of-the-sample-mean",
    "title": "Lesson 12: Functional Iteration with purrr",
    "section": "Example: The Convergence of the Sample Mean",
    "text": "Example: The Convergence of the Sample Mean\nDuring this, my 12th lesson in statistical computing, we will finally do a little bit of “traditional” statistics. Here is the general premise: the sample mean is an “unbiased” estimator. That is, if you take larger and larger samples from the population, the difference between the sample mean and the population mean goes to 0. To test this, we will first generate a medium-sized population from a random normal distribution (the set.seed() function allows me to generate the same random population each time, so that everyone can reproduce the output of my code):\n\n# for reproducibility:\nset.seed(12345) # if you change this number, you will get a different sample\n\npopulation <- rnorm(1000, mean = 1)\n\nWhat is the population mean (\\(\\mu\\))?\n\nmu <- mean(population)\nmu\n\n[1] 1.046198\n\n\n\nList of Samples\nNow, we want to take samples from the population, where each sample is bigger than the last (think of a snowball sampling design where the longer the study goes, the more people you can recruit). That is, we will start with a small batch of subjects (values from population), calculate the sample mean (\\(\\bar{x}\\)), add a few more subjects, calculate the sample mean again, and repeat this until our sample estimate of the mean gets close to the true (population) mean. Because each sample will be bigger than the last, we must use a list.\n\nsamples_ls <- list(\n  sample_0819 = population[1:5],\n  sample_0826 = population[1:10],\n  sample_0902 = population[1:15],\n  sample_0909 = population[1:20],\n  sample_0916 = population[1:25],\n  sample_0923 = population[1:30],\n  sample_0930 = population[1:40],\n  sample_1007 = population[1:50],\n  sample_1014 = population[1:75],\n  sample_1021 = population[1:100],\n  sample_1028 = population[1:125],\n  sample_1104 = population[1:150],\n  sample_1111 = population[1:175],\n  sample_1118 = population[1:200],\n  sample_1125 = population[1:250],\n  sample_1202 = population[1:300],\n  sample_1209 = population[1:400],\n  sample_1216 = population[1:500]\n)\n\n\n\nThe FOR Loop\nNow that we have our samples, we need to find the mean of each. Will simply taking the mean work?\n\nmean(samples_ls)\n\nWarning in mean.default(samples_ls): argument is not numeric or logical:\nreturning NA\n\n\n[1] NA\n\n\nUnfortunately no. Based on what we learned previously about FOR loops, we can use one of those:\n\n# Initialize\nnSamples <- length(samples_ls)\nsampleMeans <- rep(NA_real_, nSamples)\n\n# Loop\nfor (i in 1:nSamples) {\n  sampleMeans[i] <- mean(samples_ls[[i]])\n}\n\nNotice that we are using the position of the elements of the vector. These are the mean values we calculated:\n\nsampleMeans\n\n [1] 1.2676164 0.8670559 1.0341290 1.0765168 0.9988227 1.0788070 1.2401853\n [8] 1.1795663 1.1853153 1.2451972 1.2386719 1.1591299 1.1271903 1.1452152\n[15] 1.1273959 1.0814062 1.1148737 1.0824608\n\n\nHow far are these from the true population mean? We set this loop up to fill values into a numeric vector, so we can use R’s vector power again:\n\nabs(mu - sampleMeans)\n\n [1] 0.22141820 0.17914231 0.01206915 0.03031865 0.04737545 0.03260885\n [7] 0.19398711 0.13336810 0.13911715 0.19899904 0.19247376 0.11293171\n[13] 0.08099210 0.09901700 0.08119775 0.03520808 0.06867550 0.03626262\n\nplot(x = lengths(samples_ls), y = abs(mu - sampleMeans), ylim = c(0, 0.3))"
  },
  {
    "objectID": "lessons/lesson12_purrr.html#mapping-a-defined-function-to-values",
    "href": "lessons/lesson12_purrr.html#mapping-a-defined-function-to-values",
    "title": "Lesson 12: Functional Iteration with purrr",
    "section": "Mapping a Defined Function to Values",
    "text": "Mapping a Defined Function to Values\nThis code was quite cumbersome. We had to measure how long the list was, create an empty atomic vector to hold our results, and then write the FOR loop to iterate over each position in the list of samples. On top of all of this, we’ve added this useless i object to the Global Environment, and the FOR loop lost the names of the samples! There is a better way: the map() function from the purrr package (included in the tidyverse, so remember to load that package):\n\nmap(samples_ls, mean)\n\n$sample_0819\n[1] 1.267616\n\n$sample_0826\n[1] 0.8670559\n\n$sample_0902\n[1] 1.034129\n\n$sample_0909\n[1] 1.076517\n\n$sample_0916\n[1] 0.9988227\n\n$sample_0923\n[1] 1.078807\n\n$sample_0930\n[1] 1.240185\n\n$sample_1007\n[1] 1.179566\n\n$sample_1014\n[1] 1.185315\n\n$sample_1021\n[1] 1.245197\n\n$sample_1028\n[1] 1.238672\n\n$sample_1104\n[1] 1.15913\n\n$sample_1111\n[1] 1.12719\n\n$sample_1118\n[1] 1.145215\n\n$sample_1125\n[1] 1.127396\n\n$sample_1202\n[1] 1.081406\n\n$sample_1209\n[1] 1.114874\n\n$sample_1216\n[1] 1.082461\n\n\n\n\n\n\n\n\nExercises\n\n\n\n\nThis function does return the values we want, but it does so as a list. We would like an atomic vector. Check the help files for this function to find out what to change.\nWhile you are in the help file for map(), find out how to pass in a second argument to the mean() function. Set na.rm = TRUE and test it."
  },
  {
    "objectID": "lessons/lesson12_purrr.html#map-syntax",
    "href": "lessons/lesson12_purrr.html#map-syntax",
    "title": "Lesson 12: Functional Iteration with purrr",
    "section": "map() Syntax",
    "text": "map() Syntax\nIn order to use the map() function and its friends, follow the following syntax: map(.x = VECTOR, .f = FUNCTION). That’s it. For example, to find the summary of each column in the mpg data set, type:\n\nmap(mpg, summary)\n\n$manufacturer\n   Length     Class      Mode \n      234 character character \n\n$model\n   Length     Class      Mode \n      234 character character \n\n$displ\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  1.600   2.400   3.300   3.472   4.600   7.000 \n\n$year\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   1999    1999    2004    2004    2008    2008 \n\n$cyl\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  4.000   4.000   6.000   5.889   8.000   8.000 \n\n$trans\n   Length     Class      Mode \n      234 character character \n\n$drv\n   Length     Class      Mode \n      234 character character \n\n$cty\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   9.00   14.00   17.00   16.86   19.00   35.00 \n\n$hwy\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  12.00   18.00   24.00   23.44   27.00   44.00 \n\n$fl\n   Length     Class      Mode \n      234 character character \n\n$class\n   Length     Class      Mode \n      234 character character \n\n\nThis example shows that the summary() function isn’t very helpful for character information. We are immediately motivated us to ask, “Can I write my own function for map() to use?” The answer is YES!\n\nSample Means with map()\nBack to our first example, we still want to find out how close the sample mean gets to the population mean as we increase the sample size. For this, we write our own function to pass to map(). Recall the function constructor:\n\n# Create the function\nabsMean <- function(xBar_num, mu_num){\n  abs(mean(xBar_num) - mu_num)\n}\n\n# Map it\n# Recall that the help file says that additional arguments to the function\n#   and their values are added after the function name.\nmap_dbl(sampleMeans, absMean, mu_num = mu)\n\n [1] 0.22141820 0.17914231 0.01206915 0.03031865 0.04737545 0.03260885\n [7] 0.19398711 0.13336810 0.13911715 0.19899904 0.19247376 0.11293171\n[13] 0.08099210 0.09901700 0.08119775 0.03520808 0.06867550 0.03626262\n\n\nFor better or for worse, this matches the output of what we calculated using the FOR loop exactly.\n\n\nAn Improved summary()\nWe saw that when we applied summary() to each column of a tibble, the character columns didn’t give us much information. We can then write our own summary function that prints the most common unique values:\n\nMySummaryFun <- function(x){\n  \n  if (is.character(x)){\n    \n    table(x) %>% \n      sort(decreasing = TRUE) %>%\n      head()\n    \n  } else {\n    MyNumericSummaryFun(x)\n  }\n  \n}\n\nNow we can apply it to the mpg data set:\n\nmap(mpg, MySummaryFun)\n\n$manufacturer\nx\n     dodge     toyota volkswagen       ford  chevrolet       audi \n        37         34         27         25         19         18 \n\n$model\nx\n        caravan 2wd ram 1500 pickup 4wd               civic   dakota pickup 4wd \n                 11                  10                   9                   9 \n              jetta             mustang \n                  9                   9 \n\n$displ\n     Min   Q1.25%   Median     Mean   Q3.75%      Max   StdDev      IQR \n1.600000 2.400000 3.300000 3.471795 4.600000 7.000000 1.291959 2.200000 \n\n$year\n        Min      Q1.25%      Median        Mean      Q3.75%         Max \n1999.000000 1999.000000 2003.500000 2003.500000 2008.000000 2008.000000 \n     StdDev         IQR \n   4.509646    9.000000 \n\n$cyl\n     Min   Q1.25%   Median     Mean   Q3.75%      Max   StdDev      IQR \n4.000000 4.000000 6.000000 5.888889 8.000000 8.000000 1.611534 4.000000 \n\n$trans\nx\n  auto(l4) manual(m5)   auto(l5) manual(m6)   auto(s6)   auto(l6) \n        83         58         39         19         16          6 \n\n$drv\nx\n  f   4   r \n106 103  25 \n\n$cty\n      Min    Q1.25%    Median      Mean    Q3.75%       Max    StdDev       IQR \n 9.000000 14.000000 17.000000 16.858974 19.000000 35.000000  4.255946  5.000000 \n\n$hwy\n      Min    Q1.25%    Median      Mean    Q3.75%       Max    StdDev       IQR \n12.000000 18.000000 24.000000 23.440171 27.000000 44.000000  5.954643  9.000000 \n\n$fl\nx\n  r   p   e   d   c \n168  52   8   5   1 \n\n$class\nx\n       suv    compact    midsize subcompact     pickup    minivan \n        62         47         41         35         33         11 \n\n\nIt’s not terribly pretty (I am not a fan of the table() function), but it gives us a reasonable idea of what is going on in these columns.\n\n\n\n\n\n\nExercises\n\n\n\n\nCreate a sequence of sample sizes from 5 to 500 by 5. Save this vector of sample sizes. Hint: look up the help files for sequence(). You will find the function you need mentioned therein.\nUse the map() function combined with the sequence you just created to make a list of samples with increasing sizes from the population vector. Store it as another list of samples. This should make typing that list by hand obsolete.\nUse the map_dbl() function combined with the absMean() function we created to calculate the atomic vector of absolute differences from the sample mean. At what sample size does the estimate get better?\nFind one of the statistics / biostatistics students and contrast this process with the idea of “repeated sampling”. What is different here? Why doesn’t the traditional \\(n = 30\\) heuristic apply?\nRepeat the above process with the following modification: chain these operations together with pipes (%>%)."
  },
  {
    "objectID": "lessons/lesson12_purrr.html#split-the-gapminder-data-by-country",
    "href": "lessons/lesson12_purrr.html#split-the-gapminder-data-by-country",
    "title": "Lesson 12: Functional Iteration with purrr",
    "section": "Split the Gapminder Data by Country",
    "text": "Split the Gapminder Data by Country\nThe split() function is from base R. It takes in a tibble and breaks it into a list of tibbles by the elements of the column you specify (in this case, the column will be country).\n\ncountries_ls <- split(\n  x = gapminder,\n  f = ~ country\n)\n\nWe are familiar with this data set, but let’s take a look at our split data anyway.\n\n# First 3 countries\ncountries_ls[1:3]\n\n$Afghanistan\n# A tibble: 12 × 6\n   country     continent  year lifeExp      pop gdpPercap\n   <fct>       <fct>     <int>   <dbl>    <int>     <dbl>\n 1 Afghanistan Asia       1952    28.8  8425333      779.\n 2 Afghanistan Asia       1957    30.3  9240934      821.\n 3 Afghanistan Asia       1962    32.0 10267083      853.\n 4 Afghanistan Asia       1967    34.0 11537966      836.\n 5 Afghanistan Asia       1972    36.1 13079460      740.\n 6 Afghanistan Asia       1977    38.4 14880372      786.\n 7 Afghanistan Asia       1982    39.9 12881816      978.\n 8 Afghanistan Asia       1987    40.8 13867957      852.\n 9 Afghanistan Asia       1992    41.7 16317921      649.\n10 Afghanistan Asia       1997    41.8 22227415      635.\n11 Afghanistan Asia       2002    42.1 25268405      727.\n12 Afghanistan Asia       2007    43.8 31889923      975.\n\n$Albania\n# A tibble: 12 × 6\n   country continent  year lifeExp     pop gdpPercap\n   <fct>   <fct>     <int>   <dbl>   <int>     <dbl>\n 1 Albania Europe     1952    55.2 1282697     1601.\n 2 Albania Europe     1957    59.3 1476505     1942.\n 3 Albania Europe     1962    64.8 1728137     2313.\n 4 Albania Europe     1967    66.2 1984060     2760.\n 5 Albania Europe     1972    67.7 2263554     3313.\n 6 Albania Europe     1977    68.9 2509048     3533.\n 7 Albania Europe     1982    70.4 2780097     3631.\n 8 Albania Europe     1987    72   3075321     3739.\n 9 Albania Europe     1992    71.6 3326498     2497.\n10 Albania Europe     1997    73.0 3428038     3193.\n11 Albania Europe     2002    75.7 3508512     4604.\n12 Albania Europe     2007    76.4 3600523     5937.\n\n$Algeria\n# A tibble: 12 × 6\n   country continent  year lifeExp      pop gdpPercap\n   <fct>   <fct>     <int>   <dbl>    <int>     <dbl>\n 1 Algeria Africa     1952    43.1  9279525     2449.\n 2 Algeria Africa     1957    45.7 10270856     3014.\n 3 Algeria Africa     1962    48.3 11000948     2551.\n 4 Algeria Africa     1967    51.4 12760499     3247.\n 5 Algeria Africa     1972    54.5 14760787     4183.\n 6 Algeria Africa     1977    58.0 17152804     4910.\n 7 Algeria Africa     1982    61.4 20033753     5745.\n 8 Algeria Africa     1987    65.8 23254956     5681.\n 9 Algeria Africa     1992    67.7 26298373     5023.\n10 Algeria Africa     1997    69.2 29072015     4797.\n11 Algeria Africa     2002    71.0 31287142     5288.\n12 Algeria Africa     2007    72.3 33333216     6223.\n\n# Operations on a specific country\ncountries_ls$Cameroon\n\n# A tibble: 12 × 6\n   country  continent  year lifeExp      pop gdpPercap\n   <fct>    <fct>     <int>   <dbl>    <int>     <dbl>\n 1 Cameroon Africa     1952    38.5  5009067     1173.\n 2 Cameroon Africa     1957    40.4  5359923     1313.\n 3 Cameroon Africa     1962    42.6  5793633     1400.\n 4 Cameroon Africa     1967    44.8  6335506     1508.\n 5 Cameroon Africa     1972    47.0  7021028     1684.\n 6 Cameroon Africa     1977    49.4  7959865     1783.\n 7 Cameroon Africa     1982    53.0  9250831     2368.\n 8 Cameroon Africa     1987    55.0 10780667     2603.\n 9 Cameroon Africa     1992    54.3 12467171     1793.\n10 Cameroon Africa     1997    52.2 14195809     1694.\n11 Cameroon Africa     2002    49.9 15929988     1934.\n12 Cameroon Africa     2007    50.4 17696293     2042.\n\nmax(countries_ls$Cameroon$lifeExp)\n\n[1] 54.985"
  },
  {
    "objectID": "lessons/lesson12_purrr.html#apply-a-method-to-each-countrys-data",
    "href": "lessons/lesson12_purrr.html#apply-a-method-to-each-countrys-data",
    "title": "Lesson 12: Functional Iteration with purrr",
    "section": "Apply a Method to Each Country’s Data",
    "text": "Apply a Method to Each Country’s Data\nNow, if we wanted to find country-specific summaries of life expectancy, we can:\n\nlifeExpSummary_ls <- \n  map(\n    # Only show the first 5 for the example\n    .x = countries_ls,\n    .f = \"lifeExp\"\n  ) %>% \n  map(MyNumericSummaryFun)\n\nlifeExpSummary_ls[1:5]\n\n$Afghanistan\n      Min    Q1.25%    Median      Mean    Q3.75%       Max    StdDev       IQR \n28.801000 33.514250 39.146000 37.478833 41.696250 43.828000  5.098646  8.182000 \n\n$Albania\n      Min    Q1.25%    Median      Mean    Q3.75%       Max    StdDev       IQR \n55.230000 65.870000 69.675000 68.432917 72.237500 76.423000  6.322911  6.367500 \n\n$Algeria\n     Min   Q1.25%   Median     Mean   Q3.75%      Max   StdDev      IQR \n43.07700 50.63100 59.69100 59.03017 68.09600 72.30100 10.34007 17.46500 \n\n$Angola\n      Min    Q1.25%    Median      Mean    Q3.75%       Max    StdDev       IQR \n30.015000 35.488750 39.694500 37.883500 40.726000 42.731000  4.005276  5.237250 \n\n$Argentina\n     Min   Q1.25%   Median     Mean   Q3.75%      Max   StdDev      IQR \n62.48500 65.51100 69.21150 69.06042 72.21975 75.32000  4.18647  6.70875 \n\n\n\n\n\n\n\n\nExercise\n\n\n\nWe wrote the function MySummaryFun() to be able to take the summary of any column, numeric or otherwise. Modify the code above so that we can find the summaries of ALL the columns within the data set specific to each country. Make sure your code works for just the first 5 countries."
  },
  {
    "objectID": "lessons/lesson12_purrr.html#combine-the-results",
    "href": "lessons/lesson12_purrr.html#combine-the-results",
    "title": "Lesson 12: Functional Iteration with purrr",
    "section": "Combine the Results",
    "text": "Combine the Results\nWe have a list of the numeric summaries of life expectancy for each of the 142 countries. Let’s combine these results. First, we check the class of the individual list elements:\n\nclass(lifeExpSummary_ls[[1]])\n\n[1] \"numeric\"\n\n\nThe elements of the vector are numeric. If we want to end up with a tibble that has one row for each country, then the elements should first be transformed to be a one-row tibble. Unfortunately, there is not a standard as_*() function that will turn a named numeric vector into a one-row tibble. However, (very confusingly) the bind_rows() function will turn a named atomic vector into a one-row tibble. Let’s test it out:\n\n# Original named atomic vector\nlifeExpSummary_ls$Afghanistan\n\n      Min    Q1.25%    Median      Mean    Q3.75%       Max    StdDev       IQR \n28.801000 33.514250 39.146000 37.478833 41.696250 43.828000  5.098646  8.182000 \n\n# Tibble with one row\nbind_rows(lifeExpSummary_ls$Afghanistan)\n\n# A tibble: 1 × 8\n    Min `Q1.25%` Median  Mean `Q3.75%`   Max StdDev   IQR\n  <dbl>    <dbl>  <dbl> <dbl>    <dbl> <dbl>  <dbl> <dbl>\n1  28.8     33.5   39.1  37.5     41.7  43.8   5.10  8.18\n\n\nNow that we know this will work for one country, we can add it into a pipeline for all the countries. Then, calling the bind_rows() function as we would expect, we will end up with a tibble with a row for each country and 8 columns:\n\nlifeExpSummary_df <- \n  lifeExpSummary_ls %>% \n  map(bind_rows) %>% \n  bind_rows(.id = \"country\")\n\nlifeExpSummary_df\n\n# A tibble: 142 × 9\n   country       Min `Q1.25%` Median  Mean `Q3.75%`   Max StdDev   IQR\n   <chr>       <dbl>    <dbl>  <dbl> <dbl>    <dbl> <dbl>  <dbl> <dbl>\n 1 Afghanistan  28.8     33.5   39.1  37.5     41.7  43.8   5.10  8.18\n 2 Albania      55.2     65.9   69.7  68.4     72.2  76.4   6.32  6.37\n 3 Algeria      43.1     50.6   59.7  59.0     68.1  72.3  10.3  17.5 \n 4 Angola       30.0     35.5   39.7  37.9     40.7  42.7   4.01  5.24\n 5 Argentina    62.5     65.5   69.2  69.1     72.2  75.3   4.19  6.71\n 6 Australia    69.1     71.1   74.1  74.7     77.9  81.2   4.15  6.82\n 7 Austria      66.8     70.0   72.7  73.1     76.4  79.8   4.38  6.42\n 8 Bahrain      50.9     59.2   67.3  65.6     72.9  75.6   8.57 13.8 \n 9 Bangladesh   37.5     42.9   48.5  49.8     56.9  64.1   9.03 14.0 \n10 Belgium      68       70.8   73.4  73.6     76.7  79.4   3.78  5.96\n# ℹ 132 more rows\n\n\n\n\n\n\n\n\nExercise\n\n\n\n\nIn the last exercise, we found the summaries of all the features for each country (not just the numeric ones). Can these results be combined into a single tibble? Why or why not?\nRead the help file for the bind_rows() function. What does the .id argument do? Is this a default behaviour?\nTake the summary of life expectancy table above, and join it back to gapminder_df to add a column for the continent to our results. Plot a boxplot of the 75th percentile of life expectancy by continent."
  },
  {
    "objectID": "lessons/lesson12_purrr.html#example-back-to-tornados",
    "href": "lessons/lesson12_purrr.html#example-back-to-tornados",
    "title": "Lesson 12: Functional Iteration with purrr",
    "section": "Example: Back to Tornados",
    "text": "Example: Back to Tornados\nFinally, one of the most valuable applications of this technique is to import and analyze multiple data files all at once. As long as our computer is well organized, we can set a map() call to import all of the data files in a particular sub-directory. In the code below, you’ll need to change the file path to meet your own directory structure.\n\n# Review: how to import a single data set with readr::\ntornados08_df <- read_csv(file = \"../_data/purrr_example_data/2008_torn.csv\")\n\nRows: 1738 Columns: 29\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr   (1): st\ndbl  (26): om, yr, mo, dy, tz, stf, stn, mag, inj, fat, loss, closs, slat, s...\ndate  (1): date\ntime  (1): time\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n# Create a VECTOR of the names AND paths to the data sets\ndataPaths_char <- list.files(\n  path = \"../_data/purrr_example_data/\", \n  full.names = TRUE\n)\nnames(dataPaths_char) <- list.files(\n  path = \"../_data/purrr_example_data/\", \n  full.names = FALSE\n)\n\nNow that we have a vector of the file paths to the tornadoes data, we can write a map() call that imports each data file as an element of a list of tibbles.\n\ntornadoData_ls <- map(\n  .x = dataPaths_char,\n  .f = read_csv\n)\n\n\n\n\n\n\n\nExercise\n\n\n\n\nFor each year, find the set of states where a tornado was recorded (the state abbreviations are in the column st).\nIs the output you got in the last question “professional”? (Probably not). Modify your code to:\n\nCreate a table of the number of tornados by state for each year\nCreate a vector of the state abbreviations where a tornado occured for each year"
  },
  {
    "objectID": "lessons/lesson05_RStudio_projects.html",
    "href": "lessons/lesson05_RStudio_projects.html",
    "title": "Lesson 5: RStudio Projects",
    "section": "",
    "text": "What did we learn last class?\n\nThe Layered Grammar of Graphics\nLoading a Package\nMy First ggplot\nMapping Aesthetics\nGeometric Objects\nLabels\nColor palettes and examples"
  },
  {
    "objectID": "lessons/lesson05_RStudio_projects.html#everything-is-an-object",
    "href": "lessons/lesson05_RStudio_projects.html#everything-is-an-object",
    "title": "Lesson 5: RStudio Projects",
    "section": "Everything is an Object",
    "text": "Everything is an Object\nFor the computer programmers out there, R is neither a purely “object-oriented” (OOP) language nor a purely “functional” (FP) language, but shows behaviour from both schools. For everyone else who either doesn’t know or doesn’t care about the OOP v FP distinction, this is the last we’ll talk about it. Remember this, however, everything in R is an object."
  },
  {
    "objectID": "lessons/lesson05_RStudio_projects.html#object-names",
    "href": "lessons/lesson05_RStudio_projects.html#object-names",
    "title": "Lesson 5: RStudio Projects",
    "section": "Object Names",
    "text": "Object Names\nAs Shakespeare famously penned,\n\nWhat’s in a name? That which we call a rose\nBy any other word would smell as sweet.\nRomeo and Juliet, Act 2, Scene 2\n\nUnfortunately for us, computer programmers were never very good at Shakespeare, so names are very important in writing good code. Look back to our two examples. Our objects are named myMessage_char and myAge_num. If you are reading my code, could you guess what those two things are? My age and my message, right? What about if we had named the objects Stuff, stuff, x, x1, morestuff, X, or omgNeedCoffee? Notice that cAsE MaTtErS. Use names that are short, but descriptive. There are a few conventions for naming things:\n\nsnake_case\ncamelCase\nperiod.case\naBsoLUTE.andCOMPLETE_utternonsense\n\nNotice another thing about my object names: they all end with a brief tag explaining what type of object they are (we will cover object classes in more detail next lesson). myMessage_char is a character string, while myAge_num is a number (numeric, technically). I recommend using camelCase followed by an abbreviation for the type of the object, but you can pick whatever convention you like (but please be consistent).\n\n\n\n\n\n\nExercises\n\n\n\n\nYou have imported a spreadsheet of phenotype data for subjects with colorectal adenocarcinoma. What are some good names for this data set?\nYou save a subset of the above data set with all HIV-positive males. Name this data set."
  },
  {
    "objectID": "lessons/lesson05_RStudio_projects.html#basic-function-syntax",
    "href": "lessons/lesson05_RStudio_projects.html#basic-function-syntax",
    "title": "Lesson 5: RStudio Projects",
    "section": "Basic Function Syntax",
    "text": "Basic Function Syntax\nMost R functions look like this: functionName(argument1 = value1, argument2 = value2, ...). This function is an object called functionName. We don’t know what it does, because the operations of the function are stored within the object functionName. We do know that it takes in two arguments with two values, and does something to them. Let’s use a function to create our first matrix (I’ve annotated the code to show its similarities with an English sentence):\n\n# object      verb   subject1  adverb1   adverb2\nmyData_mat <- matrix(data = 0, nrow = 5, ncol = 2)\nmyData_mat\n\n     [,1] [,2]\n[1,]    0    0\n[2,]    0    0\n[3,]    0    0\n[4,]    0    0\n[5,]    0    0\n\n\nNotice a few things. We used a function called matrix (a verb) with three arguments (data, nrow, and ncol). This function did some things behind the scenes (as defined in the object matrix), and returned an output. This output is a matrix of zeroes (the “noun”) with two columns and five rows (adverbs controlling how the verb should work; not all functions use additional arguments to change their behaviour, but most do). The data input was recycled to fill the entire matrix.\n\n\n\n\n\n\nExercise\n\n\n\nLabel the “subjects”, “verbs”, “adverbs”, and “objects” in the following code:\n\nggplot(data = mpg) +\n  aes(x = displ, y = hwy) +\n  geom_point()"
  },
  {
    "objectID": "lessons/lesson05_RStudio_projects.html#our-first-function",
    "href": "lessons/lesson05_RStudio_projects.html#our-first-function",
    "title": "Lesson 5: RStudio Projects",
    "section": "Our First Function",
    "text": "Our First Function\nSo far, we have only used functions that R provided for us or functions out of supplemental R packages. However, there are many instances where we need to create our own functions. Because we know that functions are also objects, we can create them just like anything else: with a creation function. Function creation has the following syntax:\n\nmyFun_fun <- function(argument1){\n  \n  body\n  \n}\n\nWe can use this syntax to create a function to add two numbers (obviously this function already exists, but bear with me).\n\nmySum_fun <- function(x, y){ x + y }\nmySum_fun(2, 3)\n\n[1] 5\n\n\nWe can create many of our own functions, and use these functions to accomplish very difficult tasks. This flexibility to create any function we can think of is one of R’s greatest strengths, but also part of what gives R its distinct learning curve.\n\n\n\n\n\n\nExercises\n\n\n\n\nCreate a new function to greet someone good morning. The argument of your function should be who, and it’s value should be a character. Hint: look up the help file for the paste() function.\nModify your function so that it will greet you by default (with no argument value supplied to the who argument)."
  },
  {
    "objectID": "lessons/lesson05_RStudio_projects.html#function-best-practices",
    "href": "lessons/lesson05_RStudio_projects.html#function-best-practices",
    "title": "Lesson 5: RStudio Projects",
    "section": "Function Best Practices",
    "text": "Function Best Practices\nBecause R is a functional language, the functions you write should be the most important pieces of your code. Functions in R, through their inherent vectorized efficiency, turn this\nlsum <- 0\nfor (i in 1:length(x)) {\n  lsum <- lsum + log(x[i])\n}\ninto this\nlsum <- sum(log(x))\n(This and other mortal R sins are covered in The R Inferno.) R is a functional programming language, so you must learn to use functions in your code. Furthermore, while this isn’t required, you should probably think about collecting the functions you write into a package. Here are some guidelines on writing functions:\n\nFunctions should do one major thing, only that thing, and that thing well. A function that does a million things is easy to break and horribly difficult to check. Keep your functions simple, and you will not regret it.\nMajor functions should be saved in their own script files. This encourages your project code to be compartmentalized and organized. For projects, this is very important for testing and organization. Overall, I strongly recommend you do not store all of your functions in one file. If you have a ton of functions to source all at once, create a package. Even if you never plan to release the code to anyone outside your group, create a package anyway.\nUtility functions can be collected into one file. Because you probably do not need extensive documentation or checking of utility functions, you can store all related utility functions together."
  },
  {
    "objectID": "lessons/lesson05_RStudio_projects.html#documenting-your-functions",
    "href": "lessons/lesson05_RStudio_projects.html#documenting-your-functions",
    "title": "Lesson 5: RStudio Projects",
    "section": "Documenting your Functions",
    "text": "Documenting your Functions\nCode comments are the glue that hold a collaboration team together across time and space. You write comments to three people: yourself today, yourself in six months, and people who have never seen your code. These comments will include:\n\nthe function name and description,\nnames and descriptions for each argument to the function,\na description of what the function returns,\na thorough commentary on how the function works,\nat least one working example, and\ncitation, external links, internal links, etc. all as appropriate.\n\nComments always have a single space between the comment character (#) and the start of the comment. If your functions are not saved within a package, add these same comments as the first lines within your function. This ensures that the comments about the function always travel with the function.\nExample:\nCalculateSampleCovariance <- function(x, y, verbose = TRUE) {\n  # Computes the sample covariance between two vectors.\n  #\n  # Args:\n  #   x: One of two vectors whose sample covariance is to be calculated.\n  #   y: The other vector. x and y must have the same length, greater than one,\n  #      with no missing values.\n  #   verbose: If TRUE, prints sample covariance as a sentence; if not, not. \n  #      Default is TRUE.\n  #\n  # Returns:\n  #   The sample covariance between x and y.\n  # \n  # Example:\n  # CalculateSampleCovariance(x = rnorm(10), y = rnorm(10))\n  \n  \n  n <- length(x)\n  # Error handling\n  if (n <= 1 || n != length(y)) {\n    stop(\"Arguments x and y have different lengths: \",\n         length(x), \" and \", length(y), \".\")\n  }\n  if (TRUE %in% is.na(x) || TRUE %in% is.na(y)) {\n    stop(\" Arguments x and y must not have missing values.\")\n  }\n  covariance <- var(x, y)\n  if (verbose)\n    cat(\"The covariance is \", round(covariance, 4), \".\\n\", sep = \"\")\n  return(covariance)\n}"
  },
  {
    "objectID": "lessons/lesson05_RStudio_projects.html#a-new-r-script",
    "href": "lessons/lesson05_RStudio_projects.html#a-new-r-script",
    "title": "Lesson 5: RStudio Projects",
    "section": "A New R Script",
    "text": "A New R Script\nLet’s start a new script:\n\nGo to File > New File > R Script\nType “Hello from my first Script!”\nWith your cursor on the line you typed, press CTRL + ENTER to run your code.\n\nYou will notice that \"Hello from my first Script!\" appeared in the Console below, and your cursor moved to a new line in your script. You can write new commands and run them, or you can move your cursor back up to the previous line to edit the code that you’ve written."
  },
  {
    "objectID": "lessons/lesson05_RStudio_projects.html#code-paragraph-rules",
    "href": "lessons/lesson05_RStudio_projects.html#code-paragraph-rules",
    "title": "Lesson 5: RStudio Projects",
    "section": "Code “Paragraph” Rules",
    "text": "Code “Paragraph” Rules\nJust like written paragraphs in English have certain rules, code scripts also have rules and best practices to help keep your work organized. Let’s consider an example data analysis for argument’s sake. We need to import the data, clean it, wrangle it (more on this next class), analyze it, and graph the results.\nThese rules are loosely ordered by importance:\n\nAll the code in one script should be related to one subtopic of your analysis. For instance, in the data analysis example above, we would create a seperate script for data import and cleaning, a script for wrangling and transformation, an analysis script, and a graphics script.\nScripts should be named (and often dated) based on what part of the workflow they handle. For example, the analysis script may be called breast_cancer_data_analysis_201906.R. Ordered files in a project pipeline should have leading numbers (00_clean_raw_data.R, 01_explore_clean_data.R, …) to keep presentation orderly.\nPartition chunks, or blocks, of code into sections with six pound signs on either side of a block title. This helps to keep your thoughts organized. Many times I will see that a code block has become very large, which prompts me that it should be it’s own script. In the RStudio IDE, when you name a code block, the name of that block will appear in the bottom left of the Editor pane, right next to the code GPS. If you haven’t organized your script into chunks yet, you should see (Top Level) or Untitled in this space. Here’s an example:\n\n######  New Code Section  #####################################################\n# A new code section in an R script is created with six pound signs (#), two\n#   spaces, the section description, two more spaces, and pound signs until the\n#   80th character slot is reached.\n\nNon-trivial code should be annotated with helpful or clarifying comments. Use the # (pound sign, or hashtag, depending on your age) to comment a single line of code in R. When you add comments to your code, try as much as possible to answer why you wrote the code that you did and the way you did, rather than simply parroting what your line of code does. Remember, comments should never simply “parrot” the code.\nLines in your script should be at or fewer than 80 characters wide whenever possible. You can use the “Code GPS” on the bottom left of the Editor pane to tell you where in the script you are. Why 80 characters per line? Because we are slaves to tradition. Different people have different size computer monitors, and lines that are 80 characters wide can easily be displayed on all sorts of screens. Also, 80-character lines fit on a printed page or in vignette PDFs very well. This rule serves another purpose: if your lines are consistently over 80 characters, this is a signal to you that you need to make your code simpler. If this is not possible, then think of this as an opportunity to write a function to make your code cleaner.\nUse two spaces (no tabs) for indentation. If you ever decide to release a package, then spacing becomes important for R documentation and meta-data files. It’s good to get into the habit of using the “two-space” indentation rule in any case; also, the RStudio IDE does this for you automatically most of the time.\nPad all operator calls with single spaces. Similar to the “80 characters wide” rule, this rule has no bearing on how the code executes, but makes a world of difference to human readability. An exception is commas: commas have one space after but no space before. Overall, don’tmakecodehardertoreadthanithastobe, and GIVE YOUR CODE SOME SPACE. Examples:\n\nrandErr_num <- rnorm(25, sd = 0.1) instead of randErr_num<-rnorm(25,sd=0.1).\nloss <- 3 or loss < -3 instead of loss<-3.\nif (check) { instead of if(check){\n\nMinutiae: Use <- for assignment, not =. Do not end lines with ;. Use double quotes instead of single quotes."
  },
  {
    "objectID": "lessons/lesson05_RStudio_projects.html#an-example",
    "href": "lessons/lesson05_RStudio_projects.html#an-example",
    "title": "Lesson 5: RStudio Projects",
    "section": "An Example",
    "text": "An Example\nI’ll now show you some code that breaks some of these rules, and then some code that follows these rules.\n\nBad Code Formatting\n\n\n\n\n\n\n\nExercise\n\n\n\nTalk with your neighbours. Can you figure out what this code is doing? Could you modify it for your own use? How could you make this script better?\n\n\n\n\nBetter Code Formatting\n\nWe will come back to this script later in the semester to make this even better.\n\n\n\n\n\n\nExercise\n\n\n\nOpen one of your previous scripts. Swap your computer with your neighbour. Have your neighbour point out some of the formatting mistakes, and you do the same for theirs."
  },
  {
    "objectID": "lessons/lesson05_RStudio_projects.html#project-directory",
    "href": "lessons/lesson05_RStudio_projects.html#project-directory",
    "title": "Lesson 5: RStudio Projects",
    "section": "Project Directory",
    "text": "Project Directory\nInstead, organize your files by project. These directory names and contents are quite flexible. However, you should pick a directory design and be consistent with it. Here’s an example directory:\n\nThe project directory is for my lectures in the Quantitative Science Clinics for the Sylvester Comprehensive Cancer Center at the University of Miami. Within this directory, I have the following folders:\n\nCode (miscellaneous) or scripts. These are the code scripts to import and clean the data, perform the analysis, tidy the output, create figures and tables, and save the results. Remember, all of these scripts should be related to the current project!\nPackage directory for the project (optional). If you created a package (pipeline) to analyze any data of a certain type, the package should be in the directory you use it (unless it’s a pipeline you use for many different projects, then it should probably be hosted on GitHub).\nRaw and clean data. Any input files go in this folder (even if you pre-process them). Unless the point of your project is to simply clean data, then cleaned data is not an output!\nArticles, user guides, or manuals (often for the literature review of the manuscript or report that you will write to accompany the project). These are the papers, books, articles, etc. you had to read to understand the project. This directory should also include setup documentation from your PI and any data dictionaries. Any written documentation that helped you set up your work or understand your team’s work goes here. Also, this is where you save the bibliography files.\nWritten summaries and manuscript files (drafts, LaTeX logs, etc.). When writing a LaTeX manuscript or an .html report, I usually put each draft in its own subfolder. Also, when you write papers, make sure to mark the draft number as the first two characters of the file name; e.g. 01-draft_modifiedPCA.docx, 02-draft_modifiedPCA.docx. I’ve often seen that one number isn’t enough (only 9 potential drafts). This keeps you from wasting time looking for the latest version.\nProject README. This should be a simple text (.txt) or markdown (.md) file that explains what the point of the project is, and where to find all of the important files. Also, this document should have the start date of the project, the date of the most recent major revision, and the names and emails of your main collaborators. This way, if you reference a “Mandy” somewhere in your notes or file names, everyone know you’re talking about “Amanda from the statistics department”.\nFigures and tables (output files). If your paper has a results section, all that information goes here. Everything that is an “end” of an analysis goes here.\nRStudio Project File. If I were to double-click on this file, RStudio would open with all of my files that I was working in when I last saved that project. When you use RStudio projects, you don’t have to remember all the files you had in use and manually re-open them. I recommend that as soon as you have more that one script (or a single long script that you really should have broken into a few different scripts already—jeez), you create an RStudio project to organize your files."
  },
  {
    "objectID": "lessons/lesson05_RStudio_projects.html#do-not-save-your-workspace",
    "href": "lessons/lesson05_RStudio_projects.html#do-not-save-your-workspace",
    "title": "Lesson 5: RStudio Projects",
    "section": "DO NOT: Save your workspace",
    "text": "DO NOT: Save your workspace\nGet in the habit of starting the day’s work with a fresh environment. This will reduce the “it worked on my machine” errors considerably. You want to periodically restart R and re-run your scripts to ensure that the code results you are seeing aren’t the result of some hidden artefact or forgotten object definition. I restart my R session and re-run my scripts around once per hour or so. To quote the masters,\n\nWith your R scripts (and your data files), you can recreate the environment. It’s much harder to recreate your R scripts from your environment! You’ll either have to retype a lot of code from memory (making mistakes all the way) or you’ll have to carefully mine your R history. - Wickam and Grolemund, R for Data Science\n\nTo this end, I strongly recommend you remove the “restore workspace” option in RStudio (“Tools”” /> “Global Options”).\n\nThe keyboard shortcut for “restart and rerun” is CTRL + SHIFT + 0 (restart) then CTRL + SHIFT + S (source the current script). On a Mac, replace CTRL with CMD for the same effect."
  },
  {
    "objectID": "lessons/lesson05_RStudio_projects.html#do-create-a-project",
    "href": "lessons/lesson05_RStudio_projects.html#do-create-a-project",
    "title": "Lesson 5: RStudio Projects",
    "section": "DO: Create a Project",
    "text": "DO: Create a Project\nSo that you don’t painfully lose your work every time you restart, RStudio offers built-in project creation. Once you have a directory with a few scripts, data files, output files, and / or graphs, create a project to hold it all.\n\nGo to File > New Project\nSelect the “Existing Directory” option\n\nIn the “Project Working Directory”, click “Browse” and find the directory with your scripts and data files.\n\nClick “Create Project”\n\nNow, any work you do in that project will be associated with your previous work. All your files stay nice and organized. You will use this project to store figures for your publications, as well as the scripts you used to create them. This means that the next time your pesky reviewer asks you to change a plot label, you don’t have to deal with editing the .JPG or .PDF file—you can simply re-run the code to build a new picture! Your data files, analysis scripts, output .csv’s, and publication graphics all stay together under the project banner.\n\n\n\n\n\n\nExercises\n\n\n\n\nCreate a folder for your work in this class.\nCreate organized subfolders similar to what we discussed in class. The names and purposes for these folders are your prerogative.\nRead this article for tips on organizing your files: https://business.tutsplus.com/tutorials/how-to-organize-computer-files--cms-32191. I recommend project based folders with use-type subfolders. For example, I have a directory called “Teaching”, with a subdirectory for this class. That subdirectory is organized by the type or use of the files: “admin” for attendance, syllabus, and course schedule, “lectures” for my class notes, etc.\nWrite an organization plan that you can stick with.\nOrganize all the files on your computer. Start with your files and folders for your current degree. This will probably take a few days if you’ve never done it before. It could take a few hours if you haven’t done it recently."
  },
  {
    "objectID": "lessons/lesson02s_scripts.html",
    "href": "lessons/lesson02s_scripts.html",
    "title": "Lesson 2 Supplement: R Scripts",
    "section": "",
    "text": "So far, if you needed to repeat all of the work you have done today, you would be in serious trouble! If we can repeat what we did, then we certainly can’t call our work reproducible. One simple thing we can do, is to write our code in a script.\n\n\nTo create a new script, go to “File” > “New File” > “R Script”. The keyboard shortcut for this is CTRL + Shift + N on Windows, and CMD + Shift + N on Mac. You should now have a window that looks like this:\n\nAt the top of your script, you should include information about who wrote the script, when it was written, and why. Note that this information is a special form of code comment, and should be marked as such.\n\n\n\n\n\n\nExercises\n\n\n\n\nCreate a new script to run some of the commands you learned in Lesson 2. Add the meta-information at the top of your script. Notice that the colour of the file name changed from black to red.\nAdd some of the code from that lesson (a few operations).\nAdd comments explaining to yourself what these operations are doing.\nSave your script with a good name, and—if possible–today’s date (in a computer-sortable format). Notice that your file name font colour changed from red back to black. Why? Mac Users: make sure you add .R to the end of your file name.\n\n\n\nThis is what mine looks like:\n\nAs you learn more about R, your comments should quickly become more about why you did what you did, rather than what you did."
  },
  {
    "objectID": "lessons/lesson08_Data_Read_Write.html",
    "href": "lessons/lesson08_Data_Read_Write.html",
    "title": "Lesson 8: Importing Tidy Data",
    "section": "",
    "text": "What did we learn last class?\n\nLists\nTibbles and Data Frames\nPositional Subsetting\nRelational Subsetting\nNamed Subsetting"
  },
  {
    "objectID": "lessons/lesson08_Data_Read_Write.html#a-quick-comment-to-begin",
    "href": "lessons/lesson08_Data_Read_Write.html#a-quick-comment-to-begin",
    "title": "Lesson 8: Importing Tidy Data",
    "section": "A Quick Comment to Begin…",
    "text": "A Quick Comment to Begin…\nWhen you use the RStudio IDE, you have access to a point-and-click data import guide for data files in many different forms. Such forms include tab-seperated, fixed-width, .csv, Stata, SAS, SPSS, Excel, and many others. A word of caution: you should practice importing the your data with the read_fwf(), read_delim, or read_csv functions (from the readr package) using the point-and-click RStudio interface. At each import, copy the code you build in the interactive window into a script so that you can see how the functions work. Once you are familiar with how these functions treat your data, then you can start writing the readr functions directly within a script instead of using the point-and-click RStudio IDE importing steps.\nIf you have never imported data before, this can be one of the most challenging tasks in data science. Also, read R4DS Chapter 11, which covers importing data from a variety of sources. I have seen many problems in code because a tiny little piece of data was imported incorrectly, and this mistake wormed its way through an entire analysis. Don’t let this happen to you."
  },
  {
    "objectID": "lessons/lesson08_Data_Read_Write.html#example-data-food-stamp-usage-by-zip-code",
    "href": "lessons/lesson08_Data_Read_Write.html#example-data-food-stamp-usage-by-zip-code",
    "title": "Lesson 8: Importing Tidy Data",
    "section": "Example Data: Food Stamp Usage by ZIP Code",
    "text": "Example Data: Food Stamp Usage by ZIP Code\nIn order to plot food stamp usage by ZIP code, we first need data.\n\nMiami-Dade and Broward County ZIP Codes\nAll of the ZIP codes in Broward and Miami Data counties and are online: https://www.zip-codes.com/county/fl-broward.asp and https://www.zip-codes.com/county/fl-miami-dade.asp, respectively. They are stored in tables that look like this: \n\n\n\n\n\n\nExercise\n\n\n\nFor Miami-Dade and Broward counties, go to the websites above, highlight all the data in the table, copy it, paste it into a basic text editor (like Notepad or TextEdit), and save it into your directory for this class in your “data” folder (or whatever you named the folder for your data).\n\n\nYou will end up with a .txt file that should look like this: \n\n\nFood Stamps by ZIP Code\nFor data on households receiving Supplemental Nutrition Assistance Program (SNAP) benefits, we check with the US Census Bureau: https://data.census.gov/table\n\n\n\n\n\n\nExercise: Download SNAP Data by ZIP\n\n\n\nDownload the ACS data on food stamp benefits by ZIP code (you may need to disable your pop-up blocker first):\n\nUnder the “Geography” Filter heading, choose the option labelled “ZIP Code Tabulation Area”. Select the state of Florida, then check the box “All 5-digit ZIP Code Tabulation Areas fully/partially within Florida”.\nUnder the “Topics” Filter heading, choose the option labelled “Income and Poverty”. Click the “Income and Earnings” section of the menu, and check the box for “SNAP/Food Stamps”.\nYou should see about 2 dozen resulting data table names. One of them (hopefully near the top) will be called “S2201FOOD STAMPS/SUPPLEMENTAL NUTRITION ASSISTANCE PROGRAM (SNAP)”. Click this table. The data preview pane will probably say “Table is too large to display”.\nClick “DOWNLOAD TABLE”, select the most recent year in the “Table Vintages” pop-up, and click “DOWNLOAD .CSV”. This will download a zipped file called ACSST5Y2021.S2201_<your current date and time>.zip.\nUnzip the folder, and rename it to ACSST5Y2021_S2201/. There are three files in this folder:\n\nACSST5Y2021.S2201-Column-Metadata.csv\nACSST5Y2021.S2201-Data.csv\nACSST5Y2021.S2201-Table-Notes.txt\n\nSave it into your directory for this class in your data/ folder (or whatever you named the folder for your data).\n\n\n\nThe first few rows and columns of the data file should look like this:\n\nNotice that the NAME column contains the ZIP codes."
  },
  {
    "objectID": "lessons/lesson08_Data_Read_Write.html#the-readr-package",
    "href": "lessons/lesson08_Data_Read_Write.html#the-readr-package",
    "title": "Lesson 8: Importing Tidy Data",
    "section": "The readr Package",
    "text": "The readr Package\nThe readr package (https://cran.r-project.org/web/packages/readr/README.html is the data import package of the tidyverse. If you want a good overview of how to use this package, read Chapter 11 of R4DS. We’ll load the tidyverse package suite now.\n\nlibrary(tidyverse)\n\n\nPackage Goals\nThe readr package has three main goals:\n\nBe faster than the base:: package reading functions (read.csv, read.delim, read.fwf, etc.).\nImport data as a tibble, so that we don’t get hung up on character / factor conversion and we don’t mess up row and column names. For more on the tibble object, read their vignette: https://cran.r-project.org/web/packages/tibble/vignettes/tibble.html\nOperate similarly on all operating systems.\n\n\n\nThe Main Function(s)\nThere is one main file-reading function in the readr package, and two extensions of this function for commonly-occuring data formats (there are obviously more functions than just these three, but knowing how two of these three work will help you import the majority of data files you will see in practice).\n\nread_delim: read any text-based delimited file into R as a tibble.\nread_csv: an extension of read_delim designed to make reading .csv files easy.\nread_tsv: an extension of read_delim designed to make reading tab-delimited .txt files easy.\n\nBecause these functions import data as a tibble (“table” + “data frame”), you should try to store data files such that each entry of a column is of the same atomic type (all character, numeric, logical, etc.)."
  },
  {
    "objectID": "lessons/lesson08_Data_Read_Write.html#read-a-.csv-file-with-read_csv",
    "href": "lessons/lesson08_Data_Read_Write.html#read-a-.csv-file-with-read_csv",
    "title": "Lesson 8: Importing Tidy Data",
    "section": "Read a .csv File with read_csv",
    "text": "Read a .csv File with read_csv\nIn the “Import Dataset” drop-down menu, select From Text (readr).... In the “Import Text Data” pop-up window, click “Browse” to find and open your data. If you are using an RStudio project, then the “Browse” file finder should open directly to your directory for this class, and the data directory where you saved all three data files should be visible. Select the ACS data .csv file and click “Open”. You should see this window:\n\nThere is a lot of stuff going on in this window! Let’s unpack all of our options:\n\nThe “Data Preview” pane shows you an Excel-style view of the first few rows and columns of your data:\n\nThe column names were imported correctly.\nThe readr package identifies the data type for each column by looking at the first 1000 rows.\nThe down-arrow next to the column name lets you manually override readr’s best guess for the column data type, as well as include, skip, or include only the column:\n\n\nThe “Import Options” pane allows you more direct control over how the data file is imported:\n\n“Name” — what name do you want to give the data tibble in the working directory? Often, the file itself has a long name, so it’s better to name the tibble saved in your R environment a shorthand version.\n“Skip” — skip reading the first rows of the file. This is helpful if you have metadata in the first few rows of the file, and the data itself doesn’t start until later. NOTE: we will have to set skip = 1 for this data.\nCheck Box Options — these do what they say they do.\n“Delimiter: Comma” — this drop-down menu allows you to switch among commas, tabs, semicolons, white space, or other delimiters. The readr package correctly identified that our .csv file was comma-delimited.\n“NA” — how are missing values coded in your data? The drop-down menu has only a few options, but have more flexibility by interacting with the code itself (more on that in the next lesson).\n\nThe “Code Preview” pane shows you the results of all of the options you specified. Here is what the “Import Options” and “Code Preview” panes look like for the ACS SNAP .csv data:\n\n \nThe “Code Preview” pane shows what code will be ran automatically when I click the “Import” button in that window. Specifically, I’ve named the incoming data object FL_allZIPs, and I’ve turned off the automatic View() command. Also, notice that because readr identified that the data file was a .csv file, the read_csv() function was selected automatically. We click “Import” and this code runs for us:\n\nFL_allZIPs <- read_csv(\n  \"../_data/ACSST5Y2021_S2201/ACSST5Y2021.S2201-Data.csv\", \n  skip = 1\n)\n\nNew names:\nRows: 1013 Columns: 459\n── Column specification\n──────────────────────────────────────────────────────── Delimiter: \",\" chr\n(236): Geography, Geographic Area Name, Estimate!!Total!!Households!!HOU... dbl\n(222): Estimate!!Total!!Households, Margin of Error!!Total!!Households, ... lgl\n(1): ...459\nℹ Use `spec()` to retrieve the full column specification for this data. ℹ\nSpecify the column types or set `show_col_types = FALSE` to quiet this message.\n• `` -> `...459`\n\n\n\n\n\n\n\n\nExercise\n\n\n\nImport the SNAP data into R."
  },
  {
    "objectID": "lessons/lesson08_Data_Read_Write.html#read-a-tab-delimited-.txt-file-with-read_tsv",
    "href": "lessons/lesson08_Data_Read_Write.html#read-a-tab-delimited-.txt-file-with-read_tsv",
    "title": "Lesson 8: Importing Tidy Data",
    "section": "Read a Tab-Delimited .txt File with read_tsv",
    "text": "Read a Tab-Delimited .txt File with read_tsv\nNow that we have a decent idea of how the read_csv function works, we can easily read in the Miami-Dade and Broward ZIP code files with the read_tsv function—it has the same syntax! Note: you will have to change the file path to match where your data is stored; mine is stored in a subfolder called _data/.\n\nmiamidade_ZIPs <- read_tsv(\"../_data/miamidade_ZIP_codes.txt\")\n\nRows: 127 Columns: 6\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \"\\t\"\nchr (5): ZIP Code, Classification, City, Timezone, Area Code(s)\nnum (1): Population\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nbroward_ZIPs <- read_tsv(\"../_data/broward_ZIP_codes.txt\")\n\nRows: 88 Columns: 6\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \"\\t\"\nchr (5): ZIP Code, Classification, City, Timezone, Area Code(s)\nnum (1): Population\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nNotice the messages readr gives us when importing data: all the columns (except for population) were imported as character columns.\n\n\n\n\n\n\nExercise\n\n\n\nImport the Miami-Dade and Broward county ZIP code data into R.\n\n\n\n\n\n\n\n\nLooking ahead…\n\n\n\nNotice that the ZIP code column in the Miami-Dade and Broward data sets do not exactly match the ZIP code column in the ACS SNAP data. In order to match these data sets, we will need tools that help us deal with tibbles (coming up in the dplyr lesson) and tools that help us deal with character strings (coming up in the stringr lesson). We will see these data sets again."
  },
  {
    "objectID": "lessons/lesson08_Data_Read_Write.html#data-format-example-tuberculosis-cases",
    "href": "lessons/lesson08_Data_Read_Write.html#data-format-example-tuberculosis-cases",
    "title": "Lesson 8: Importing Tidy Data",
    "section": "Data Format Example: Tuberculosis Cases",
    "text": "Data Format Example: Tuberculosis Cases\nConsider data with counts of tuberculosis (TB) cases for three countries measured over a single 10-year interval. What could our data look like?\n\n\n\nCountry\nYear\nRate\n\n\n\n\n“Afghanistan”\n1999\n“745/19987071”\n\n\n“Afghanistan”\n2000\n“2666/20595360”\n\n\n“Brazil”\n1999\n“37737/172006362”\n\n\n“Brazil”\n2000\n“80488/174504898”\n\n\n“China”\n1999\n“212258/1272915272”\n\n\n“China”\n2000\n“213766/1280428583”\n\n\n\nNotice that this table has all the information we need: the name of the country, the year of the demograpic measurement, the number of TB cases in that year for each country, and the total population in the country at that time. The data is in a good format for humans. However, the information in this data is not immediately accesible by the computer.\n\n\n\n\n\n\nExercises\n\n\n\n\nDiscuss with your neighbour about why this data may not be useful to us in R.\nWhy are the rate values in quotes?"
  },
  {
    "objectID": "lessons/lesson08_Data_Read_Write.html#what-is-tidy-data",
    "href": "lessons/lesson08_Data_Read_Write.html#what-is-tidy-data",
    "title": "Lesson 8: Importing Tidy Data",
    "section": "What is Tidy Data?",
    "text": "What is Tidy Data?\nBefore we try to “tidy up” the data set above, we need a grammar for data. Specifically, mathematical convention holds that (if you would like the justification for these rules, please see Wickham (2014)):\n\nEach variable must have its own column.\nEach observation must have its own row.\nEach value must have its own cell.\n\nVisually, tidy data has this form:\n\n\nTidy the TB Data\nNow that we have some rules, we can tidy up the TB data. Honestly, it was already pretty close; we simply need to split the “Rate” column into its numerator and denominator (this allows us to remove the quotes):\n\n\n\nCountry\nYear\nCases\nPopulation\n\n\n\n\n“Afghanistan”\n1999\n745\n19987071\n\n\n“Afghanistan”\n2000\n2666\n20595360\n\n\n“Brazil”\n1999\n37737\n172006362\n\n\n“Brazil”\n2000\n80488\n174504898\n\n\n“China”\n1999\n212258\n1272915272\n\n\n“China”\n2000\n213766\n1280428583"
  },
  {
    "objectID": "lessons/lesson08_Data_Read_Write.html#why-tidy-data",
    "href": "lessons/lesson08_Data_Read_Write.html#why-tidy-data",
    "title": "Lesson 8: Importing Tidy Data",
    "section": "Why Tidy Data",
    "text": "Why Tidy Data\nMost of my work as a data scientist is extracting or cleaning data. As such, here are the reasons I use the tidy data format:\n\nIt is mathematically consistent. When we perform calculations with statistics, the notation of matrix algebra and calculus assume that the observations are in the rows of a matrix while the measurements are in its columns.\nKeeping the same structure for all raw data means I don’t waste time re-writing code to work with data in different formats. If I write code that works for one data set, it will usually work for another data set with only slight modifications.\nStoring measurements in columns of a tibble means that R treats the data set as a vector of atomic vectors (recall that a tibble is actually a list, and as such it is a non-atomic vector of other vectors). Because of this, we get to take advantages of R’s strength as a vectorised language."
  },
  {
    "objectID": "lessons/lesson13_eda_w_tidyverse.html",
    "href": "lessons/lesson13_eda_w_tidyverse.html",
    "title": "Lesson 13: Exploring Data with the Tidyverse",
    "section": "",
    "text": "What have we learned so far this semester?\n\nWriting reports with Quarto\nPlots with ggplot2\nVectors\nImporting and wrangling data with readr, tibble, and dplyr\nManipulating strings with stringr\nWriting functions and applying them with purrr"
  },
  {
    "objectID": "lessons/lesson13_eda_w_tidyverse.html#the-raw-data",
    "href": "lessons/lesson13_eda_w_tidyverse.html#the-raw-data",
    "title": "Lesson 13: Exploring Data with the Tidyverse",
    "section": "The Raw Data",
    "text": "The Raw Data\nYou should have already done all this in lesson 8. However, if you did not complete that exercise, download the data and metadata from GitHub. You should have a metadata file called ACSST5Y2021.S2201-Column-Metadata.csv which explains all the variable names and a data file called ACSST5Y2021.S2201-Data.csv that contains some of the features of interest."
  },
  {
    "objectID": "lessons/lesson13_eda_w_tidyverse.html#read-the-data",
    "href": "lessons/lesson13_eda_w_tidyverse.html#read-the-data",
    "title": "Lesson 13: Exploring Data with the Tidyverse",
    "section": "Read the Data",
    "text": "Read the Data\nNow that you have raw data files, import them into R (you will have to update the path to these data sets based on how you saved these files on your computer). ACS data files often have more than one row of column names (the first row is a unique ID for the column, and sometimes the next 1-2 rows are metadata about the column). In our case, we have character information we don’t want at the tops of our columns, so we will import the column names first, then import the data.\n\nSNAP Data Values\nWe first define a path to our data values (remember to update this to match your machine), then we import only the column headers for this data (that’s the n_max = 0 part). After we have the names we want, we can import the rest of the data—skipping the first two rows—but using the names we calculated in the step before.\n\ndata_path <- \"../_data/ACSST5Y2021_S2201/ACSST5Y2021.S2201-Data.csv\"\ncolNames_char <- names(read_csv(data_path, n_max = 0))\n\nNew names:\nRows: 0 Columns: 459\n── Column specification\n──────────────────────────────────────────────────────── Delimiter: \",\" chr\n(459): GEO_ID, NAME, S2201_C01_001E, S2201_C01_001M, S2201_C01_002E, S22...\nℹ Use `spec()` to retrieve the full column specification for this data. ℹ\nSpecify the column types or set `show_col_types = FALSE` to quiet this message.\n• `` -> `...459`\n\nFLallZIP_df <- read_csv(\n  file = data_path,\n  col_names = colNames_char,\n  skip = 2\n)\n\nRows: 1013 Columns: 459\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (236): GEO_ID, NAME, S2201_C01_034E, S2201_C01_034M, S2201_C02_001E, S22...\ndbl (222): S2201_C01_001E, S2201_C01_001M, S2201_C01_002E, S2201_C01_002M, S...\nlgl   (1): ...459\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nThe meta-data doesn’t need those tricks. We can import it as is.\n\nFLmetadata_df <- read_csv(\n  file = \"../_data/ACSST5Y2021_S2201/ACSST5Y2021.S2201-Column-Metadata.csv\"\n)\n\nRows: 458 Columns: 2\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (2): Column Name, Label\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\nInspect Data Sets\nLet’s get an idea of what is in these data sets:\n\nFLallZIP_df\n\n# A tibble: 1,013 × 459\n   GEO_ID      NAME  S2201_C01_001E S2201_C01_001M S2201_C01_002E S2201_C01_002M\n   <chr>       <chr>          <dbl>          <dbl>          <dbl>          <dbl>\n 1 860Z200US3… ZCTA…          11090            672           5276            611\n 2 860Z200US3… ZCTA…           2354            378           1300            272\n 3 860Z200US3… ZCTA…           1383            231            574            106\n 4 860Z200US3… ZCTA…           5480            430           2172            294\n 5 860Z200US3… ZCTA…              5             11              5             11\n 6 860Z200US3… ZCTA…           7220            403           3636            322\n 7 860Z200US3… ZCTA…           8127            544           3524            323\n 8 860Z200US3… ZCTA…              0             14              0             14\n 9 860Z200US3… ZCTA…           1915            425           1096            177\n10 860Z200US3… ZCTA…          16526            728           9846            654\n# ℹ 1,003 more rows\n# ℹ 453 more variables: S2201_C01_003E <dbl>, S2201_C01_003M <dbl>,\n#   S2201_C01_004E <dbl>, S2201_C01_004M <dbl>, S2201_C01_005E <dbl>,\n#   S2201_C01_005M <dbl>, S2201_C01_006E <dbl>, S2201_C01_006M <dbl>,\n#   S2201_C01_007E <dbl>, S2201_C01_007M <dbl>, S2201_C01_008E <dbl>,\n#   S2201_C01_008M <dbl>, S2201_C01_009E <dbl>, S2201_C01_009M <dbl>,\n#   S2201_C01_010E <dbl>, S2201_C01_010M <dbl>, S2201_C01_011E <dbl>, …\n\n\nThere are 457 columns of information (459 - 2 index columns), and it looks like all of these columns have bizarre codes for their names. Also, many of the columns are numeric and many are character (some columns that are character shouldn’t be).\nNow for the metadata:\n\nFLmetadata_df\n\n# A tibble: 458 × 2\n   `Column Name`  Label                                                         \n   <chr>          <chr>                                                         \n 1 GEO_ID         Geography                                                     \n 2 NAME           Geographic Area Name                                          \n 3 S2201_C01_001E Estimate!!Total!!Households                                   \n 4 S2201_C01_001M Margin of Error!!Total!!Households                            \n 5 S2201_C01_002E Estimate!!Total!!Households!!With one or more people in the h…\n 6 S2201_C01_002M Margin of Error!!Total!!Households!!With one or more people i…\n 7 S2201_C01_003E Estimate!!Total!!Households!!No people in the household 60 ye…\n 8 S2201_C01_003M Margin of Error!!Total!!Households!!No people in the househol…\n 9 S2201_C01_004E Estimate!!Total!!Households!!Married-couple family            \n10 S2201_C01_004M Margin of Error!!Total!!Households!!Married-couple family     \n# ℹ 448 more rows\n\n\nThe first column of this data looks exactly like the crazy column names of the main data set. This information should allow us to find out what the column codes mean.\n\n\nUpdated Summary Function\nRecall our lesson on functions last week. Based on this lesson, we are able to write an updated version of the summary() function. Our summary function should print the most common unique values for character information, but call the summary() function as normal for anything else:\n\nMySummary <- function(x){\n  \n  if (is.character(x)){\n    \n    table(x) %>% \n      sort(decreasing = TRUE) %>%\n      head()\n    \n  } else {\n    summary(x)\n  }\n  \n}\n\n\n\nApply to the Raw Data\nNow that we have an updated function to take summaries of a tibble across the columns, let’s apply it to each column of the data (because this will print almost 500 results, we will to a random set of 50 columns):\n\nset.seed(12345)\n# The first two columns are ZIP codes and geography IDs\nrandColumns_idx <- sort(sample(3:ncol(FLallZIP_df), size = 50))\n\nmap(FLallZIP_df[, randColumns_idx], MySummary)\n\n$S2201_C01_006M\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n    5.0    64.0   141.0   159.3   227.0   715.0 \n\n$S2201_C01_007M\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n    2.0   109.0   220.0   235.8   337.0   959.0 \n\n$S2201_C01_008M\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n    6.0   199.0   392.0   384.2   541.0  1272.0 \n\n$S2201_C01_013E\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n    0.0   107.0   397.0   599.2   877.0  4735.0 \n\n$S2201_C01_018M\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n    4.0    35.0    86.0   104.4   146.0   672.0 \n\n$S2201_C01_019M\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n    5.0    67.0   133.0   151.1   214.0   725.0 \n\n$S2201_C01_020M\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n    6.0   198.0   389.0   382.9   541.0  1272.0 \n\n$S2201_C01_026E\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n      0      71     370    1103    1251   18704 \n\n$S2201_C01_030M\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n    3.0    22.0    78.0   111.9   161.0   629.0 \n\n$S2201_C01_031M\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n    2.0    57.0   154.0   204.1   293.0  1084.0 \n\n$S2201_C01_038E\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n      0     624    2028    2496    3744   12111 \n\n$S2201_C02_002M\nx\n3.3  ** 3.4 3.5 2.8 3.2 \n 38  33  33  32  31  30 \n\n$S2201_C02_005M\nx\n3.0 3.2  ** 2.5 2.6 2.8 \n 34  34  33  32  31  29 \n\n$S2201_C02_009E\nx\n   -  0.0 25.2 20.5 22.5 24.0 \n  33   24   11    7    7    7 \n\n$S2201_C02_014E\nx\n0.0 0.1 0.2 0.3 0.4   - \n475 121  97  81  58  33 \n\n$S2201_C02_015M\nx\n3.1  ** 2.9 3.2 3.3 2.8 \n 36  33  33  33  32  28 \n\n$S2201_C02_024E\nx\n    - 100.0  78.8  69.0  74.1  74.9 \n   33    17     9     8     8     8 \n\n$S2201_C02_031E\nx\n0.0   - 3.4 3.0 2.3 3.5 \n 73  33  20  18  15  15 \n\n$S2201_C02_033E\nx\n    - 100.0   0.0  85.3  77.3  83.2 \n   33    33     6     6     5     5 \n\n$S2201_C02_033M\nx\n3.5 3.7  ** 2.9 3.2 3.0 \n 37  36  33  33  32  31 \n\n$S2201_C02_036M\nx\n ** 3.1 3.7 3.4 2.8 3.6 \n 38  28  27  25  24  21 \n\n$S2201_C02_038M\nx\n ** 5.0 4.1 4.5 4.7 3.9 \n 38  28  25  25  24  23 \n\n$S2201_C03_007M\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n    3.0    42.0   106.0   132.8   192.0   603.0 \n\n$S2201_C03_020M\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n    4.0    40.0    96.0   119.6   171.0   568.0 \n\n$S2201_C03_028M\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   2.00   14.00   23.00   28.65   30.00  266.00 \n\n$S2201_C03_030E\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   0.00    0.00    7.00   58.42   63.00 1076.00 \n\n$S2201_C03_030M\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   3.00   17.00   25.00   50.47   60.00  568.00 \n\n$S2201_C03_032M\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n      3      22      68     120     173     795 \n\n$S2201_C03_033M\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n    5.0    57.0   118.0   130.6   185.0   606.0 \n\n$S2201_C03_034M\nx\n   **   *** 12937  3422  5566  6141 \n  223     2     2     2     2     2 \n\n$S2201_C04_002M\nx\n   **   9.8  12.6   8.4 100.0  10.1 \n   81    15    12    11    10     9 \n\n$S2201_C04_015E\nx\n    - 100.0   0.0  60.2  48.9  45.5 \n   81    36     9     8     7     5 \n\n$S2201_C04_015M\nx\n  ** 10.3 13.4 11.5 11.2 11.3 \n  81   12   11   10    9    9 \n\n$S2201_C04_016E\nx\n 0.0    -  6.9 12.1  6.7  7.5 \n  92   81   10    9    9    9 \n\n$S2201_C04_019M\nx\n ** 4.5 3.7 5.3 4.1 4.6 \n 81  17  16  15  13  13 \n\n$S2201_C04_029M\nx\n ** 1.8 1.1 1.9 1.5 1.7 \n 81  17  16  14  13  13 \n\n$S2201_C04_030M\nx\n ** 3.6 4.5 2.7 2.9 2.1 \n 81  13  13  12  12  11 \n\n$S2201_C04_033M\nx\n   **  10.8 100.0   8.1  16.5  10.2 \n   81    10    10    10     9     8 \n\n$S2201_C05_005M\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n    2.0   113.0   226.0   241.5   343.0  1152.0 \n\n$S2201_C05_012M\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   2.00   34.00   81.00   98.49  141.00  479.00 \n\n$S2201_C05_023M\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n    3.0   161.0   278.0   288.6   401.0  1050.0 \n\n$S2201_C05_024M\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n    6.0   267.0   487.0   474.8   654.0  1448.0 \n\n$S2201_C05_025M\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n    6.0   252.0   457.0   434.5   595.0  1337.0 \n\n$S2201_C05_029E\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  0.000   0.000   0.000   3.098   0.000 121.000 \n\n$S2201_C05_036E\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n    0.0   235.0   651.0   859.6  1175.0 14985.0 \n\n$S2201_C06_005E\nx\n 0.0    - 11.3 10.7 12.7  8.5 \n  36   35   12   11   11   11 \n\n$S2201_C06_007E\nx\n0.0   - 6.2 8.3 8.0 3.7 \n 47  35  19  16  15  13 \n\n$S2201_C06_018M\nx\n0.8 0.9 1.0 1.1 1.4 1.2 \n 67  60  57  53  53  51 \n\n$S2201_C06_022E\nx\n100.0     -  91.6  92.8  92.7  91.3 \n   39    35    15    15    13    12 \n\n$S2201_C06_035E\n (X) \n1013 \n\n\nIt looks like many of these columns (such as S2201_C02_002M or S2201_C06_022E) have numeric data stored as character information, probably because the symbols \"-\" and \"**\" are used in some columns (they may mark missing data).\nIf we were planning to perform an analysis of all these features, then we should write code to go through these columns to 1) replace the \"-\" and \"**\" with NA_real_, and 2) transform these columns to numeric. However, we only need a few columns from this data set. If the columns we need have this issue, then we will fix it."
  },
  {
    "objectID": "lessons/lesson13_eda_w_tidyverse.html#detecting-strings",
    "href": "lessons/lesson13_eda_w_tidyverse.html#detecting-strings",
    "title": "Lesson 13: Exploring Data with the Tidyverse",
    "section": "Detecting Strings",
    "text": "Detecting Strings\nFrom looking at the columns in the metadata table, it would probably be helpful to find if a word or phrase is contained in a character string. This is the function of str_detect().\n\nFLmetadata_df %>% \n  pull(Label) %>% \n  str_detect(pattern = \"Hispanic\") %>% \n  table()\n\n.\nFALSE  TRUE \n  434    24 \n\n\nAs we can see, this function returns a logical vector indicating if the string \"Hispanic\" is in the elements of the Label column, then the table() function tells us this information is present in only a handful of the columns. By itself, this isn’t helpful: we don’t know what the strings are, and we certainly don’t know which rows of the tibble they belong to. But at least we know that we have some data on Hispanic households.\nTo solve these problems, we combine str_detect() with mutate() and filter():\n\nFLmetadata_df %>% \n  mutate(Hispanic_logi = str_detect(Label, \"Hispanic\")) %>% \n  filter(Hispanic_logi) %>% \n  select(-Hispanic_logi)\n\n# A tibble: 24 × 2\n   `Column Name`  Label                                                         \n   <chr>          <chr>                                                         \n 1 S2201_C01_032E Estimate!!Total!!Households!!RACE AND HISPANIC OR LATINO ORIG…\n 2 S2201_C01_032M Margin of Error!!Total!!Households!!RACE AND HISPANIC OR LATI…\n 3 S2201_C01_033E Estimate!!Total!!Households!!RACE AND HISPANIC OR LATINO ORIG…\n 4 S2201_C01_033M Margin of Error!!Total!!Households!!RACE AND HISPANIC OR LATI…\n 5 S2201_C02_032E Estimate!!Percent!!Households!!RACE AND HISPANIC OR LATINO OR…\n 6 S2201_C02_032M Margin of Error!!Percent!!Households!!RACE AND HISPANIC OR LA…\n 7 S2201_C02_033E Estimate!!Percent!!Households!!RACE AND HISPANIC OR LATINO OR…\n 8 S2201_C02_033M Margin of Error!!Percent!!Households!!RACE AND HISPANIC OR LA…\n 9 S2201_C03_032E Estimate!!Households receiving food stamps/SNAP!!Households!!…\n10 S2201_C03_032M Margin of Error!!Households receiving food stamps/SNAP!!House…\n# ℹ 14 more rows\n\n\nThis is a very nice result: we used the mutate() function to add a column of TRUE or FALSE values to the data frame to indicate if \"Hispanic\" was present in the column names (in the Label column). Then, we selected all of the rows where this indicator was TRUE, and then removed the indicator (because we no longer needed it).\n\n\n\n\n\n\nExercises\n\n\n\n\nTry to find “HISPANIC” and “hispanic”. What can we do to modify the metadata so that one search will find all the rows we might want?\nMany of the rows in the meta-data are not going to be any use to use at all. Can you brainstorm a stringr:: pipeline that will clean up the meta-data table to make it easier for us to go through?"
  },
  {
    "objectID": "lessons/lesson13_eda_w_tidyverse.html#string-cases",
    "href": "lessons/lesson13_eda_w_tidyverse.html#string-cases",
    "title": "Lesson 13: Exploring Data with the Tidyverse",
    "section": "String Cases",
    "text": "String Cases\nBecause R is case sensitive, the string \"Hispanic\" and \"HISPANIC\" are not the same. We can use the str_to_upper() and str_to_lower() functions to convert all of the string data to the same case (so our searches don’t fail). In this case, we have to make sure to save the new tibble:\n\nFLmetadata2_df <- \n  FLmetadata_df %>% \n  mutate(Label = str_to_lower(Label))\n\n# Did it work?\nFLmetadata2_df %>% \n  mutate(Hispanic_logi = str_detect(Label, \"hispanic\")) %>% \n  filter(Hispanic_logi) %>% \n  select(-Hispanic_logi)\n\n# A tibble: 108 × 2\n   `Column Name`  Label                                                         \n   <chr>          <chr>                                                         \n 1 S2201_C01_025E estimate!!total!!households!!race and hispanic or latino orig…\n 2 S2201_C01_025M margin of error!!total!!households!!race and hispanic or lati…\n 3 S2201_C01_026E estimate!!total!!households!!race and hispanic or latino orig…\n 4 S2201_C01_026M margin of error!!total!!households!!race and hispanic or lati…\n 5 S2201_C01_027E estimate!!total!!households!!race and hispanic or latino orig…\n 6 S2201_C01_027M margin of error!!total!!households!!race and hispanic or lati…\n 7 S2201_C01_028E estimate!!total!!households!!race and hispanic or latino orig…\n 8 S2201_C01_028M margin of error!!total!!households!!race and hispanic or lati…\n 9 S2201_C01_029E estimate!!total!!households!!race and hispanic or latino orig…\n10 S2201_C01_029M margin of error!!total!!households!!race and hispanic or lati…\n# ℹ 98 more rows\n\n\nOne tip for working with strings: DO NOT write the new object into the container holding the old object. Strings are incredibly difficult to work with at times, so make sure you can always go back a few steps. This is why I saved the new look-up table with a different name (personally, I usually append a number to the name of the object when I’m working with strings; then, when I’m sure I have done all the string clean-up I need, I save it with a better name).\nIn the dictionary/look-up table, we have all the information necessary to find the columns we want. However, before we dig into the look-up table, we notice that all of the rows are copied twice: one for estimate, and one for margin of error. For now, we aren’t interested in the margins of error, so let’s remove these rows:\n\nFLmetadata3_df <- \n  FLmetadata2_df %>% \n  mutate(MOE = str_detect(Label, \"margin of error\")) %>% \n  filter(!MOE) %>% \n  select(-MOE)\n\n# Check\nFLmetadata3_df\n\n# A tibble: 230 × 2\n   `Column Name`  Label                                                         \n   <chr>          <chr>                                                         \n 1 GEO_ID         geography                                                     \n 2 NAME           geographic area name                                          \n 3 S2201_C01_001E estimate!!total!!households                                   \n 4 S2201_C01_002E estimate!!total!!households!!with one or more people in the h…\n 5 S2201_C01_003E estimate!!total!!households!!no people in the household 60 ye…\n 6 S2201_C01_004E estimate!!total!!households!!married-couple family            \n 7 S2201_C01_005E estimate!!total!!households!!other family:                    \n 8 S2201_C01_006E estimate!!total!!households!!other family:!!male householder,…\n 9 S2201_C01_007E estimate!!total!!households!!other family:!!female householde…\n10 S2201_C01_008E estimate!!total!!households!!nonfamily households             \n# ℹ 220 more rows\n\n\n\n\n\n\n\n\nExercises\n\n\n\n\nThe meta-data table has information on whether the number is an estimate of the raw count (total!!) or an estimate of the population proportion (percent!!). Use stringr:: functions to remove this information from the “Label” column and add it to its own column.\nCan you break the “Label” column into any other pieces without losing information?"
  },
  {
    "objectID": "lessons/lesson13_eda_w_tidyverse.html#find-the-food-stamps-metric",
    "href": "lessons/lesson13_eda_w_tidyverse.html#find-the-food-stamps-metric",
    "title": "Lesson 13: Exploring Data with the Tidyverse",
    "section": "Find the “Food Stamps” Metric",
    "text": "Find the “Food Stamps” Metric\nWe will use the same process as above (mutate() + str_detect() + filter()) to find all the columns that measure food stamp usage as a percentage:\n\nFLmetadata3_df %>% \n  mutate(foodStamps_logi = str_detect(Label, \"food stamps\")) %>% \n  mutate(percent_logi = str_detect(Label, \"percent\")) %>% \n  filter(foodStamps_logi & percent_logi) %>% \n  select(-foodStamps_logi, -percent_logi)\n\n# A tibble: 76 × 2\n   `Column Name`  Label                                                         \n   <chr>          <chr>                                                         \n 1 S2201_C04_001E estimate!!percent households receiving food stamps/snap!!hous…\n 2 S2201_C04_002E estimate!!percent households receiving food stamps/snap!!hous…\n 3 S2201_C04_003E estimate!!percent households receiving food stamps/snap!!hous…\n 4 S2201_C04_004E estimate!!percent households receiving food stamps/snap!!hous…\n 5 S2201_C04_005E estimate!!percent households receiving food stamps/snap!!hous…\n 6 S2201_C04_006E estimate!!percent households receiving food stamps/snap!!hous…\n 7 S2201_C04_007E estimate!!percent households receiving food stamps/snap!!hous…\n 8 S2201_C04_008E estimate!!percent households receiving food stamps/snap!!hous…\n 9 S2201_C04_009E estimate!!percent households receiving food stamps/snap!!hous…\n10 S2201_C04_010E estimate!!percent households receiving food stamps/snap!!hous…\n# ℹ 66 more rows\n\n\nWhile there are 76 options, it looks like we want the one labelled S2201_C04_001E, but the tibble print options cut off the full label. Let’s use pull() to extract the label and confirm it’s what we want, but note that we have to surround column names with spaces with backticks:\n\nFLmetadata3_df %>% \n  filter(`Column Name` == \"S2201_C04_001E\") %>% \n  pull(Label)\n\n[1] \"estimate!!percent households receiving food stamps/snap!!households\"\n\n\nThat label is correct, and it matches to the feature \"estimate!!percent households receiving food stamps/snap!!households\". Let’s save this column ID.\n\nfoodStampsColID_char <- \"S2201_C04_001E\""
  },
  {
    "objectID": "lessons/lesson13_eda_w_tidyverse.html#find-the-income-metric",
    "href": "lessons/lesson13_eda_w_tidyverse.html#find-the-income-metric",
    "title": "Lesson 13: Exploring Data with the Tidyverse",
    "section": "Find the “Income” Metric",
    "text": "Find the “Income” Metric\nJust like we found the column name of the food stamps metric we needed, we can find the column name for income (I recommend using the View() function interactively to make sure you can read the labels):\n\nFLmetadata3_df %>%  \n  mutate(income_logi = str_detect(Label, \"income\")) %>% \n  filter(income_logi) %>% \n  select(-income_logi)\n\n# A tibble: 6 × 2\n  `Column Name`  Label                                                          \n  <chr>          <chr>                                                          \n1 S2201_C01_034E estimate!!total!!households!!household income in the past 12 m…\n2 S2201_C02_034E estimate!!percent!!households!!household income in the past 12…\n3 S2201_C03_034E estimate!!households receiving food stamps/snap!!households!!h…\n4 S2201_C04_034E estimate!!percent households receiving food stamps/snap!!house…\n5 S2201_C05_034E estimate!!households not receiving food stamps/snap!!household…\n6 S2201_C06_034E estimate!!percent households not receiving food stamps/snap!!h…\n\n\nThese labels are too long, so we need to “pull” them out of the data frame:\n\nFLmetadata3_df %>%  \n  mutate(income_logi = str_detect(Label, \"income\")) %>% \n  filter(income_logi) %>% \n  select(-income_logi) %>% \n  pull(Label)\n\n[1] \"estimate!!total!!households!!household income in the past 12 months (in 2021 inflation-adjusted dollars)!!median income (dollars)\"                                            \n[2] \"estimate!!percent!!households!!household income in the past 12 months (in 2021 inflation-adjusted dollars)!!median income (dollars)\"                                          \n[3] \"estimate!!households receiving food stamps/snap!!households!!household income in the past 12 months (in 2021 inflation-adjusted dollars)!!median income (dollars)\"            \n[4] \"estimate!!percent households receiving food stamps/snap!!households!!household income in the past 12 months (in 2021 inflation-adjusted dollars)!!median income (dollars)\"    \n[5] \"estimate!!households not receiving food stamps/snap!!households!!household income in the past 12 months (in 2021 inflation-adjusted dollars)!!median income (dollars)\"        \n[6] \"estimate!!percent households not receiving food stamps/snap!!households!!household income in the past 12 months (in 2021 inflation-adjusted dollars)!!median income (dollars)\"\n\n\nBecause our sanity check is “ZIP codes with higher income should have lower percentages of food stamp recipients”, we want the most basic income measurement (the first one). Let’s pull the column ID for that first match:\n\nincomeColID_char <- \n  FLmetadata3_df %>%  \n  mutate(income_logi = str_detect(Label, \"income\")) %>% \n  filter(income_logi) %>% \n  slice(1) %>%\n  pull(`Column Name`)\n\n# Check\nFLmetadata3_df %>% \n  filter(`Column Name` == incomeColID_char) %>% \n  pull(Label)\n\n[1] \"estimate!!total!!households!!household income in the past 12 months (in 2021 inflation-adjusted dollars)!!median income (dollars)\"\n\n\nNow that we have the two columns we care about, we can subset the SNAP values data to include only the following columns: ZIP code (technically the ZCTA), proportion of households receiving food stamps in that area, and the median household income for that area.\n\nFLallZIP_df %>% \n  select(\n    zcta = NAME,\n    # # OLD version:\n    # food_stamp_prop = foodStampsColID_char,\n    # median_household_income = incomeColID_char\n    # # New version:\n    food_stamp_prop = all_of(foodStampsColID_char),\n    median_household_income = all_of(incomeColID_char)\n  ) \n\n# A tibble: 1,013 × 3\n   zcta        food_stamp_prop median_household_income\n   <chr>       <chr>           <chr>                  \n 1 ZCTA5 32003 3.1             103019                 \n 2 ZCTA5 32008 18.3            42802                  \n 3 ZCTA5 32009 8.8             65850                  \n 4 ZCTA5 32011 13.3            67087                  \n 5 ZCTA5 32013 100.0           -                      \n 6 ZCTA5 32024 14.8            57636                  \n 7 ZCTA5 32025 19.7            47439                  \n 8 ZCTA5 32026 -               -                      \n 9 ZCTA5 32033 8.7             71360                  \n10 ZCTA5 32034 7.3             87047                  \n# ℹ 1,003 more rows\n\n# NOTE: after I wrote this lesson, the tidyverse developers modified how the\n#   select() function works. We should now use the all_of() helper functions.\n#   I included the original way (which causes warnings), but commented it out."
  },
  {
    "objectID": "lessons/lesson13_eda_w_tidyverse.html#subset-and-mutate-the-data",
    "href": "lessons/lesson13_eda_w_tidyverse.html#subset-and-mutate-the-data",
    "title": "Lesson 13: Exploring Data with the Tidyverse",
    "section": "Subset and Mutate the Data",
    "text": "Subset and Mutate the Data\nNotice that the atomic class of the median_household_income column is character. We see that some of the values are missing. Subsequently, it looks like have numeric information stored in character columns because a letter or symbol was used instead of NA. For atomic data, we can follow the type conversion rules to demote this character information to numeric (which triggers a warning):\n\nincomeSNAP_df <- \n  FLallZIP_df %>% \n  select(\n    zcta = NAME,\n    food_stamp_prop = all_of(foodStampsColID_char),\n    median_household_income = all_of(incomeColID_char)\n  )  %>% \n  # drop character to numeric\n  mutate(\n    food_stamp_prop = as.numeric(food_stamp_prop),\n    median_household_income = as.numeric(median_household_income)\n  )\n\nWarning: There were 2 warnings in `mutate()`.\nThe first warning was:\nℹ In argument: `food_stamp_prop = as.numeric(food_stamp_prop)`.\nCaused by warning:\n! NAs introduced by coercion\nℹ Run `dplyr::last_dplyr_warnings()` to see the 1 remaining warning.\n\nincomeSNAP_df\n\n# A tibble: 1,013 × 3\n   zcta        food_stamp_prop median_household_income\n   <chr>                 <dbl>                   <dbl>\n 1 ZCTA5 32003             3.1                  103019\n 2 ZCTA5 32008            18.3                   42802\n 3 ZCTA5 32009             8.8                   65850\n 4 ZCTA5 32011            13.3                   67087\n 5 ZCTA5 32013           100                        NA\n 6 ZCTA5 32024            14.8                   57636\n 7 ZCTA5 32025            19.7                   47439\n 8 ZCTA5 32026            NA                        NA\n 9 ZCTA5 32033             8.7                   71360\n10 ZCTA5 32034             7.3                   87047\n# ℹ 1,003 more rows\n\n\nNotice that the \"-\" symbols were replaced by NA values. (If you have other features to control for or to add to the plot, make sure you include them here.)"
  },
  {
    "objectID": "lessons/lesson13_eda_w_tidyverse.html#plotting-the-relationship",
    "href": "lessons/lesson13_eda_w_tidyverse.html#plotting-the-relationship",
    "title": "Lesson 13: Exploring Data with the Tidyverse",
    "section": "Plotting the Relationship",
    "text": "Plotting the Relationship\nFinally, we have data we can plot!\n\nggplot(data = incomeSNAP_df) +\n  aes(x = median_household_income, y = food_stamp_prop) +\n  geom_point()\n\n\n\n\nThis clearly shows a negative relationship between income and proportion of residents on food stamps. However, the x-axis shows a strong tail, so let’s try to clean this up with a log transformation (also, the relationship looks non-linear, so I’ve added a LOESS estimate in blue):\n\nggplot(data = incomeSNAP_df) +\n  aes(x = log10(median_household_income), y = food_stamp_prop) +\n  geom_point(alpha = 0.3) +\n  geom_smooth(se = FALSE)\n\n\n\n\nIn practice, at this point we would thoroughly inspect all of the features of interest, and plot their relationships with the outcomes of interest. However, we don’t have time to do this in class.\n\n\n\n\n\n\nExercises\n\n\n\n\nWhy did I turn off the error bands for the LOESS smoother? Discuss with one of the statistics / biostatistics students (HINT: think about the assumptions of regression).\nImport the ZIP code data for Miami-Dade and Broward counties.\nMerge these two county tibbles, and clean up the ZIP code column (if you haven’t already done this as part of your homework from Lessons 8 and 10).\nUse a *_join() function to create a single subset of the 2021 ACS SNAP data set with a column that indicates if the ZIP code belongs to one of these two counties.\nRe-build your plot of this relationship, adding a color to indicate the ZIP codes in Miami-Dade and Broward counties. Do you see any differences between the relationship between food stamp usage and median income for the ZIP codes in our counties vs the whole state?"
  },
  {
    "objectID": "lessons/lesson02_introduction_to_R.html",
    "href": "lessons/lesson02_introduction_to_R.html",
    "title": "Lesson 2: Introduction to R",
    "section": "",
    "text": "Data science is the intersection of statistics, code, and domain knowledge.\n\n\n\nData science has a few major components:\n\nData Preparation and Exploration\nData Representation and Transformation\nComputing with Data\nModelling Data\nVisualizing and Presenting Data\nScience / Philosophy about Data Science\n\nReproducible research is pre-producible: research results that have been created with code can be re-created at will.\n\"Hello, world!\""
  },
  {
    "objectID": "lessons/lesson02_introduction_to_R.html#characters",
    "href": "lessons/lesson02_introduction_to_R.html#characters",
    "title": "Lesson 2: Introduction to R",
    "section": "Characters",
    "text": "Characters\nYour first code in R last class was to instruct R to tell the world hello. R uses \" (double quotes) and ' (single quotes) to mark textual information.\n\n\n\n\n\n\nExercise\n\n\n\nInstruct R to greet your neighbour, but using single quotes instead of double quotes. What changed?\n\n\n\n\n\n\n\n\nTip\n\n\n\nYou can use the “up arrow” key to recall the last command you typed."
  },
  {
    "objectID": "lessons/lesson02_introduction_to_R.html#scalar-arithmetic",
    "href": "lessons/lesson02_introduction_to_R.html#scalar-arithmetic",
    "title": "Lesson 2: Introduction to R",
    "section": "Scalar Arithmetic",
    "text": "Scalar Arithmetic\nR can do lots of powerful things, but it can also act as a very simple calculator. To add two numbers, after the > prompt, type\n\n> 867 + 5309\n\nIf you would like to chain multiple operations together, you can use multiple lines. The catch: you have to end all but your last line with an operator.\n\n> 24 *\n+   7\n\n\n\n\n\n\n\nExercise\n\n\n\nType your age, then the plus sign (+), then hit Enter. What happens to the prompt? Can you type other commands, like a \"Hello, world!\"? What do you think you should do to get the original prompt back?\n\n\nNote that from here on out, I will be assuming that you will type code at the proper > prompt, so I won’t include that anymore.\nWhy “scalar” arithmetic? Did you notice the “[1]” next to your answers? In mathematics, a scalar is a quantity represented in one dimension, or—as most commonly refer to them—numbers. We will return to this concept, and why it is important in R, shortly."
  },
  {
    "objectID": "lessons/lesson02_introduction_to_R.html#logic",
    "href": "lessons/lesson02_introduction_to_R.html#logic",
    "title": "Lesson 2: Introduction to R",
    "section": "Logic",
    "text": "Logic\nWe can use R’s logic system to compare values. A simple comparison is, “is 5 less than 3”? In R, this is\n\n5 < 3\n\n[1] FALSE\n\n\nThis comparison returns a logical indicator, FALSE. Notice that this value is not surrounded by quotes, and it’s also not a “number”. TRUE and FALSE are special symbols in R.\nThe following symbols are useful in logical comparisons:\n\n\n\nSymbol\nMeaning\nExample\n\n\n\n\n>\ngreater than\n5 > 3\n\n\n<\nless than\n5 < 3\n\n\n>=\ngreater than or equal to\n5 >= 3\n\n\n<=\nless than or equal to\n5 <= 3\n\n\n==\nequal to\n5 == 3\n\n\n!=\nnot equal to\n5 != 3"
  },
  {
    "objectID": "lessons/lesson02_introduction_to_R.html#the-code-comment",
    "href": "lessons/lesson02_introduction_to_R.html#the-code-comment",
    "title": "Lesson 2: Introduction to R",
    "section": "The Code Comment",
    "text": "The Code Comment\nMany times, we want to include notes with our code, to remind ourselves why we did what we did. In these cases, we don’t want R to try to evaluate these notes, so we use a special character to mark our notes as “code comments”.\n\n2 + 4 + 6 + 8\n\n[1] 20\n\n# Who do you appreciate?\n\n\n\n\n\n\n\nExercises\n\n\n\n\nIs the character string “florida” equal to the character string “Florida”?\nInput TRUE | FALSE. What does this evaluate to? What about FALSE | TRUE? What do you think the “|” symbol represents?\nWhat simple comparison symbol should replace ??? in TRUE ??? FALSE to make R return FALSE?"
  },
  {
    "objectID": "lessons/lesson02_introduction_to_R.html#what-is-an-object",
    "href": "lessons/lesson02_introduction_to_R.html#what-is-an-object",
    "title": "Lesson 2: Introduction to R",
    "section": "What is an Object?",
    "text": "What is an Object?\nAn object is like a basket or container to hold stuff. Let’s make our very first object. We are going to create an object named x, and store the number 2 in it:\n\nx <- 2\n\nNow, we can recall this value any time we evaluate x.\n\nx\n\n[1] 2\n\n\nNow look at the “Environment” pane on the top right. You should see this:\n\nWhat happened? Consider this analogy: you have a meal container, you put the number 2 in it, and you label the container as x.\n\nSo far, you have used “containers” without labelling them. When you executed 24 * 7, R created a container and put the number 168 in it. However, R is like a vigilant office administrator: anything unlabelled in the refrigerator will be tossed out! Thus, if you wanted access to this number again, you must calculate 24 * 7 from scratch.\nWe can perform calculations with objects just like we could with anything contained in that object. For instance, if you wanted 10 to the power of 2, we see that the following are equivalent:\n\n10 ^ 2\n\n[1] 100\n\n10 ^ x\n\n[1] 100\n\n\nJust like any real lunch container, we can always empty out old food and put new food in it. To do this, we simply assign some new value to x:\n\nx <- 3\n\n\n\n\n\n\n\nTip\n\n\n\nYou can use the keyboard shortcut Alt + - to insert the <- symbol with spaces around it. Recall that to use a keyboard shortcut, the “+” symbol means “press these keys at the same time”.\n\n\n\n\n\n\n\n\nExercises\n\n\n\n\nCreate an object named myState that holds your current state of residence (e.g., “Florida”). Use the logical check for equality to show that the myState object and the object “florida” are not equal.\nCreate a new object y which is x + 3. Examine y. Now assign x to be “FL”. What happens to y? Why? What does this tell you about x?"
  },
  {
    "objectID": "lessons/lesson02_introduction_to_R.html#vectors",
    "href": "lessons/lesson02_introduction_to_R.html#vectors",
    "title": "Lesson 2: Introduction to R",
    "section": "Vectors",
    "text": "Vectors\nRecall that our examples had scalar values? R, however, is designed to work with ordered sets of values, known as a vector. There are a few simple ways to make vectors in R, depending on what you want these vectors to contain. Let’s first make a vector of the digits on a keypad.\n\nkeypad <- 0:9\n\nWe see that the syntax a:b creates a sequence of integers from a to b. We can do everything with a vector of numbers that we could do with a scalar value:\n\nkeypad + 3\n\n [1]  3  4  5  6  7  8  9 10 11 12\n\nkeypad * 2\n\n [1]  0  2  4  6  8 10 12 14 16 18\n\n10 - keypad\n\n [1] 10  9  8  7  6  5  4  3  2  1\n\n2 ^ keypad\n\n [1]   1   2   4   8  16  32  64 128 256 512\n\nkeypad < 5\n\n [1]  TRUE  TRUE  TRUE  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE\n\n\n\n\n\n\n\n\nExercises\n\n\n\n\nCreate a sequence from 70 to 100. How does the display of this vector differ from the display of the object keypad?\nCreate a vector called revKeypad with the integers from 9 to 0.\nAll of the values we combined with the keypad vector were scalars. Multiply two vectors together: revKeypad * keypad. What happened? Is this what you expected?\nCreate a new vector of integers from -1 to 1. Multiply this new vector by keypad. What happened? Is this what you expected?"
  },
  {
    "objectID": "lessons/lesson02_introduction_to_R.html#the-concatenate-function",
    "href": "lessons/lesson02_introduction_to_R.html#the-concatenate-function",
    "title": "Lesson 2: Introduction to R",
    "section": "The “Concatenate” Function",
    "text": "The “Concatenate” Function\nOne of the most important functions you will learn is the function to create simple vectors:\n\nc(1, 3, 6, 12)\n\n[1]  1  3  6 12\n\n\nThe c() function will put almost anything you want into a single vector, provided that they are all similar things. For instance\n\nme <- c(\"Prof.\", \"Gabriel\", \"J.\", \"Odom\", \"PhD\", \"ThD\")\nme\n\n[1] \"Prof.\"   \"Gabriel\" \"J.\"      \"Odom\"    \"PhD\"     \"ThD\""
  },
  {
    "objectID": "lessons/lesson02_introduction_to_R.html#function-components",
    "href": "lessons/lesson02_introduction_to_R.html#function-components",
    "title": "Lesson 2: Introduction to R",
    "section": "Function Components",
    "text": "Function Components\nFunctions have three main components: its name, its arguments’ names, and its arguments’ values. For instance, the function to take an arithmetic mean in R is mean(). When you type mean in the Console pane, RStudio displays a hint on how to use the function. Let’s use this hint to find the expected roll on a six-sided die:\n\nmean(x = 1:6)\n\n[1] 3.5\n\n\nWe unpack this as follows:\n\nThe function is named “mean”.\nThe mean function has an argument named “x”.\nWe supply the vector of integers from 1 to 6 as the value to the argument “x”.\n\nWe can even put functions inside of other functions:\n\nlog(c(10, 100, 1000))\n\n[1] 2.302585 4.605170 6.907755\n\n\nNotice that the name of the argument to the mean() function is “x”. Most functions have named arguments, but the c() function does not. It allows you to choose your own names.\n\n\n\n\n\n\nExercises\n\n\n\n\nCreate a vector of your first name, last name, and your degrees with the c() function.\nCreate the same vector as above, but name each of the components as you create the vector. Hint: think back to how we referenced the name of the argument for the mean() function."
  },
  {
    "objectID": "lessons/lesson03_introduction_to_Quarto.html",
    "href": "lessons/lesson03_introduction_to_Quarto.html",
    "title": "Lesson 3: Quarto for Reproducible Reports",
    "section": "",
    "text": "What did we learn last class?\n\nEverything in R is an Object. Objects are baskets that are labelled and hold values. We learned about objects that contain character, numeric, or logical information, among other things.\nCreate new objects with containerName <- value syntax.\nR is a vectorised language: it treats single values as part of a larger set.\nUse functions with functionName(argumentName = argumentValue) syntax.\nGet help with ? or Google."
  },
  {
    "objectID": "lessons/lesson03_introduction_to_Quarto.html#setting-up-a-basic-qurto-file",
    "href": "lessons/lesson03_introduction_to_Quarto.html#setting-up-a-basic-qurto-file",
    "title": "Lesson 3: Quarto for Reproducible Reports",
    "section": "Setting up a Basic Qurto File",
    "text": "Setting up a Basic Qurto File\n\n\n\n\n\n\nExercise\n\n\n\nGo to “File” > “New File” > “Quarto Document…”.\n\n\nThis window appears, giving us some options:\n\nThis window gives us a few options:\n\nType of document:\n\nDocument (plain manuscript style)\nPresentation (slide deck)\nShiny (interactive website)\nFrom Template (download a template from a journal or major conference, and write your manuscript to their formatting specifications)\n\nTitle and Author(s): if you are working in a group, this is where you add the names of your co-authors\nOutput Format:\n\nHTML (the default). This is the recommended starting place for any document. I will show you how to change this output type for a document that you have already written. We will use this option now, as it is the easiest to learn.\nPDF (advanced). This output style requires that you have additional advanced software installed, such as Windows MiKTeX or MacOS MacTeX. If you plan to use LaTeX to write your PhD dissertation, then you should learn how to use these tools; otherwise, avoid this option. Most people don’t need it.\nWORD (intermediate). This output style requires you to have MS Word installed on your computer (most people do). We will use this option for our reports later in the semester.\n\n\n\n\n\n\n\n\nExercise\n\n\n\nCustomise your title and author fields. Once you have finished your customization, click “OK”."
  },
  {
    "objectID": "lessons/lesson03_introduction_to_Quarto.html#inspecting-your-quarto-file",
    "href": "lessons/lesson03_introduction_to_Quarto.html#inspecting-your-quarto-file",
    "title": "Lesson 3: Quarto for Reproducible Reports",
    "section": "Inspecting your Quarto File",
    "text": "Inspecting your Quarto File\nWe should all see this basic Quarto template:\n\nLet’s dive in to the structure and syntax of this document.\n\nThe Meta-Data Header\nThe first few lines of the document are the document header. These lines tell R crucial information about how to build your report. The entire header, and all of the document options in it, are bounded by the three horizontal dashes (---) above and below.\nCurrently our header is quite basic. It includes:\n\nThe title of the document; title: \"My First Quarto\"\nWho wrote it: author: \"Gabriel Odom\"\nToday’s date: date: \"format(Sys.time(), '%b %d, %Y')\" (this looks crazy, but don’t worry about it now; we will learn what this means later if we need to)\nThe output type: format: html\n\nNotice that each one of these options (other than the date) are directly filled by your choices in the previous window.\n\n\nCode Chunks\nThe next thing we see is a code chunk. Code chunks look like this:\n\nThe components are:\n\nComputing language: Quarto documents can compile more than just R code, but we specify the language R here (with r).\nChunk name: this part is not required, but it can be helpful if you have errors in your code to know where they come from.\nChunk options: there are a few common options, which we will discuss later. This echo=false option means that this code chunk will not be included in the report output.\nChunk delimiters: all code chunks start and end with three backticks (```). If you want code that will run in a certain language (which most of the time, we do), add {} after the opening set of backtick delimiters, and put the language in first. For example, a basic code chunk could look like\n\n\n\nChunk body: this is where you put the actual R code that you want to compute.\n\nNotice two more things: 1) code chunks are on a grey background so they are easier to spot in the document, and 2) you can test the code in the chunk by clicking the green “Run Current Chunk” button on the top right.\n\n\nMarkup Text\nNow that you have a report with a header and some code, you need to explain what your code is doing and why. This is where the plain text comes in. Outside of a code chunk, type anything you want. You can even include pictures and tables. We will discuss these options, and the text formatting options, later.\n\n\n\n\n\n\nExercise\n\n\n\nSave the report. Mac Users: make sure you add .qmd to the end of the file name."
  },
  {
    "objectID": "lessons/lesson03_introduction_to_Quarto.html#render-your-report",
    "href": "lessons/lesson03_introduction_to_Quarto.html#render-your-report",
    "title": "Lesson 3: Quarto for Reproducible Reports",
    "section": "Render your Report",
    "text": "Render your Report\nNow that you have saved the Quarto file, you can “Render” your report.\n\n\n\n\n\n\nExercise\n\n\n\nRender your report. This may require you to install some packages, so click “OK” on the installation popup.\n\n\n\nWhile your report is building, notice that the “Console” pane has a new tab called “Background Jobs”. If this tab isn’t already open, click on it. You should see the following (I’ve annotated some of the important components in blue):\n\nNote that the names of the code chunks appear in this build report, as well as their options. Any text that doesn’t include R code to evaluate is labelled as “ordinary text without R code”. We can also see the progress in percent on the right side of the report."
  },
  {
    "objectID": "lessons/lesson03_introduction_to_Quarto.html#inspect-the-final-product",
    "href": "lessons/lesson03_introduction_to_Quarto.html#inspect-the-final-product",
    "title": "Lesson 3: Quarto for Reproducible Reports",
    "section": "Inspect the Final Product",
    "text": "Inspect the Final Product\nFinally, we have a rendered report!\n\nWe can see how each of the components of the original .qmd file control the look of the report itself. We can see that the meta-data set the title, author, and date of the report. We can see how the typed text is formatted in the final report.\n\n\n\n\n\n\nExercise\n\n\n\nCompare the three code chunks and their options with what R code appears in the report. Can you explain what the code chunk options are doing?"
  },
  {
    "objectID": "lessons/lesson03_introduction_to_Quarto.html#the-quarto-guide",
    "href": "lessons/lesson03_introduction_to_Quarto.html#the-quarto-guide",
    "title": "Lesson 3: Quarto for Reproducible Reports",
    "section": "The Quarto Guide",
    "text": "The Quarto Guide\nSo that you don’t have to try to remember all of what we just covered in excruciating detail, there is a very handy website with all of the major points of today’s lesson: https://quarto.org/."
  },
  {
    "objectID": "lessons/lesson03_introduction_to_Quarto.html#including-code-chunks",
    "href": "lessons/lesson03_introduction_to_Quarto.html#including-code-chunks",
    "title": "Lesson 3: Quarto for Reproducible Reports",
    "section": "Including Code Chunks",
    "text": "Including Code Chunks\nTo construct your own report, you will need to create your own code chunks. The keyboard shortcut for this is CTRL + Alt + I on Windows, CMD + Alt + I on Mac. This will insert a basic code chunk with the R language selected. From there, you can name your chunk, add chunk options, and include code for R to execute. For chunk options, see Section 5 of the cheat sheet."
  },
  {
    "objectID": "lessons/lesson03_introduction_to_Quarto.html#annotating-your-work",
    "href": "lessons/lesson03_introduction_to_Quarto.html#annotating-your-work",
    "title": "Lesson 3: Quarto for Reproducible Reports",
    "section": "Annotating your Work",
    "text": "Annotating your Work\nGood code has good explanations. Whenever you write code, you should include explanations for why you are doing what you are doing. Good code should be readable, in the sense that someone who knows the language can look at the code and see what you are doing. However, no one but you knows exactly why you chose to do what you did in the way that you did it.\nAs will most textual explanation, we often need to organize it, format it, and add supplemental figures and tables to explain it. Here are the rules for formatting your report:\n\n\n\n\n\n\n\nExercises\n\n\n\n\nMake a Quarto report to include some of your notes from the past few lectures. Include:\n\ncode examples\nannotations for what you learned about the code you had to write\nan image of a meme that you find funny (look at the cheat sheet for how to include images) as a hyperlink\n\nRender your report as an .html document first, and check to see that your formatting is appropriate.\nAlso render your report as a Word document. Note the slight changes in formatting.\n\n\n\nCongratulations! You are now well on your way to writing powerful and flexible scientific reports with Quarto.\n\n\n\n\n\n\nFinal Exercise\n\n\n\nInstall the tidyverse package the same way you installed the knitr package above. (We need it for next class.)"
  },
  {
    "objectID": "lessons/lesson09_dplyr.html",
    "href": "lessons/lesson09_dplyr.html",
    "title": "Lesson 9: Data Manipulation with dplyr",
    "section": "",
    "text": "What did we learn last class?\n\nFind some raw data\nReading in flat text / CSV files\nTibbles and “tidy” data\nWriting flat text / CSV files\nThe pipe (%>%) operator"
  },
  {
    "objectID": "lessons/lesson09_dplyr.html#common-functions",
    "href": "lessons/lesson09_dplyr.html#common-functions",
    "title": "Lesson 9: Data Manipulation with dplyr",
    "section": "Common Functions",
    "text": "Common Functions\nThese functions all operate on tidy data frames:\n\nfilter(): return rows that match a certain set of conditions\narrange(): sort rows by a given set of measurements\nselect(): select, rename, and / or reorder columns\nmutate(): create new columns (often as functions of your existing columns)\ngroup_by(): group rows by chosen columns\nsummarise(): collapse multiple rows into one (often paired with group_by() for group summaries)\n*_join(): match observations from one tibble to observations from another\n\nAll of these functions have very similar syntax: function(data_df, ...). The ellipsis will take in the additional conditions or arguments for the function, and column names are passed unquoted. Because these functions all take in the data as their first argument and return the new data set, these functions are often written with the pipe operator we learned last class as data_df %>% function(...). Additionally, these functions do not create new data objects. If you want to keep the transformed data table you’ve created, you must store it as an object.\n\n\n\n\n\n\nImportant\n\n\n\nThe dplyr functions do not create new data objects. If you want to keep the transformed data table you’ve created, you must store it as an object.\n\n\nThese functions are all from the dplyr package, which is in the tidyverse. Load it now.\n\nlibrary(tidyverse)\n\nIf you get stuck, the dplyr cheat sheet is here: https://www.rstudio.com/wp-content/uploads/2015/02/data-wrangling-cheatsheet.pdf"
  },
  {
    "objectID": "lessons/lesson09_dplyr.html#example-data",
    "href": "lessons/lesson09_dplyr.html#example-data",
    "title": "Lesson 9: Data Manipulation with dplyr",
    "section": "Example Data",
    "text": "Example Data\nOur example data set has measurements on all flights departing the Greater New York City area in 2013. It has 336,776 unique flights and 19 measurements on those flights. We will use this data set to explore a few of the more commonly-used dplyr functions. Load the nycflights13 package you installed last class:\n\nlibrary(nycflights13)\nflights\n\n# A tibble: 336,776 × 19\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   <int> <int> <int>    <int>          <int>     <dbl>    <int>          <int>\n 1  2013     1     1      517            515         2      830            819\n 2  2013     1     1      533            529         4      850            830\n 3  2013     1     1      542            540         2      923            850\n 4  2013     1     1      544            545        -1     1004           1022\n 5  2013     1     1      554            600        -6      812            837\n 6  2013     1     1      554            558        -4      740            728\n 7  2013     1     1      555            600        -5      913            854\n 8  2013     1     1      557            600        -3      709            723\n 9  2013     1     1      557            600        -3      838            846\n10  2013     1     1      558            600        -2      753            745\n# ℹ 336,766 more rows\n# ℹ 11 more variables: arr_delay <dbl>, carrier <chr>, flight <int>,\n#   tailnum <chr>, origin <chr>, dest <chr>, air_time <dbl>, distance <dbl>,\n#   hour <dbl>, minute <dbl>, time_hour <dttm>"
  },
  {
    "objectID": "lessons/lesson09_dplyr.html#examples",
    "href": "lessons/lesson09_dplyr.html#examples",
    "title": "Lesson 9: Data Manipulation with dplyr",
    "section": "Examples",
    "text": "Examples\n\nFind all the flights on Christmas Eve. We’ll use the same code structure as the code for finding all the New Year’s Day flights.\n\n\nflights %>% filter(month == 12, day == 24)\n\n# A tibble: 761 × 19\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   <int> <int> <int>    <int>          <int>     <dbl>    <int>          <int>\n 1  2013    12    24        9           2359        10      444            445\n 2  2013    12    24      458            500        -2      652            651\n 3  2013    12    24      513            515        -2      813            814\n 4  2013    12    24      543            540         3      844            850\n 5  2013    12    24      546            550        -4     1032           1027\n 6  2013    12    24      555            600        -5      851            915\n 7  2013    12    24      556            600        -4      845            846\n 8  2013    12    24      557            600        -3      908            849\n 9  2013    12    24      558            600        -2      827            831\n10  2013    12    24      558            600        -2      729            718\n# ℹ 751 more rows\n# ℹ 11 more variables: arr_delay <dbl>, carrier <chr>, flight <int>,\n#   tailnum <chr>, origin <chr>, dest <chr>, air_time <dbl>, distance <dbl>,\n#   hour <dbl>, minute <dbl>, time_hour <dttm>\n\n\n\nFind all flights during the summer months (June, July, and August).\n\n\nflights %>% filter(month %in% c(6, 7, 8))\n\n# A tibble: 86,995 × 19\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   <int> <int> <int>    <int>          <int>     <dbl>    <int>          <int>\n 1  2013     6     1        2           2359         3      341            350\n 2  2013     6     1      451            500        -9      624            640\n 3  2013     6     1      506            515        -9      715            800\n 4  2013     6     1      534            545       -11      800            829\n 5  2013     6     1      538            545        -7      925            922\n 6  2013     6     1      539            540        -1      832            840\n 7  2013     6     1      546            600       -14      850            910\n 8  2013     6     1      551            600        -9      828            850\n 9  2013     6     1      552            600        -8      647            655\n10  2013     6     1      553            600        -7      700            711\n# ℹ 86,985 more rows\n# ℹ 11 more variables: arr_delay <dbl>, carrier <chr>, flight <int>,\n#   tailnum <chr>, origin <chr>, dest <chr>, air_time <dbl>, distance <dbl>,\n#   hour <dbl>, minute <dbl>, time_hour <dttm>\n\n\n\nFind all flights that did not depart from Newark Liberty.\n\n\nflights %>% filter(origin != \"EWR\")\n\n# A tibble: 215,941 × 19\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   <int> <int> <int>    <int>          <int>     <dbl>    <int>          <int>\n 1  2013     1     1      533            529         4      850            830\n 2  2013     1     1      542            540         2      923            850\n 3  2013     1     1      544            545        -1     1004           1022\n 4  2013     1     1      554            600        -6      812            837\n 5  2013     1     1      557            600        -3      709            723\n 6  2013     1     1      557            600        -3      838            846\n 7  2013     1     1      558            600        -2      753            745\n 8  2013     1     1      558            600        -2      849            851\n 9  2013     1     1      558            600        -2      853            856\n10  2013     1     1      558            600        -2      924            917\n# ℹ 215,931 more rows\n# ℹ 11 more variables: arr_delay <dbl>, carrier <chr>, flight <int>,\n#   tailnum <chr>, origin <chr>, dest <chr>, air_time <dbl>, distance <dbl>,\n#   hour <dbl>, minute <dbl>, time_hour <dttm>\n\n\n\nFind all JetBlue (“B6”) or Southwest (“WN”) flights.\n\n\nflights %>% filter(carrier == \"B6\" | carrier == \"WN\")\n\n# A tibble: 66,910 × 19\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   <int> <int> <int>    <int>          <int>     <dbl>    <int>          <int>\n 1  2013     1     1      544            545        -1     1004           1022\n 2  2013     1     1      555            600        -5      913            854\n 3  2013     1     1      557            600        -3      838            846\n 4  2013     1     1      558            600        -2      849            851\n 5  2013     1     1      558            600        -2      853            856\n 6  2013     1     1      559            559         0      702            706\n 7  2013     1     1      600            600         0      851            858\n 8  2013     1     1      601            600         1      844            850\n 9  2013     1     1      613            610         3      925            921\n10  2013     1     1      615            615         0     1039           1100\n# ℹ 66,900 more rows\n# ℹ 11 more variables: arr_delay <dbl>, carrier <chr>, flight <int>,\n#   tailnum <chr>, origin <chr>, dest <chr>, air_time <dbl>, distance <dbl>,\n#   hour <dbl>, minute <dbl>, time_hour <dttm>\n\n\n\nFind any flights out of LaGuardia that actually left on time.\n\n\nflights %>% filter(origin == \"LGA\" & dep_delay <= 0)\n\n# A tibble: 67,819 × 19\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   <int> <int> <int>    <int>          <int>     <dbl>    <int>          <int>\n 1  2013     1     1      554            600        -6      812            837\n 2  2013     1     1      557            600        -3      709            723\n 3  2013     1     1      558            600        -2      753            745\n 4  2013     1     1      559            600        -1      941            910\n 5  2013     1     1      600            600         0      851            858\n 6  2013     1     1      600            600         0      837            825\n 7  2013     1     1      602            610        -8      812            820\n 8  2013     1     1      602            605        -3      821            805\n 9  2013     1     1      623            627        -4      933            932\n10  2013     1     1      624            630        -6      840            830\n# ℹ 67,809 more rows\n# ℹ 11 more variables: arr_delay <dbl>, carrier <chr>, flight <int>,\n#   tailnum <chr>, origin <chr>, dest <chr>, air_time <dbl>, distance <dbl>,\n#   hour <dbl>, minute <dbl>, time_hour <dttm>"
  },
  {
    "objectID": "lessons/lesson09_dplyr.html#select-columns-that-meet-our-criteria",
    "href": "lessons/lesson09_dplyr.html#select-columns-that-meet-our-criteria",
    "title": "Lesson 9: Data Manipulation with dplyr",
    "section": "Select Columns that Meet Our Criteria",
    "text": "Select Columns that Meet Our Criteria\nWe first select three columns specifically by their names.\n\nflights %>% select(year, month, day)\n\n# A tibble: 336,776 × 3\n    year month   day\n   <int> <int> <int>\n 1  2013     1     1\n 2  2013     1     1\n 3  2013     1     1\n 4  2013     1     1\n 5  2013     1     1\n 6  2013     1     1\n 7  2013     1     1\n 8  2013     1     1\n 9  2013     1     1\n10  2013     1     1\n# ℹ 336,766 more rows\n\n\nNotice that we only have the three columns we explicitly requested by name and no more. The select() function will drop whatever we don’t ask for by default, but we can change this behaviour by adding the additional everything() argument (we’ll come back to this in the “reordering columns” section).\nWe could have also specified a range of column names to achieve the same effect.\n\nflights %>% select(year:day)\n\n# A tibble: 336,776 × 3\n    year month   day\n   <int> <int> <int>\n 1  2013     1     1\n 2  2013     1     1\n 3  2013     1     1\n 4  2013     1     1\n 5  2013     1     1\n 6  2013     1     1\n 7  2013     1     1\n 8  2013     1     1\n 9  2013     1     1\n10  2013     1     1\n# ℹ 336,766 more rows\n\n\nIf you have used regular expressions or performed string manipulation before, you can also use the following modifiers to the select() function:\n\nFind all the columns with names starting with “dep_”.\n\n\nflights %>% select(starts_with(\"dep_\"))\n\n# A tibble: 336,776 × 2\n   dep_time dep_delay\n      <int>     <dbl>\n 1      517         2\n 2      533         4\n 3      542         2\n 4      544        -1\n 5      554        -6\n 6      554        -4\n 7      555        -5\n 8      557        -3\n 9      557        -3\n10      558        -2\n# ℹ 336,766 more rows\n\n\n\nFind all the columns with names ending with “ay”.\n\n\nflights %>% select(ends_with(\"ay\"))\n\n# A tibble: 336,776 × 3\n     day dep_delay arr_delay\n   <int>     <dbl>     <dbl>\n 1     1         2        11\n 2     1         4        20\n 3     1         2        33\n 4     1        -1       -18\n 5     1        -6       -25\n 6     1        -4        12\n 7     1        -5        19\n 8     1        -3       -14\n 9     1        -3        -8\n10     1        -2         8\n# ℹ 336,766 more rows\n\n\n\nFind all the columns with names that contain “time”.\n\n\nflights %>% select(contains(\"time\"))\n\n# A tibble: 336,776 × 6\n   dep_time sched_dep_time arr_time sched_arr_time air_time time_hour          \n      <int>          <int>    <int>          <int>    <dbl> <dttm>             \n 1      517            515      830            819      227 2013-01-01 05:00:00\n 2      533            529      850            830      227 2013-01-01 05:00:00\n 3      542            540      923            850      160 2013-01-01 05:00:00\n 4      544            545     1004           1022      183 2013-01-01 05:00:00\n 5      554            600      812            837      116 2013-01-01 06:00:00\n 6      554            558      740            728      150 2013-01-01 05:00:00\n 7      555            600      913            854      158 2013-01-01 06:00:00\n 8      557            600      709            723       53 2013-01-01 06:00:00\n 9      557            600      838            846      140 2013-01-01 06:00:00\n10      558            600      753            745      138 2013-01-01 06:00:00\n# ℹ 336,766 more rows\n\n\n\nFind all the columns with names that start with exactly three lower case letters followed by “_“.\n\n\nflights %>% select(matches(\"^[a-z]{3}\\\\_\"))\n\n# A tibble: 336,776 × 5\n   dep_time dep_delay arr_time arr_delay air_time\n      <int>     <dbl>    <int>     <dbl>    <dbl>\n 1      517         2      830        11      227\n 2      533         4      850        20      227\n 3      542         2      923        33      160\n 4      544        -1     1004       -18      183\n 5      554        -6      812       -25      116\n 6      554        -4      740        12      150\n 7      555        -5      913        19      158\n 8      557        -3      709       -14       53\n 9      557        -3      838        -8      140\n10      558        -2      753         8      138\n# ℹ 336,766 more rows\n\n\nThe matches() function takes in a regular expression. If you have never used regular expressions for string queries before, don’t be afraid. You can do most of the things you need without ever touching the matches() function. However, if you do find yourself needing some help with string manipulation in R, please see the stringr package cheat sheet from the RStudio Cheat Sheets page and the strings chapter from R for Data Science. You can also practice building expressions on https://regexr.com/."
  },
  {
    "objectID": "lessons/lesson09_dplyr.html#remove-reorder-or-rename",
    "href": "lessons/lesson09_dplyr.html#remove-reorder-or-rename",
    "title": "Lesson 9: Data Manipulation with dplyr",
    "section": "Remove, Reorder, or Rename",
    "text": "Remove, Reorder, or Rename\n\nRemove Columns\nWe can also use “negative indexing” to select all the columns except for the columns we named.\n\nflights %>% select(-(year:day))\n\n# A tibble: 336,776 × 16\n   dep_time sched_dep_time dep_delay arr_time sched_arr_time arr_delay carrier\n      <int>          <int>     <dbl>    <int>          <int>     <dbl> <chr>  \n 1      517            515         2      830            819        11 UA     \n 2      533            529         4      850            830        20 UA     \n 3      542            540         2      923            850        33 AA     \n 4      544            545        -1     1004           1022       -18 B6     \n 5      554            600        -6      812            837       -25 DL     \n 6      554            558        -4      740            728        12 UA     \n 7      555            600        -5      913            854        19 B6     \n 8      557            600        -3      709            723       -14 EV     \n 9      557            600        -3      838            846        -8 B6     \n10      558            600        -2      753            745         8 AA     \n# ℹ 336,766 more rows\n# ℹ 9 more variables: flight <int>, tailnum <chr>, origin <chr>, dest <chr>,\n#   air_time <dbl>, distance <dbl>, hour <dbl>, minute <dbl>, time_hour <dttm>\n\n\nThis is particularly useful when we have filtered out all of one type of observation. We can then remove the redundant column information. For instance, previously we filtered only the flights leaving on 1 January, 2013. However, we still had the year, month, and day columns in this data table, even though this information was superfluous after filtering.\n\n# Before\nflights %>%\n  filter(month == 1, day == 1)\n\n# A tibble: 842 × 19\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   <int> <int> <int>    <int>          <int>     <dbl>    <int>          <int>\n 1  2013     1     1      517            515         2      830            819\n 2  2013     1     1      533            529         4      850            830\n 3  2013     1     1      542            540         2      923            850\n 4  2013     1     1      544            545        -1     1004           1022\n 5  2013     1     1      554            600        -6      812            837\n 6  2013     1     1      554            558        -4      740            728\n 7  2013     1     1      555            600        -5      913            854\n 8  2013     1     1      557            600        -3      709            723\n 9  2013     1     1      557            600        -3      838            846\n10  2013     1     1      558            600        -2      753            745\n# ℹ 832 more rows\n# ℹ 11 more variables: arr_delay <dbl>, carrier <chr>, flight <int>,\n#   tailnum <chr>, origin <chr>, dest <chr>, air_time <dbl>, distance <dbl>,\n#   hour <dbl>, minute <dbl>, time_hour <dttm>\n\n# After\nflights %>%\n  filter(month == 1, day == 1) %>% \n  select(-year, -month, -day)\n\n# A tibble: 842 × 16\n   dep_time sched_dep_time dep_delay arr_time sched_arr_time arr_delay carrier\n      <int>          <int>     <dbl>    <int>          <int>     <dbl> <chr>  \n 1      517            515         2      830            819        11 UA     \n 2      533            529         4      850            830        20 UA     \n 3      542            540         2      923            850        33 AA     \n 4      544            545        -1     1004           1022       -18 B6     \n 5      554            600        -6      812            837       -25 DL     \n 6      554            558        -4      740            728        12 UA     \n 7      555            600        -5      913            854        19 B6     \n 8      557            600        -3      709            723       -14 EV     \n 9      557            600        -3      838            846        -8 B6     \n10      558            600        -2      753            745         8 AA     \n# ℹ 832 more rows\n# ℹ 9 more variables: flight <int>, tailnum <chr>, origin <chr>, dest <chr>,\n#   air_time <dbl>, distance <dbl>, hour <dbl>, minute <dbl>, time_hour <dttm>\n\n\n\n\nReorder Columns\nAs we alluded to above, we can also use the select() function to change the order of the columns of the data table, without removing the columns we don’t explicitely name, with the helpof the everything() function.\n\nflights %>% select(time_hour, air_time, everything())\n\n# A tibble: 336,776 × 19\n   time_hour           air_time  year month   day dep_time sched_dep_time\n   <dttm>                 <dbl> <int> <int> <int>    <int>          <int>\n 1 2013-01-01 05:00:00      227  2013     1     1      517            515\n 2 2013-01-01 05:00:00      227  2013     1     1      533            529\n 3 2013-01-01 05:00:00      160  2013     1     1      542            540\n 4 2013-01-01 05:00:00      183  2013     1     1      544            545\n 5 2013-01-01 06:00:00      116  2013     1     1      554            600\n 6 2013-01-01 05:00:00      150  2013     1     1      554            558\n 7 2013-01-01 06:00:00      158  2013     1     1      555            600\n 8 2013-01-01 06:00:00       53  2013     1     1      557            600\n 9 2013-01-01 06:00:00      140  2013     1     1      557            600\n10 2013-01-01 06:00:00      138  2013     1     1      558            600\n# ℹ 336,766 more rows\n# ℹ 12 more variables: dep_delay <dbl>, arr_time <int>, sched_arr_time <int>,\n#   arr_delay <dbl>, carrier <chr>, flight <int>, tailnum <chr>, origin <chr>,\n#   dest <chr>, distance <dbl>, hour <dbl>, minute <dbl>\n\n\n\n\nRename Columns\nWhile the select() function can rename columns, we recommend using the rename() function for better readibility of your code instead. This function takes in the data table and an argument that follows the [new name] = [old name] syntax. For example, we notice that all of the column names with more than one word are written in snake_case except for tailnum. We can rename this column to match our naming convention. However, we must save the results of the output of the rename() function. Otherwise, the data table with the new column name will print to the screen but never be saved anywhere. We can use the names() function to check that our new name stuck.\n\nflights <- rename(flights, tail_num = tailnum)\nnames(flights)\n\n [1] \"year\"           \"month\"          \"day\"            \"dep_time\"      \n [5] \"sched_dep_time\" \"dep_delay\"      \"arr_time\"       \"sched_arr_time\"\n [9] \"arr_delay\"      \"carrier\"        \"flight\"         \"tail_num\"      \n[13] \"origin\"         \"dest\"           \"air_time\"       \"distance\"      \n[17] \"hour\"           \"minute\"         \"time_hour\""
  },
  {
    "objectID": "lessons/lesson09_dplyr.html#the-case_when-function",
    "href": "lessons/lesson09_dplyr.html#the-case_when-function",
    "title": "Lesson 9: Data Manipulation with dplyr",
    "section": "The case_when() Function",
    "text": "The case_when() Function\nWe can use the mutate() in conjunction with the case_when() function to add a label indicating if the flight has beverage service, meals for sale, or meals included. In order to use the case_when() function, we need to map out all of the meal options and the flight durations that trigger them. This will take the form of a giant IF-THEN ladder:\n\nIF air_time <= 50 THEN no beverage service or snacks\nIF 50 < air_time AND air_time <= 2.5 * 60 THEN beverage and snacks\nIF 2.5 * 60 < air_time AND air_time <= 4 * 60 THEN beverage and snacks with meals for sale\nIF 4 * 60 < air_time AND air_time <= 7 * 60 THEN beverage, snacks, and 1 meal\nIF 7 * 60 < air_time THEN beverage, snacks, and 2 meals\n\nThe syntax to use the case_when() function is:\n\nthe IF statement is automatically included\nAND and OR use R’s regular functions: &, |\nTHEN is the tilde symbol, ~.\n\nThus, the code to add flight food labels is:\n\nflights %>%\n  mutate(\n    food = case_when(\n      air_time <= 50 ~\n        \"none\",\n      50 < air_time & air_time <= 2.5 * 60 ~\n        \"drinks + light snacks\",\n      2.5 * 60 < air_time & air_time <= 4 * 60 ~\n        \"drinks + heavy snacks\",\n      4 * 60 < air_time & air_time <= 7 * 60 ~\n        \"drinks, snacks, and 1 meal\",\n      7 * 60 < air_time ~\n        \"drinks, snacks, and 2 meals\"\n    )\n  ) %>%  \n  select(air_time, food)\n\n# A tibble: 336,776 × 2\n   air_time food                 \n      <dbl> <chr>                \n 1      227 drinks + heavy snacks\n 2      227 drinks + heavy snacks\n 3      160 drinks + heavy snacks\n 4      183 drinks + heavy snacks\n 5      116 drinks + light snacks\n 6      150 drinks + light snacks\n 7      158 drinks + heavy snacks\n 8       53 drinks + light snacks\n 9      140 drinks + light snacks\n10      138 drinks + light snacks\n# ℹ 336,766 more rows\n\n\nThe code pieces on the left and right of the tilde are called expressions, and they are used to construct functions. The mutate() function can also make use of functions you construct. We will discuss this more in the lesson on control flow and functions."
  },
  {
    "objectID": "lessons/lesson09_dplyr.html#examples-1",
    "href": "lessons/lesson09_dplyr.html#examples-1",
    "title": "Lesson 9: Data Manipulation with dplyr",
    "section": "Examples",
    "text": "Examples\nThe possible uses of the mutate() function are practically endless, but we can look a few examples.\n\nBasic Arithmetic\nWe may not be concerned with the actual distance of a flight, but perhaps its difference from the average flight distance.\n\nflights %>% \n  transmute(residual_dist = distance - mean(distance))\n\n# A tibble: 336,776 × 1\n   residual_dist\n           <dbl>\n 1         360. \n 2         376. \n 3          49.1\n 4         536. \n 5        -278. \n 6        -321. \n 7          25.1\n 8        -811. \n 9         -95.9\n10        -307. \n# ℹ 336,766 more rows\n\n\nPerhaps we want to add an indicator for “long flights” (American Airlines considers a long flight any flight over four-and-a-half hours) and then order these flights by flight time, excluding flights to Honolulu.\n\nflights %>%\n  mutate(long_flight = air_time >= 270) %>% \n  filter(dest != \"HNL\") %>% \n  select(dest, long_flight, air_time, everything()) %>% \n  arrange(desc(air_time))\n\n# A tibble: 336,069 × 20\n   dest  long_flight air_time  year month   day dep_time sched_dep_time\n   <chr> <lgl>          <dbl> <int> <int> <int>    <int>          <int>\n 1 SFO   TRUE             490  2013     7    28     1727           1730\n 2 LAX   TRUE             440  2013    11    22     1812           1815\n 3 SFO   TRUE             438  2013    12     6     1727           1730\n 4 ANC   TRUE             434  2013     8     3     1615           1615\n 5 ANC   TRUE             428  2013     8    24     1633           1625\n 6 SFO   TRUE             426  2013    12     6     1746           1745\n 7 SFO   TRUE             422  2013     2     4      747            745\n 8 LAX   TRUE             422  2013     7    10     1814           1815\n 9 SFO   TRUE             421  2013     8     8     1724           1710\n10 SFO   TRUE             420  2013     8     8     1819           1519\n# ℹ 336,059 more rows\n# ℹ 12 more variables: dep_delay <dbl>, arr_time <int>, sched_arr_time <int>,\n#   arr_delay <dbl>, carrier <chr>, flight <int>, tail_num <chr>, origin <chr>,\n#   distance <dbl>, hour <dbl>, minute <dbl>, time_hour <dttm>\n\n\n\n\nTime and Modular Arithmetic (Optional)\nThe departure and arrival times are presented in a readable form of hours as the first two digits and and minutes as the last two (for example, 5:17AM is 517). However, we can’t subtract arrival time from departure time because these times are not proper continuous variables. We can create two new columns which measure the number of minutes after midnight for both departure and arrival (using modular arithmetic). We will then move these columns to the front so we can see them.\n\nflights %>%\n  mutate(\n    dep_time_min = (dep_time %/% 100) * 60 + dep_time %% 100,\n    arr_time_min = (arr_time %/% 100) * 60 + arr_time %% 100\n  ) %>% \n  select(starts_with(\"dep_time\"), starts_with(\"arr_time\"), everything())\n\n# A tibble: 336,776 × 21\n   dep_time dep_time_min arr_time arr_time_min  year month   day sched_dep_time\n      <int>        <dbl>    <int>        <dbl> <int> <int> <int>          <int>\n 1      517          317      830          510  2013     1     1            515\n 2      533          333      850          530  2013     1     1            529\n 3      542          342      923          563  2013     1     1            540\n 4      544          344     1004          604  2013     1     1            545\n 5      554          354      812          492  2013     1     1            600\n 6      554          354      740          460  2013     1     1            558\n 7      555          355      913          553  2013     1     1            600\n 8      557          357      709          429  2013     1     1            600\n 9      557          357      838          518  2013     1     1            600\n10      558          358      753          473  2013     1     1            600\n# ℹ 336,766 more rows\n# ℹ 13 more variables: dep_delay <dbl>, sched_arr_time <int>, arr_delay <dbl>,\n#   carrier <chr>, flight <int>, tail_num <chr>, origin <chr>, dest <chr>,\n#   air_time <dbl>, distance <dbl>, hour <dbl>, minute <dbl>, time_hour <dttm>\n\n\nThe %% operator is the modulo operator (sometimes called the “remainder” operator) in R. The a %% b operation returns the remainder after dividing a by b. The %/% operator is the integer division operator; the a %/% b operation returns the quotient of a and b with any decimal information discarded."
  },
  {
    "objectID": "lessons/lesson09_dplyr.html#chaining-operations-together",
    "href": "lessons/lesson09_dplyr.html#chaining-operations-together",
    "title": "Lesson 9: Data Manipulation with dplyr",
    "section": "Chaining Operations Together",
    "text": "Chaining Operations Together\nWe have already used the pipe (%>%) operator quite a bit. This allows us to chain multiple steps together. For example, we might want to plot the relationship between flight distance and arrival delay (if you don’t remember how to use ggplot(), take a look at the Review section).\n\n# Create a \"delays\" data table\ndelays <- flights %>% \n  group_by(dest) %>% \n  summarise(\n    count = n(),\n    dist = mean(distance, na.rm = TRUE),\n    delay = mean(arr_delay, na.rm = TRUE)\n  ) %>% \n  # We don't want any small airports, or Honolulu\n  filter(count > 20, dest != \"HNL\")\n\n# Plot the delays and add a smoother\nggplot(data = delays) +\n  aes(x = dist, y = delay) +\n  geom_point(aes(size = count), alpha = 1/3) +\n  geom_smooth(se = FALSE)\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'"
  },
  {
    "objectID": "lessons/lesson09_dplyr.html#adding-and-visualising-counts",
    "href": "lessons/lesson09_dplyr.html#adding-and-visualising-counts",
    "title": "Lesson 9: Data Manipulation with dplyr",
    "section": "Adding and Visualising Counts",
    "text": "Adding and Visualising Counts\nLet’s look at the average delay by plane. Based on this graph, there are some planes with an average delay of over five hours! But how many flights did that plane make? We need to add a count.\n\ndelays <- not_cancelled %>% \n  group_by(tail_num) %>% \n  summarise(\n    delay = mean(arr_delay)\n  )\n\nggplot(data = delays) + \n  aes(x = delay) +\n  geom_freqpoly(binwidth = 10)\n\n\n\n\nNow that we add a count and re-plot the average arrival delay, we immediately see the Central Limit Theorem in action. All those planes with massive average delays only had one or two flights.\n\ndelays <- not_cancelled %>% \n  group_by(tail_num) %>% \n  summarise(\n    delay = mean(arr_delay, na.rm = TRUE),\n    n = n()\n  )\n\nggplot(data = delays) + \n  aes(x = n, y = delay) +\n  geom_point(alpha = 1/10)\n\n\n\n\nWe can remove any planes with fewer than 30 flights and re-visualize the relationships between average delay and number of flights and the overall count-delay distribution.\n\ndelays %>% \n  filter(n >= 30) %>% \n  ggplot() + \n    aes(x = n, y = delay) +\n    geom_point(alpha = 1/10)\n\n\n\ndelays %>% \n  filter(n >= 30) %>% \n  ggplot() + \n    aes(x = delay) +\n    geom_freqpoly(binwidth = 10)"
  },
  {
    "objectID": "lessons/lesson09_dplyr.html#other-useful-summaries",
    "href": "lessons/lesson09_dplyr.html#other-useful-summaries",
    "title": "Lesson 9: Data Manipulation with dplyr",
    "section": "Other Useful Summaries",
    "text": "Other Useful Summaries\nWe know that passengers don’t usually complain if their flight is early, but our dep_delay has negative values for flights which left early. We can find the average true “delay” by taking the summary of only the positive delay values.\n\nnot_cancelled %>% \n  group_by(year, month, day) %>% \n  summarise(\n    avg_delay1 = mean(arr_delay),\n    # the average positive delay\n    avg_delay2 = mean(arr_delay[arr_delay > 0])\n  )\n\n`summarise()` has grouped output by 'year', 'month'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 365 × 5\n# Groups:   year, month [12]\n    year month   day avg_delay1 avg_delay2\n   <int> <int> <int>      <dbl>      <dbl>\n 1  2013     1     1     12.7         32.5\n 2  2013     1     2     12.7         32.0\n 3  2013     1     3      5.73        27.7\n 4  2013     1     4     -1.93        28.3\n 5  2013     1     5     -1.53        22.6\n 6  2013     1     6      4.24        24.4\n 7  2013     1     7     -4.95        27.8\n 8  2013     1     8     -3.23        20.8\n 9  2013     1     9     -0.264       25.6\n10  2013     1    10     -5.90        27.3\n# ℹ 355 more rows\n\n\n\nExamples\n\nWe can find the proportion of flights by day that are delayed longer than 1 hour.\n\n\nnot_cancelled %>% \n  group_by(year, month, day) %>% \n  summarise(hour_perc = mean(arr_delay > 60))\n\n`summarise()` has grouped output by 'year', 'month'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 365 × 4\n# Groups:   year, month [12]\n    year month   day hour_perc\n   <int> <int> <int>     <dbl>\n 1  2013     1     1    0.0722\n 2  2013     1     2    0.0851\n 3  2013     1     3    0.0567\n 4  2013     1     4    0.0396\n 5  2013     1     5    0.0349\n 6  2013     1     6    0.0470\n 7  2013     1     7    0.0333\n 8  2013     1     8    0.0213\n 9  2013     1     9    0.0202\n10  2013     1    10    0.0183\n# ℹ 355 more rows\n\n\n\nWe can also measure parametric and non-parametric spread or variability.\n\n\nnot_cancelled %>% \n  group_by(dest) %>% \n  summarise(distance_sd = sd(distance)) %>% \n  arrange(desc(distance_sd))\n\n# A tibble: 104 × 2\n   dest  distance_sd\n   <chr>       <dbl>\n 1 EGE         10.5 \n 2 SAN         10.4 \n 3 SFO         10.2 \n 4 HNL         10.0 \n 5 SEA          9.98\n 6 LAS          9.91\n 7 PDX          9.87\n 8 PHX          9.86\n 9 LAX          9.66\n10 IND          9.46\n# ℹ 94 more rows\n\nnot_cancelled %>% \n  group_by(year, month, day) %>% \n  summarise(\n    first = min(dep_time),\n    p25 = quantile(dep_time, 0.25),\n    last = max(dep_time)\n  )\n\n`summarise()` has grouped output by 'year', 'month'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 365 × 6\n# Groups:   year, month [12]\n    year month   day first   p25  last\n   <int> <int> <int> <int> <dbl> <int>\n 1  2013     1     1   517  938.  2356\n 2  2013     1     2    42  912.  2354\n 3  2013     1     3    32  909   2349\n 4  2013     1     4    25  901.  2358\n 5  2013     1     5    14  859   2357\n 6  2013     1     6    16 1003   2355\n 7  2013     1     7    49  907.  2359\n 8  2013     1     8   454  858   2351\n 9  2013     1     9     2  858   2252\n10  2013     1    10     3  859   2320\n# ℹ 355 more rows\n\n\n\nBecause counting by groups is so common, we can use the shorthand count() function.\n\n\n# Instead of \nnot_cancelled %>%\n  group_by(dest) %>%\n  summarise(n = n())\n\n# A tibble: 104 × 2\n   dest      n\n   <chr> <int>\n 1 ABQ     254\n 2 ACK     264\n 3 ALB     418\n 4 ANC       8\n 5 ATL   16837\n 6 AUS    2411\n 7 AVL     261\n 8 BDL     412\n 9 BGR     358\n10 BHM     269\n# ℹ 94 more rows\n\n# use\nnot_cancelled %>% \n  count(dest)\n\n# A tibble: 104 × 2\n   dest      n\n   <chr> <int>\n 1 ABQ     254\n 2 ACK     264\n 3 ALB     418\n 4 ANC       8\n 5 ATL   16837\n 6 AUS    2411\n 7 AVL     261\n 8 BDL     412\n 9 BGR     358\n10 BHM     269\n# ℹ 94 more rows\n\n\n\nThe count() function can take in weights as well. We can use this to find the planes that logged the most air miles in 2013.\n\n\nnot_cancelled %>% \n  count(tail_num, wt = distance) %>% \n  arrange(desc(n))\n\n# A tibble: 4,037 × 2\n   tail_num      n\n   <chr>     <dbl>\n 1 N328AA   929090\n 2 N338AA   921172\n 3 N335AA   902271\n 4 N327AA   900482\n 5 N323AA   839468\n 6 N319AA   837924\n 7 N336AA   833136\n 8 N329AA   825826\n 9 N324AA   786159\n10 N339AA   783648\n# ℹ 4,027 more rows"
  },
  {
    "objectID": "lessons/lesson09_dplyr.html#grouping-by-multiple-variables",
    "href": "lessons/lesson09_dplyr.html#grouping-by-multiple-variables",
    "title": "Lesson 9: Data Manipulation with dplyr",
    "section": "Grouping by Multiple Variables",
    "text": "Grouping by Multiple Variables\nWe can group on the year, month within year, and day within month. Then, we can “roll up” the data summaries.\n\n(\n  per_day <- flights %>% \n    group_by(year, month, day) %>% \n    summarise(flights = n())\n)\n\n`summarise()` has grouped output by 'year', 'month'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 365 × 4\n# Groups:   year, month [12]\n    year month   day flights\n   <int> <int> <int>   <int>\n 1  2013     1     1     842\n 2  2013     1     2     943\n 3  2013     1     3     914\n 4  2013     1     4     915\n 5  2013     1     5     720\n 6  2013     1     6     832\n 7  2013     1     7     933\n 8  2013     1     8     899\n 9  2013     1     9     902\n10  2013     1    10     932\n# ℹ 355 more rows\n\n(\n  per_month <- per_day %>% \n    summarise(flights = sum(flights))\n)\n\n`summarise()` has grouped output by 'year'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 12 × 3\n# Groups:   year [1]\n    year month flights\n   <int> <int>   <int>\n 1  2013     1   27004\n 2  2013     2   24951\n 3  2013     3   28834\n 4  2013     4   28330\n 5  2013     5   28796\n 6  2013     6   28243\n 7  2013     7   29425\n 8  2013     8   29327\n 9  2013     9   27574\n10  2013    10   28889\n11  2013    11   27268\n12  2013    12   28135\n\n(\n  per_year <- per_month %>%\n    summarise(flights = sum(flights))\n)\n\n# A tibble: 1 × 2\n   year flights\n  <int>   <int>\n1  2013  336776"
  },
  {
    "objectID": "lessons/lesson09_dplyr.html#carrier-name-data",
    "href": "lessons/lesson09_dplyr.html#carrier-name-data",
    "title": "Lesson 9: Data Manipulation with dplyr",
    "section": "Carrier Name Data",
    "text": "Carrier Name Data\nTake a look at the names of the airlines in the flights data set (the unique() function does what you think it does)\n\nflights %>% \n  select(carrier) %>% \n  unique()\n\n# A tibble: 16 × 1\n   carrier\n   <chr>  \n 1 UA     \n 2 AA     \n 3 B6     \n 4 DL     \n 5 EV     \n 6 MQ     \n 7 US     \n 8 WN     \n 9 VX     \n10 FL     \n11 AS     \n12 9E     \n13 F9     \n14 HA     \n15 YV     \n16 OO     \n\n\nSome of these abbreviations I know, but not all of them. However, in the nycflights13 package, there is another data set that matches the airline abbreviation with its full company name (I found this data set by looking at the help file for the flights object):\n\nairlines\n\n# A tibble: 16 × 2\n   carrier name                       \n   <chr>   <chr>                      \n 1 9E      Endeavor Air Inc.          \n 2 AA      American Airlines Inc.     \n 3 AS      Alaska Airlines Inc.       \n 4 B6      JetBlue Airways            \n 5 DL      Delta Air Lines Inc.       \n 6 EV      ExpressJet Airlines Inc.   \n 7 F9      Frontier Airlines Inc.     \n 8 FL      AirTran Airways Corporation\n 9 HA      Hawaiian Airlines Inc.     \n10 MQ      Envoy Air                  \n11 OO      SkyWest Airlines Inc.      \n12 UA      United Air Lines Inc.      \n13 US      US Airways Inc.            \n14 VX      Virgin America             \n15 WN      Southwest Airlines Co.     \n16 YV      Mesa Airlines Inc.         \n\n\n\nAirline with the Fewest Delays\nWe want to find the airlines and airports to fly out of NYC on that will get us to our destination on time.\n\nmean_arr_delay_df <- \n  not_cancelled %>% \n  group_by(carrier, origin) %>% \n  summarise(mean_arr_delay = mean(arr_delay)) %>% \n  arrange(mean_arr_delay)\n\n`summarise()` has grouped output by 'carrier'. You can override using the\n`.groups` argument.\n\nmean_arr_delay_df\n\n# A tibble: 35 × 3\n# Groups:   carrier [16]\n   carrier origin mean_arr_delay\n   <chr>   <chr>           <dbl>\n 1 AS      EWR            -9.93 \n 2 HA      JFK            -6.92 \n 3 DL      JFK            -2.38 \n 4 AA      LGA            -1.33 \n 5 VX      EWR            -0.677\n 6 US      EWR             0.977\n 7 AA      EWR             0.978\n 8 9E      EWR             1.62 \n 9 9E      LGA             1.77 \n10 AA      JFK             2.08 \n# ℹ 25 more rows\n\n\nNow, we can join this tibble to the airlines tibble. Which join will we use? We want to keep all the rows from this mean arrival delay tibble, and match the rows from the airlines tibble to it. We will use the left_join() function, with mean_arr_delay_df as the left table and airlines as the right:\n\nleft_join(mean_arr_delay_df, airlines)\n\nJoining with `by = join_by(carrier)`\n\n\n# A tibble: 35 × 4\n# Groups:   carrier [16]\n   carrier origin mean_arr_delay name                  \n   <chr>   <chr>           <dbl> <chr>                 \n 1 AS      EWR            -9.93  Alaska Airlines Inc.  \n 2 HA      JFK            -6.92  Hawaiian Airlines Inc.\n 3 DL      JFK            -2.38  Delta Air Lines Inc.  \n 4 AA      LGA            -1.33  American Airlines Inc.\n 5 VX      EWR            -0.677 Virgin America        \n 6 US      EWR             0.977 US Airways Inc.       \n 7 AA      EWR             0.978 American Airlines Inc.\n 8 9E      EWR             1.62  Endeavor Air Inc.     \n 9 9E      LGA             1.77  Endeavor Air Inc.     \n10 AA      JFK             2.08  American Airlines Inc.\n# ℹ 25 more rows\n\n\nWe will spend a bit more time on joins when we are working with the ACS SNAP data (remember that we have one data set with all the ZIP codes for Miami-Dade and Broward and a different data set with all the SNAP recipients for the whole state). However, we still need to learn how to work with data in character strings first, so we will be back to these data after the stringr:: lesson.\n\n\n\n\n\n\nExercise\n\n\n\nFind the airports and airlines that have the lowest average arrival delay to Miami."
  }
]