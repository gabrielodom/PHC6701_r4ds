---
title: "Lesson 12: Functional Iteration with purrr"
author: "Gabriel Odom "
date: "04/10/2023"
date-modified: "2023-11-30"
format:
  html:
    toc: true
    toc-depth: 2
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE) # , eval = FALSE
```

# Review
What did we learn last class? 

1. Control Flow in R
2. Creating Functions
3. Best Practices
4. Function Scoping

</br>

*******************************************************************************
</br>



# Overview
In this lesson, we will cover the following:

1. Review vectors
2. Review functions
3. What are "Functionals"?
4. Applying Functions to Vectors
5. Split-Apply-Combine

Because the point of this lesson is to meaningfully connect functions and vectors, we will review both concepts before adding new material.


## Reading, Videos, and Assignments

- Watch: <>
- Read: 
- Do: 

</br>

*******************************************************************************
</br>



# Learning Resources
This lesson borrows data from some material from Washington State University's [Department of Statistics](https://cougrstats.wordpress.com/2020/02/19/an-introduction-to-working-with-lists-using-purrr/). The link to the zipped data (1.7Mb unzipped) is: <https://drive.google.com/drive/folders/1HDeAg0EtqE_T1PuRBjKsczR8_ev3XKIA>.

For this lesson, we will also use a simple subset of the Gapminder data. And, of course, we will need the `tidyverse` again:
```{r packages, message=FALSE}
# install.packages("gapminder")
library(gapminder)
library(tidyverse)

gapminder_df <- as_tibble(gapminder)
```

::: {.callout-note title="Exercises"}
## Exercises
1. Download the compressed file from the link above; unzip it on your desktop.
2. Rename the `data/` subdirectory in the folder above to `purrr_example_data/`; move it to your data folder for this class.
3. Delete the compressed and unzipped folders from your desktop.
:::

</br>

*******************************************************************************
</br>



# Review: Vectors
Recall that most of the data you see in R is a vector (either atomic or non-atomic) in some way. In math, vectors have a precise definition, but they are much more loosely defined in R: vectors are simply an ordered collection of objects, themselves in an object.

We have atomic vectors:
```{r}
x <- c(1, 3, 5)
```

We have non-atomic vectors, including lists:
```{r}
me_ls <- list(
  forname = "Gabriel",
  surname = "Odom",
  age = 35
)

me_ls
```

and tibbles:
```{r}
gapminder_df
```

All the elements of any vector can be accessed by their **position**:
```{r}
x[1]
me_ls[1]
gapminder_df[1]
```

This idea of using position to access the elements of a vector is important for this lesson, and we will bring it up again shortly. Similarly, we should recognize that using the `[` accessor yields vector elements that could be atomic or non-atomic. The concepts of 1) position access to vector elements and 2) the classes of those elements will be key to understanding this lesson.

</br>

*******************************************************************************
</br>



# Review: Functions

Last lesson, we learned functions, how they work, and the best practices for writing them. Recall that functions have 3 main components:

- **Name**: the object in the environment (Global Environment for example) that "holds" the code we write
- **Arguments**: inputs of the function; what does the user need to provide in order for the function to work?
- **Body**: what the function does; that is, the code that we write

We have written a few versions of a "data summary" function in the past. Here is one version, specifically designed for numeric data:
```{r}
MyNumericSummaryFun <- function(x_num) {
  c(
    Min = min(x_num),
    Q1 = quantile(x_num, 0.25),
    Median = median(x_num),
    Mean = mean(x_num),
    Q3 = quantile(x_num, 0.75),
    Max = max(x_num),
    StdDev = sd(x_num),
    IQR = IQR(x_num)
  )
}

# Test
MyNumericSummaryFun(0:10)
```

::: {.callout-note title="Exercises"}
## Exercises
1. Identify the name, arguments, and body of the function above.
2. If we need to remove missing values from the `x_num` vector, how could we modify the function above?
3. Sketch out the documentation for this function.
:::

</br>

*******************************************************************************
</br>



# Functionals
So far, we our interactions with functions have usually been to call them directly; that is, 
```{r}
#| eval: false

output <- a_function(input1, input2, ...)
```

Functionals give us the ability to abstract this relationship between inputs, outputs, and the work done in between. Functionals are specific *helper functions* which take in another function as one of its arguments. So, our interaction with functionals looks more like one of these:
```{r}
#| eval: false
# A Functional form
output <- DO(TO = c(input1, input2, ...), THIS = a_function, WITH = {options})

# Another Functional form
output <- DO(THIS = a_function, TO = c(input1, input2, ...), WITH = {options})
```

In the two sets of code above, the object `output` would contain the same information, but it might be in a different "form" (think about the `class()` function). Also, the ordering of the `THIS` (the function) and the `TO` (the function arguments) may be reversed, and sometimes the `WITH` options are mixed in with the function arguments (i.e., there isn't a separation between the `TO` and `WITH` parts of the functional).


## An Example
Thankfully, before we get completely lost, we have actually seen something similar to a functional already. Let's use the Gapminder data and find the 10 countries with the smallest maximum life expectancy:
```{r}
gapminder_df %>% 
  group_by(country) %>% 
  summarise(best_life_expectancy = max(lifeExp, na.rm = TRUE)) %>% 
  slice_min(order_by = best_life_expectancy, n = 10)
```

Here, the `summarize()` function is like a functional. It says "find the life expectancy column, and take the maximum of it"; that is, it is similar to 
```{r}
#| eval: false

DO(TO = lifeExp, THIS = max(), WITH = {na.rm = TRUE})
```

::: {.callout-important}
**Functionals are functions which take in another function as one of its arguments.**.
:::

</br>

*******************************************************************************
</br>



# Applying Functions to Vectors
Now that we have reviewed vectors, functions, and learned some basics of functionals, we can start *applying* our functions to our data. Recall that most objects in R are either functions or vectors. We saw that the FOR loop controller was capable of evaluating a function with each element of a vector (for instance, adding up all the values of a vector using a FOR loop). We also saw that, for most cases, R's vectorised nature makes using FOR loops unnecessary. 

::: {.callout-important}
**Our task: APPLY (*functional*) a FUNCTION to EACH ELEMENT of a VECTOR**.
:::


## Example: The Convergence of the Sample Mean
During this, my 12th lesson in statistical computing, we will finally do a little bit of "traditional" statistics. Here is the general premise: the sample mean is an "unbiased" estimator. That is, if you take larger and larger samples from the population, the difference between the sample mean and the population mean should get smaller. To test this, we will first generate a medium-sized population from a random normal distribution (the `set.seed()` function allows me to generate the same random population each time, so that everyone can reproduce the output of my code):
```{r}
# for reproducibility:
set.seed(12345) # if you change this number, you will get a different sample

population <- rnorm(1000, mean = 1)
```

What is the population mean ($\mu$)?
```{r}
mu <- mean(population)
mu
```

### List of Samples
Now, we want to take samples from the population, where each sample is bigger than the last (think of a snowball sampling design where the longer the study goes, the more people you can recruit). That is, we will start with a small batch of subjects (values from `population`), calculate the sample mean ($\bar{x}$), add a few more subjects, calculate the sample mean again, and repeat this until our sample estimate of the mean gets close to the true (population) mean. Because each sample will be bigger than the last, we must use a *list*.
```{r}
samples_ls <- list(
  sample_0819 = population[1:5],
  sample_0826 = population[1:10],
  sample_0902 = population[1:15],
  sample_0909 = population[1:20],
  sample_0916 = population[1:25],
  sample_0923 = population[1:30],
  sample_0930 = population[1:40],
  sample_1007 = population[1:50],
  sample_1014 = population[1:75],
  sample_1021 = population[1:100],
  sample_1028 = population[1:125],
  sample_1104 = population[1:150],
  sample_1111 = population[1:175],
  sample_1118 = population[1:200],
  sample_1125 = population[1:250],
  sample_1202 = population[1:300],
  sample_1209 = population[1:400],
  sample_1216 = population[1:500]
)
```

### The FOR Loop
Now that we have our samples, we need to find the mean of each. Will simply taking the mean work?
```{r}
mean(samples_ls)
```

Unfortunately no. Based on what we learned previously about FOR loops, we can use one of those:
```{r}
# Initialize
nSamples <- length(samples_ls)
sampleMeans <- rep(NA_real_, nSamples)

# Loop
for (i in 1:nSamples) {
  sampleMeans[i] <- mean(samples_ls[[i]])
}
```

Notice that we are using the **position** of the elements of the vector. These are the mean values we calculated:
```{r}
sampleMeans
```

How far are these from the true population mean? We set this loop up to fill values into a numeric vector, so we can use R's vector power again:
```{r}
abs(mu - sampleMeans)
plot(x = lengths(samples_ls), y = abs(mu - sampleMeans), ylim = c(0, 0.3))
```

We can see that, as my sample size grows, the difference between the sample mean and the population mean gets smaller.


## Mapping a Defined Function to Values
This code was quite cumbersome. We had to measure how long the list was, create an empty atomic vector to hold our results, and then write the FOR loop to iterate over each position in the list of samples. On top of all of this, we've added this useless `i` object to the Global Environment, and the FOR loop lost the names of the samples! There is a better way: the `map()` function from the `purrr` package (included in the `tidyverse`, so remember to load that package):
```{r}
map(samples_ls, mean)
```

::: {.callout-note title="Exercises"}
## Exercises
1. This function does return the values we want, but it does so as a list. We would like an atomic vector. Check the help files for `map()` to find out what to change.
2. While you are in the help file for `map()`, find out how to pass in a second argument to the `mean()` function. Set `na.rm = TRUE` and test it.
:::


## `map()` Syntax
In order to use the `map()` function and its friends, follow the following syntax: `map(.x = VECTOR, .f = FUNCTION)`. That's it. For example, to find the summary of each column in the `mpg` data set, type:
```{r}
map(mpg, summary)
```

::: {.callout-tip}
This example shows that the `summary()` function isn't very helpful for character information. We are immediately motivated us to ask, "Can I write my own function for `map()` to use?" The answer is YES! More on that shortly...
:::

### Sample Means with `map()`
Back to our first example, we still want to find out how close the sample mean gets to the population mean as we increase the sample size. For this, we write our own function to pass to `map()`. Recall the function constructor:
```{r}
# Create the function
absMean <- function(xBar_num, mu_num){
  abs(mean(xBar_num) - mu_num)
}

# Map it
# Recall that the help file says that additional arguments to the function
#   and their values are added after the function name.
map_dbl(sampleMeans, absMean, mu_num = mu)
```

This matches the output of what we calculated using the FOR loop exactly, but with two added benefits: 1) we wrote a function (that could be reused elsewhere in our analysis), and 2) the map is self-contained---we didn't have to initialize a vector or clean up after the FOR loop.

### An Improved `summary()`
We saw that when we applied `summary()` to each column of a tibble, the character columns didn't give us much information. We can then write our own summary function that prints the most common unique values:
```{r}
MySummaryFun <- function(x){
  
  if (is.character(x)){
    
    table(x) %>% 
      sort(decreasing = TRUE) %>%
      head()
    
  } else {
    MyNumericSummaryFun(x)
  }
  
}
```

Now we can apply it to the `mpg` data set:
```{r}
map(mpg, MySummaryFun)
```

It's not terribly pretty (I am *not* a fan of the `table()` function), but it gives us a reasonable idea of what is going on in these columns.

::: {.callout-note title="Exercises"}
## Exercises
1. Why do we only see at most 6 categories for the character information in our function? How could we add an option to our `MySummaryFun()` to change this?
2. Create a sequence of sample sizes from 5 to 500 by 5. Save this vector of sample sizes. *Hint: look up the help files for `sequence()`. You will find the function you need mentioned therein.*
3. Use the `map()` function combined with the sequence you just created to make a list of samples with increasing sizes from the `population` vector. Store it as another list of samples. This should make typing that list by hand obsolete.
4. Use the `map_dbl()` function combined with the `absMean()` function we created to calculate the atomic vector of absolute differences from the sample mean. At what sample size does the estimate get better?
5. Find one of the statistics / biostatistics students and contrast this process with the idea of "repeated sampling". What is different here? Why doesn't the traditional $n = 30$ heuristic apply?
6. Repeat the above process with the following modification: chain these operations together with pipes (`%>%`).
:::

<!-- You can also chain everything together, and then pass it it `ggplot`: -->
<!-- ```{r} -->
<!-- # Create a sequence of sample sizes -->
<!-- seq(5, 100, by = 5) %>%  -->
<!--   # Create a list of larger and larger samples from the population -->
<!--   map(function(i) {population[1:i]}) %>% -->
<!--   # Take the absolute deviation from the population mean -->
<!--   map_dbl(absMean, mu_num = mu) %>% -->
<!--   # Make it a tibble (required for ggplot) -->
<!--   # The "." means "put the input from the pipe here" -->
<!--   tibble(means = .) %>% -->
<!--   # Add on a column for the index of the samples -->
<!--   mutate(index = 1:nrow(.)) %>% -->
<!--   # pass this new tibble with two columns to ggplot() -->
<!--   ggplot() + -->
<!--     aes(x = index, y = means) + -->
<!--     geom_path() -->
<!-- ``` -->

</br>

*******************************************************************************
</br>



# The Split-Apply-Combine Strategy
Now that we have an understanding of how to **map** functions to the values of a vector, we will discuss a powerful technique in data science. Many times we have to deal with either 1) very large datasets (and our computers don't have the memory to hold all the data at once), or 2) datasets with distinct sub-populations (and its not appropriate to estimate population statistics without taking these groupings into account). In these cases, we often employ the following steps:

1. Split the data into subgroups. If there are sub-populations, then use these natural splits. If we simply have too much data, then use random splits.
2. Apply a statistical or machine learning method to each of the smaller data sets and save the results.
3. Combine the saved results from each sub-analysis and report.

We will walk through an example using the Gapminder data. Our goal is to create a table of the life expectancy distribution for each country.


## Split the Gapminder Data by Country
The `split()` function is from base R. It takes in a tibble and breaks it into a *list* of tibbles by the elements of the column you specify (in this case, the column will be `country`).
```{r}
countries_ls <- split(
  x = gapminder,
  f = ~ country
)
```

We are familiar with this data set, but let's take a look at our split data anyway.
```{r}
# First 3 countries
countries_ls[1:3]

# Operations on a specific country
countries_ls$Cameroon
max(countries_ls$Cameroon$lifeExp)
```


## Apply a Method to Each Country's Data
Now, if we wanted to find country-specific summaries of life expectancy, we can:
```{r}
lifeExpSummary_ls <- 
  map(
    # Only show the first 5 for the example
    .x = countries_ls,
    .f = "lifeExp"
  ) %>% 
  map(MyNumericSummaryFun)

lifeExpSummary_ls[1:5]
```

For this example, we could probably get very similar results just using `group_by()` and `summarize()` together. However, this "split-apply-combine" strategy works for **ANY** analysis or operation that you want to do---even advanced machine learning methods---far beyond the capabilities of the `summarize()` function alone.

::: {.callout-note title="Exercise"}
## Exercise
We wrote the function `MySummaryFun()` to be able to take the summary of any column, numeric or otherwise. Modify the code above so that we can find the summaries of ALL the columns within the data set specific to each country. Make sure your code works for just the first 5 countries.
:::


## Combine the Results
We have a list of the numeric summaries of life expectancy for each of the `r length(countries_ls)` countries. Let's combine these results. First, we check the class of the individual list elements:
```{r}
class(lifeExpSummary_ls[[1]])
```

The elements of the vector are numeric. If we want to end up with a tibble that has one row for each country, then the elements should first be transformed to be a one-row tibble. Unfortunately, there is not a standard `as_*()` function that will turn a named numeric vector into a one-row tibble. However, (very confusingly) the `bind_rows()` function will turn a named atomic vector into a one-row tibble. Let's test it out:
```{r}
# Original named atomic vector
lifeExpSummary_ls$Afghanistan

# Tibble with one row
bind_rows(lifeExpSummary_ls$Afghanistan)
```

Now that we know this will work for one country, we can add it into a pipeline for all the countries. Then, calling the `bind_rows()` function a second time (using it as designed), we will end up with a tibble with a row for each country and `r length(lifeExpSummary_ls$Afghanistan)` columns:
```{r}
lifeExpSummary_df <- 
  lifeExpSummary_ls %>% 
  map(bind_rows) %>% 
  bind_rows(.id = "country")

lifeExpSummary_df
```

::: {.callout-note title="Exercise"}
## Exercise
1. In the last exercise, we found the summaries of *all* the features for each country (not just the numeric ones). Can these results be combined into a single tibble? Why or why not?
2. Can you create the `lifeExpSummary_df` data table by using `group_by()` and `summarize()` (without the split-apply-combine strategy)?
3. Read the help file for the `bind_rows()` function. What does the `.id` argument do? Is this a default behavior?
4. Take the summary of life expectancy table above, and join it back to `gapminder_df` to add a column for the continent to our results. Plot a boxplot of the 75th percentile of life expectancy by continent.
:::


## Example: Back to Tornados
Finally, one of the most valuable applications of this technique is to import and analyze multiple data files all at once. As long as our computer is well organized, we can set a `map()` call to import all of the data files in a particular sub-directory. In the code below, you'll need to change the file path to meet your own directory structure.
```{r}
# Review: how to import a single data set with readr::
tornados08_df <- read_csv(file = "../_data/purrr_example_data/2008_torn.csv")

# Create a VECTOR of the names AND paths to the data sets
dataPaths_char <- list.files(
  path = "../_data/purrr_example_data/", 
  full.names = TRUE
)
names(dataPaths_char) <- list.files(
  path = "../_data/purrr_example_data/", 
  full.names = FALSE
)

# Inspect
dataPaths_char
```

Now that we have a vector of the file paths to the tornadoes data, we can write a `map()` call that imports each data file as an element of a list of tibbles.
```{r}
#| message: false

tornadoData_ls <- map(
  .x = dataPaths_char,
  .f = read_csv
)
```

::: {.callout-note title="Exercise"}
## Exercise
1. For each year, find the set of states where a tornado was recorded (the state abbreviations are in the column `st`).
2. Is the output you got in the last question "professional"? (Probably not). Modify your code to:
    + Create a table of the number of tornados by state for each year
    + Create a vector of the state abbreviations where a tornado occured for each year
3. The `list.files()` function has an argument `full.names`. What does this do, and why did we need to change this argument from `TRUE` to `FALSE` in the code above?
:::

```{r}
#| include: false

# Extract the states where tornadoes occurred in each year:
map(
  .x = tornadoData_ls,
  .f = "st"
)
# NOTE: have them do this as an exercise, so that the lesson doesn't explode

# Extract the *unique* states where tornadoes occurred in each year
map(
  .x = tornadoData_ls,
  # .f = function(x) {
  .f = ~ {
    # unique(.x[["st"]])
    .x %>%
      pull("st") %>%
      unique()
  }
)
```

